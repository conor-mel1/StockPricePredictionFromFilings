{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Total Liabilities</th>\n",
       "      <th>Total Equity</th>\n",
       "      <th>Total Shares Out. on Filing Date</th>\n",
       "      <th>Book Value / Share</th>\n",
       "      <th>Tangible Book Value</th>\n",
       "      <th>Tangible Book Value Per Share</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RHI</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>1490.3</td>\n",
       "      <td>570.6</td>\n",
       "      <td>919.6</td>\n",
       "      <td>135.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>718.3</td>\n",
       "      <td>5.31</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-274.3</td>\n",
       "      <td>41.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RCL</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>19804.4</td>\n",
       "      <td>11396.6</td>\n",
       "      <td>8407.8</td>\n",
       "      <td>217.5</td>\n",
       "      <td>38.74</td>\n",
       "      <td>7442.4</td>\n",
       "      <td>34.29</td>\n",
       "      <td>8507.2</td>\n",
       "      <td>8245.0</td>\n",
       "      <td>24.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>17315.0</td>\n",
       "      <td>5111.0</td>\n",
       "      <td>12204.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>19.93</td>\n",
       "      <td>11537.0</td>\n",
       "      <td>18.84</td>\n",
       "      <td>2643.0</td>\n",
       "      <td>-8254.0</td>\n",
       "      <td>236.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STC</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>1291.2</td>\n",
       "      <td>710.8</td>\n",
       "      <td>580.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>29.31</td>\n",
       "      <td>263.5</td>\n",
       "      <td>13.58</td>\n",
       "      <td>71.2</td>\n",
       "      <td>-137.4</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XRAY</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>3258.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>1909.9</td>\n",
       "      <td>142.1</td>\n",
       "      <td>12.98</td>\n",
       "      <td>457.6</td>\n",
       "      <td>3.23</td>\n",
       "      <td>786.6</td>\n",
       "      <td>246.6</td>\n",
       "      <td>34.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GWW</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>5694.3</td>\n",
       "      <td>3788.5</td>\n",
       "      <td>1905.8</td>\n",
       "      <td>58.8</td>\n",
       "      <td>30.57</td>\n",
       "      <td>684.7</td>\n",
       "      <td>11.64</td>\n",
       "      <td>2247.1</td>\n",
       "      <td>1972.9</td>\n",
       "      <td>232.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SKM</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>24288.4</td>\n",
       "      <td>11223.5</td>\n",
       "      <td>13064.9</td>\n",
       "      <td>70.6</td>\n",
       "      <td>183.55</td>\n",
       "      <td>9386.2</td>\n",
       "      <td>132.93</td>\n",
       "      <td>7039.9</td>\n",
       "      <td>5790.9</td>\n",
       "      <td>20.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BAX</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>19073.0</td>\n",
       "      <td>12245.0</td>\n",
       "      <td>6828.0</td>\n",
       "      <td>560.3</td>\n",
       "      <td>11.74</td>\n",
       "      <td>3442.0</td>\n",
       "      <td>6.14</td>\n",
       "      <td>5195.0</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>26.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MAR</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>6342.0</td>\n",
       "      <td>7627.0</td>\n",
       "      <td>-1285.0</td>\n",
       "      <td>312.3</td>\n",
       "      <td>-4.13</td>\n",
       "      <td>-3274.0</td>\n",
       "      <td>-10.53</td>\n",
       "      <td>2935.0</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>37.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SJM</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>16711.3</td>\n",
       "      <td>8740.8</td>\n",
       "      <td>7970.5</td>\n",
       "      <td>113.7</td>\n",
       "      <td>70.08</td>\n",
       "      <td>-5059.2</td>\n",
       "      <td>-44.48</td>\n",
       "      <td>5959.9</td>\n",
       "      <td>5858.6</td>\n",
       "      <td>122.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HPQ</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>28987.0</td>\n",
       "      <td>32876.0</td>\n",
       "      <td>-3889.0</td>\n",
       "      <td>1705.5</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>-9511.0</td>\n",
       "      <td>-5.56</td>\n",
       "      <td>6813.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>14.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MHK</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>12094.9</td>\n",
       "      <td>4998.4</td>\n",
       "      <td>7096.5</td>\n",
       "      <td>74.4</td>\n",
       "      <td>94.85</td>\n",
       "      <td>3695.9</td>\n",
       "      <td>49.66</td>\n",
       "      <td>2763.6</td>\n",
       "      <td>2678.7</td>\n",
       "      <td>275.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FDX</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>33070.0</td>\n",
       "      <td>17793.0</td>\n",
       "      <td>15277.0</td>\n",
       "      <td>285.4</td>\n",
       "      <td>53.52</td>\n",
       "      <td>12430.0</td>\n",
       "      <td>43.55</td>\n",
       "      <td>4737.0</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>144.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSI</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>11851.0</td>\n",
       "      <td>8162.0</td>\n",
       "      <td>3689.0</td>\n",
       "      <td>253.9</td>\n",
       "      <td>14.38</td>\n",
       "      <td>3292.0</td>\n",
       "      <td>12.94</td>\n",
       "      <td>2461.0</td>\n",
       "      <td>-764.0</td>\n",
       "      <td>67.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CINF</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>25408.0</td>\n",
       "      <td>15544.0</td>\n",
       "      <td>9864.0</td>\n",
       "      <td>162.7</td>\n",
       "      <td>60.55</td>\n",
       "      <td>9864.0</td>\n",
       "      <td>60.55</td>\n",
       "      <td>885.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>105.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WU</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>10121.3</td>\n",
       "      <td>9016.6</td>\n",
       "      <td>1104.7</td>\n",
       "      <td>547.9</td>\n",
       "      <td>2.01</td>\n",
       "      <td>-2585.9</td>\n",
       "      <td>-4.71</td>\n",
       "      <td>4220.8</td>\n",
       "      <td>2036.1</td>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MGEE</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2081.7</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>855.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>24.68</td>\n",
       "      <td>841.0</td>\n",
       "      <td>24.26</td>\n",
       "      <td>562.4</td>\n",
       "      <td>538.9</td>\n",
       "      <td>78.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CCOI</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>606.5</td>\n",
       "      <td>446.8</td>\n",
       "      <td>159.8</td>\n",
       "      <td>45.4</td>\n",
       "      <td>3.52</td>\n",
       "      <td>159.8</td>\n",
       "      <td>3.52</td>\n",
       "      <td>395.4</td>\n",
       "      <td>148.1</td>\n",
       "      <td>22.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TPR</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>6678.3</td>\n",
       "      <td>3433.7</td>\n",
       "      <td>3244.6</td>\n",
       "      <td>288.0</td>\n",
       "      <td>11.27</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1600.6</td>\n",
       "      <td>350.6</td>\n",
       "      <td>46.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HWKN</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>385.6</td>\n",
       "      <td>167.7</td>\n",
       "      <td>217.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>20.57</td>\n",
       "      <td>93.7</td>\n",
       "      <td>8.85</td>\n",
       "      <td>84.6</td>\n",
       "      <td>75.4</td>\n",
       "      <td>36.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ULTA</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>2908.7</td>\n",
       "      <td>1134.5</td>\n",
       "      <td>1774.2</td>\n",
       "      <td>60.6</td>\n",
       "      <td>29.17</td>\n",
       "      <td>1774.2</td>\n",
       "      <td>29.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-397.4</td>\n",
       "      <td>203.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NEE</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>103702.0</td>\n",
       "      <td>65821.0</td>\n",
       "      <td>37881.0</td>\n",
       "      <td>478.2</td>\n",
       "      <td>71.43</td>\n",
       "      <td>32545.0</td>\n",
       "      <td>68.09</td>\n",
       "      <td>37775.0</td>\n",
       "      <td>37137.0</td>\n",
       "      <td>173.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PM</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>35488.0</td>\n",
       "      <td>33725.0</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>1721.9</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-13396.0</td>\n",
       "      <td>-7.76</td>\n",
       "      <td>18545.0</td>\n",
       "      <td>15995.0</td>\n",
       "      <td>78.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PNR</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>3806.5</td>\n",
       "      <td>1970.4</td>\n",
       "      <td>1836.1</td>\n",
       "      <td>171.4</td>\n",
       "      <td>10.71</td>\n",
       "      <td>-512.9</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>787.6</td>\n",
       "      <td>713.3</td>\n",
       "      <td>37.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SSP</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2129.5</td>\n",
       "      <td>1192.1</td>\n",
       "      <td>937.5</td>\n",
       "      <td>81.5</td>\n",
       "      <td>11.48</td>\n",
       "      <td>-330.3</td>\n",
       "      <td>-4.05</td>\n",
       "      <td>693.3</td>\n",
       "      <td>544.6</td>\n",
       "      <td>15.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>STZ</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>29231.5</td>\n",
       "      <td>16394.3</td>\n",
       "      <td>12837.2</td>\n",
       "      <td>190.2</td>\n",
       "      <td>66.01</td>\n",
       "      <td>1264.1</td>\n",
       "      <td>6.65</td>\n",
       "      <td>13616.5</td>\n",
       "      <td>13522.9</td>\n",
       "      <td>169.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ELP</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>9638.1</td>\n",
       "      <td>4490.4</td>\n",
       "      <td>5147.8</td>\n",
       "      <td>273.7</td>\n",
       "      <td>18.33</td>\n",
       "      <td>4197.3</td>\n",
       "      <td>15.34</td>\n",
       "      <td>2277.8</td>\n",
       "      <td>1826.6</td>\n",
       "      <td>11.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CLX</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>4164.0</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>128.6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-1534.0</td>\n",
       "      <td>-11.93</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>104.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MKTX</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>581.2</td>\n",
       "      <td>66.5</td>\n",
       "      <td>514.8</td>\n",
       "      <td>37.6</td>\n",
       "      <td>13.68</td>\n",
       "      <td>451.7</td>\n",
       "      <td>12.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-258.3</td>\n",
       "      <td>201.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ENIA</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>16851.5</td>\n",
       "      <td>8971.7</td>\n",
       "      <td>7879.7</td>\n",
       "      <td>57452.6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3686.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>4307.8</td>\n",
       "      <td>1514.7</td>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>SWKS</td>\n",
       "      <td>2010-10-01</td>\n",
       "      <td>1564.1</td>\n",
       "      <td>247.5</td>\n",
       "      <td>1316.6</td>\n",
       "      <td>183.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>818.5</td>\n",
       "      <td>4.54</td>\n",
       "      <td>74.7</td>\n",
       "      <td>-378.5</td>\n",
       "      <td>22.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>TU</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>19605.5</td>\n",
       "      <td>12215.2</td>\n",
       "      <td>7390.3</td>\n",
       "      <td>1299.4</td>\n",
       "      <td>5.69</td>\n",
       "      <td>-2263.4</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>6864.1</td>\n",
       "      <td>6817.8</td>\n",
       "      <td>53.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>LBTYA</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>49046.3</td>\n",
       "      <td>35847.7</td>\n",
       "      <td>13198.6</td>\n",
       "      <td>632.6</td>\n",
       "      <td>21.51</td>\n",
       "      <td>-1018.0</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>30309.1</td>\n",
       "      <td>21895.9</td>\n",
       "      <td>22.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>VERU</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>35.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>31.4</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1.09</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>9.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>GPC</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>12683.0</td>\n",
       "      <td>9211.0</td>\n",
       "      <td>3472.0</td>\n",
       "      <td>145.9</td>\n",
       "      <td>23.64</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>3149.6</td>\n",
       "      <td>2816.1</td>\n",
       "      <td>96.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>LPX</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>2331.0</td>\n",
       "      <td>1297.2</td>\n",
       "      <td>1033.8</td>\n",
       "      <td>139.3</td>\n",
       "      <td>7.46</td>\n",
       "      <td>997.2</td>\n",
       "      <td>7.20</td>\n",
       "      <td>880.5</td>\n",
       "      <td>319.6</td>\n",
       "      <td>19.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>TNK</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>1241.2</td>\n",
       "      <td>762.9</td>\n",
       "      <td>478.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.16</td>\n",
       "      <td>478.3</td>\n",
       "      <td>34.16</td>\n",
       "      <td>726.8</td>\n",
       "      <td>564.0</td>\n",
       "      <td>40.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>DUK</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>113856.0</td>\n",
       "      <td>72822.0</td>\n",
       "      <td>41034.0</td>\n",
       "      <td>704.7</td>\n",
       "      <td>58.04</td>\n",
       "      <td>24126.0</td>\n",
       "      <td>34.27</td>\n",
       "      <td>40718.0</td>\n",
       "      <td>38959.0</td>\n",
       "      <td>63.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>TT</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>17658.1</td>\n",
       "      <td>10526.8</td>\n",
       "      <td>7131.3</td>\n",
       "      <td>278.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>-2393.7</td>\n",
       "      <td>-8.47</td>\n",
       "      <td>3521.2</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>61.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>FFIV</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2476.5</td>\n",
       "      <td>1247.1</td>\n",
       "      <td>1229.4</td>\n",
       "      <td>62.6</td>\n",
       "      <td>19.64</td>\n",
       "      <td>630.9</td>\n",
       "      <td>10.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1016.9</td>\n",
       "      <td>120.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>AOS</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>2515.3</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1381.3</td>\n",
       "      <td>178.7</td>\n",
       "      <td>7.73</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>223.8</td>\n",
       "      <td>-318.1</td>\n",
       "      <td>28.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>OII</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>3128.5</td>\n",
       "      <td>1085.1</td>\n",
       "      <td>2043.4</td>\n",
       "      <td>108.2</td>\n",
       "      <td>18.89</td>\n",
       "      <td>1630.9</td>\n",
       "      <td>15.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-91.4</td>\n",
       "      <td>78.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>KEP</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>166405.3</td>\n",
       "      <td>102544.2</td>\n",
       "      <td>63861.1</td>\n",
       "      <td>642.0</td>\n",
       "      <td>97.59</td>\n",
       "      <td>61627.1</td>\n",
       "      <td>96.00</td>\n",
       "      <td>55134.5</td>\n",
       "      <td>51796.1</td>\n",
       "      <td>14.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>SYY</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>18070.4</td>\n",
       "      <td>15525.8</td>\n",
       "      <td>2544.6</td>\n",
       "      <td>520.6</td>\n",
       "      <td>4.82</td>\n",
       "      <td>-2428.3</td>\n",
       "      <td>-4.66</td>\n",
       "      <td>8377.0</td>\n",
       "      <td>7824.7</td>\n",
       "      <td>68.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>SBUX</td>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>8219.2</td>\n",
       "      <td>3104.7</td>\n",
       "      <td>5114.5</td>\n",
       "      <td>1487.2</td>\n",
       "      <td>3.41</td>\n",
       "      <td>4566.2</td>\n",
       "      <td>3.05</td>\n",
       "      <td>549.6</td>\n",
       "      <td>-1487.4</td>\n",
       "      <td>25.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>CXO</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>12119.0</td>\n",
       "      <td>4496.0</td>\n",
       "      <td>7623.0</td>\n",
       "      <td>147.1</td>\n",
       "      <td>52.61</td>\n",
       "      <td>7599.0</td>\n",
       "      <td>52.44</td>\n",
       "      <td>2741.0</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>132.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>2890.9</td>\n",
       "      <td>1019.3</td>\n",
       "      <td>1871.6</td>\n",
       "      <td>191.8</td>\n",
       "      <td>9.75</td>\n",
       "      <td>1860.5</td>\n",
       "      <td>9.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-967.4</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>CB</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>167022.0</td>\n",
       "      <td>115850.0</td>\n",
       "      <td>51172.0</td>\n",
       "      <td>464.1</td>\n",
       "      <td>110.32</td>\n",
       "      <td>29118.0</td>\n",
       "      <td>62.78</td>\n",
       "      <td>16022.0</td>\n",
       "      <td>15294.0</td>\n",
       "      <td>146.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1054.3</td>\n",
       "      <td>117.5</td>\n",
       "      <td>936.9</td>\n",
       "      <td>45.1</td>\n",
       "      <td>20.76</td>\n",
       "      <td>900.0</td>\n",
       "      <td>19.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-491.7</td>\n",
       "      <td>285.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>PPL</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>41479.0</td>\n",
       "      <td>30718.0</td>\n",
       "      <td>10761.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>15.52</td>\n",
       "      <td>6806.0</td>\n",
       "      <td>9.82</td>\n",
       "      <td>21375.0</td>\n",
       "      <td>20890.0</td>\n",
       "      <td>30.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>CWCO</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>165.4</td>\n",
       "      <td>23.9</td>\n",
       "      <td>141.5</td>\n",
       "      <td>14.7</td>\n",
       "      <td>9.46</td>\n",
       "      <td>134.3</td>\n",
       "      <td>9.14</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>KT</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>30965.9</td>\n",
       "      <td>20166.5</td>\n",
       "      <td>10799.4</td>\n",
       "      <td>244.9</td>\n",
       "      <td>38.68</td>\n",
       "      <td>6820.8</td>\n",
       "      <td>27.86</td>\n",
       "      <td>11903.3</td>\n",
       "      <td>9868.1</td>\n",
       "      <td>14.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>USM</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>6462.3</td>\n",
       "      <td>3148.6</td>\n",
       "      <td>3313.8</td>\n",
       "      <td>84.0</td>\n",
       "      <td>39.27</td>\n",
       "      <td>1488.4</td>\n",
       "      <td>17.70</td>\n",
       "      <td>1126.9</td>\n",
       "      <td>915.4</td>\n",
       "      <td>39.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>GL</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>18191.7</td>\n",
       "      <td>14415.4</td>\n",
       "      <td>3776.3</td>\n",
       "      <td>132.8</td>\n",
       "      <td>28.13</td>\n",
       "      <td>3334.8</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1219.9</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>52.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>VIAC</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>20843.0</td>\n",
       "      <td>18865.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>382.7</td>\n",
       "      <td>5.16</td>\n",
       "      <td>-5579.0</td>\n",
       "      <td>-14.57</td>\n",
       "      <td>10162.0</td>\n",
       "      <td>9877.0</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>HRL</td>\n",
       "      <td>2010-10-01</td>\n",
       "      <td>4053.9</td>\n",
       "      <td>1647.3</td>\n",
       "      <td>2406.6</td>\n",
       "      <td>532.5</td>\n",
       "      <td>4.51</td>\n",
       "      <td>1630.1</td>\n",
       "      <td>3.06</td>\n",
       "      <td>350.0</td>\n",
       "      <td>-168.4</td>\n",
       "      <td>11.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>PFE</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>171615.0</td>\n",
       "      <td>111775.0</td>\n",
       "      <td>59840.0</td>\n",
       "      <td>5951.9</td>\n",
       "      <td>9.81</td>\n",
       "      <td>-47577.0</td>\n",
       "      <td>-7.84</td>\n",
       "      <td>42234.0</td>\n",
       "      <td>24358.0</td>\n",
       "      <td>32.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>FMC</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>6139.3</td>\n",
       "      <td>4146.3</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>14.64</td>\n",
       "      <td>707.4</td>\n",
       "      <td>5.29</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>1856.8</td>\n",
       "      <td>49.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>LPX</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>2139.9</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>1000.9</td>\n",
       "      <td>137.1</td>\n",
       "      <td>7.30</td>\n",
       "      <td>961.4</td>\n",
       "      <td>7.01</td>\n",
       "      <td>729.1</td>\n",
       "      <td>389.1</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>CCOI</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>662.8</td>\n",
       "      <td>675.1</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>581.5</td>\n",
       "      <td>377.9</td>\n",
       "      <td>34.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company        Time  Total Assets  Total Liabilities  Total Equity  \\\n",
       "0        RHI  2013-12-01        1490.3              570.6         919.6   \n",
       "1        RCL  2011-12-01       19804.4            11396.6        8407.8   \n",
       "2       NVDA  2020-01-01       17315.0             5111.0       12204.0   \n",
       "3        STC  2012-12-01        1291.2              710.8         580.4   \n",
       "4       XRAY  2010-12-01        3258.0             1348.0        1909.9   \n",
       "5        GWW  2016-12-01        5694.3             3788.5        1905.8   \n",
       "6        SKM  2015-12-01       24288.4            11223.5       13064.9   \n",
       "7        BAX  2011-12-01       19073.0            12245.0        6828.0   \n",
       "8        MAR  2012-12-01        6342.0             7627.0       -1285.0   \n",
       "9        SJM  2019-04-01       16711.3             8740.8        7970.5   \n",
       "10       HPQ  2016-10-01       28987.0            32876.0       -3889.0   \n",
       "11       MHK  2017-12-01       12094.9             4998.4        7096.5   \n",
       "12       FDX  2014-05-01       33070.0            17793.0       15277.0   \n",
       "13       MSI  2013-12-01       11851.0             8162.0        3689.0   \n",
       "14      CINF  2019-12-01       25408.0            15544.0        9864.0   \n",
       "15        WU  2013-12-01       10121.3             9016.6        1104.7   \n",
       "16      MGEE  2019-12-01        2081.7             1226.0         855.7   \n",
       "17      CCOI  2012-12-01         606.5              446.8         159.8   \n",
       "18       TPR  2018-06-01        6678.3             3433.7        3244.6   \n",
       "19      HWKN  2019-03-01         385.6              167.7         217.9   \n",
       "20      ULTA  2018-02-01        2908.7             1134.5        1774.2   \n",
       "21       NEE  2018-12-01      103702.0            65821.0       37881.0   \n",
       "22        PM  2011-12-01       35488.0            33725.0        1763.0   \n",
       "23       PNR  2018-12-01        3806.5             1970.4        1836.1   \n",
       "24       SSP  2017-12-01        2129.5             1192.1         937.5   \n",
       "25       STZ  2019-02-01       29231.5            16394.3       12837.2   \n",
       "26       ELP  2014-12-01        9638.1             4490.4        5147.8   \n",
       "27       CLX  2015-06-01        4164.0             4046.0         118.0   \n",
       "28      MKTX  2017-12-01         581.2               66.5         514.8   \n",
       "29      ENIA  2016-12-01       16851.5             8971.7        7879.7   \n",
       "...      ...         ...           ...                ...           ...   \n",
       "4970    SWKS  2010-10-01        1564.1              247.5        1316.6   \n",
       "4971      TU  2011-12-01       19605.5            12215.2        7390.3   \n",
       "4972   LBTYA  2019-12-01       49046.3            35847.7       13198.6   \n",
       "4973    VERU  2013-09-01          35.2                3.8          31.4   \n",
       "4974     GPC  2018-12-01       12683.0             9211.0        3472.0   \n",
       "4975     LPX  2012-12-01        2331.0             1297.2        1033.8   \n",
       "4976     TNK  2014-12-01        1241.2              762.9         478.3   \n",
       "4977     DUK  2012-12-01      113856.0            72822.0       41034.0   \n",
       "4978      TT  2013-12-01       17658.1            10526.8        7131.3   \n",
       "4979    FFIV  2017-09-01        2476.5             1247.1        1229.4   \n",
       "4980     AOS  2014-12-01        2515.3             1134.0        1381.3   \n",
       "4981     OII  2013-12-01        3128.5             1085.1        2043.4   \n",
       "4982     KEP  2018-12-01      166405.3           102544.2       63861.1   \n",
       "4983     SYY  2018-06-01       18070.4            15525.8        2544.6   \n",
       "4984    SBUX  2012-09-01        8219.2             3104.7        5114.5   \n",
       "4985     CXO  2016-12-01       12119.0             4496.0        7623.0   \n",
       "4986    EXPD  2014-12-01        2890.9             1019.3        1871.6   \n",
       "4987      CB  2017-12-01      167022.0           115850.0       51172.0   \n",
       "4988    ABMD  2019-03-01        1054.3              117.5         936.9   \n",
       "4989     PPL  2017-12-01       41479.0            30718.0       10761.0   \n",
       "4990    CWCO  2013-12-01         165.4               23.9         141.5   \n",
       "4991      KT  2014-12-01       30965.9            20166.5       10799.4   \n",
       "4992     USM  2014-12-01        6462.3             3148.6        3313.8   \n",
       "4993      GL  2013-12-01       18191.7            14415.4        3776.3   \n",
       "4994    VIAC  2017-12-01       20843.0            18865.0        1978.0   \n",
       "4995     HRL  2010-10-01        4053.9             1647.3        2406.6   \n",
       "4996     PFE  2016-12-01      171615.0           111775.0       59840.0   \n",
       "4997     FMC  2016-12-01        6139.3             4146.3        1993.0   \n",
       "4998     LPX  2011-12-01        2139.9             1139.0        1000.9   \n",
       "4999    CCOI  2015-12-01         662.8              675.1         -12.3   \n",
       "\n",
       "      Total Shares Out. on Filing Date  Book Value / Share  \\\n",
       "0                                135.3                6.80   \n",
       "1                                217.5               38.74   \n",
       "2                                612.0               19.93   \n",
       "3                                 21.1               29.31   \n",
       "4                                142.1               12.98   \n",
       "5                                 58.8               30.57   \n",
       "6                                 70.6              183.55   \n",
       "7                                560.3               11.74   \n",
       "8                                312.3               -4.13   \n",
       "9                                113.7               70.08   \n",
       "10                              1705.5               -2.27   \n",
       "11                                74.4               94.85   \n",
       "12                               285.4               53.52   \n",
       "13                               253.9               14.38   \n",
       "14                               162.7               60.55   \n",
       "15                               547.9                2.01   \n",
       "16                                34.7               24.68   \n",
       "17                                45.4                3.52   \n",
       "18                               288.0               11.27   \n",
       "19                                10.6               20.57   \n",
       "20                                60.6               29.17   \n",
       "21                               478.2               71.43   \n",
       "22                              1721.9                0.13   \n",
       "23                               171.4               10.71   \n",
       "24                                81.5               11.48   \n",
       "25                               190.2               66.01   \n",
       "26                               273.7               18.33   \n",
       "27                               128.6                0.92   \n",
       "28                                37.6               13.68   \n",
       "29                             57452.6                0.11   \n",
       "...                                ...                 ...   \n",
       "4970                             183.3                7.30   \n",
       "4971                            1299.4                5.69   \n",
       "4972                             632.6               21.51   \n",
       "4973                              28.7                1.09   \n",
       "4974                             145.9               23.64   \n",
       "4975                             139.3                7.46   \n",
       "4976                              14.0               34.16   \n",
       "4977                             704.7               58.04   \n",
       "4978                             278.0               25.00   \n",
       "4979                              62.6               19.64   \n",
       "4980                             178.7                7.73   \n",
       "4981                             108.2               18.89   \n",
       "4982                             642.0               97.59   \n",
       "4983                             520.6                4.82   \n",
       "4984                            1487.2                3.41   \n",
       "4985                             147.1               52.61   \n",
       "4986                             191.8                9.75   \n",
       "4987                             464.1              110.32   \n",
       "4988                              45.1               20.76   \n",
       "4989                             694.0               15.52   \n",
       "4990                              14.7                9.46   \n",
       "4991                             244.9               38.68   \n",
       "4992                              84.0               39.27   \n",
       "4993                             132.8               28.13   \n",
       "4994                             382.7                5.16   \n",
       "4995                             532.5                4.51   \n",
       "4996                            5951.9                9.81   \n",
       "4997                             133.7               14.64   \n",
       "4998                             137.1                7.30   \n",
       "4999                              44.3               -0.28   \n",
       "\n",
       "      Tangible Book Value  Tangible Book Value Per Share  Total Debt  \\\n",
       "0                   718.3                           5.31         1.4   \n",
       "1                  7442.4                          34.29      8507.2   \n",
       "2                 11537.0                          18.84      2643.0   \n",
       "3                   263.5                          13.58        71.2   \n",
       "4                   457.6                           3.23       786.6   \n",
       "5                   684.7                          11.64      2247.1   \n",
       "6                  9386.2                         132.93      7039.9   \n",
       "7                  3442.0                           6.14      5195.0   \n",
       "8                 -3274.0                         -10.53      2935.0   \n",
       "9                 -5059.2                         -44.48      5959.9   \n",
       "10                -9511.0                          -5.56      6813.0   \n",
       "11                 3695.9                          49.66      2763.6   \n",
       "12                12430.0                          43.55      4737.0   \n",
       "13                 3292.0                          12.94      2461.0   \n",
       "14                 9864.0                          60.55       885.0   \n",
       "15                -2585.9                          -4.71      4220.8   \n",
       "16                  841.0                          24.26       562.4   \n",
       "17                  159.8                           3.52       395.4   \n",
       "18                   27.4                           0.10      1600.6   \n",
       "19                   93.7                           8.85        84.6   \n",
       "20                 1774.2                          29.17         0.0   \n",
       "21                32545.0                          68.09     37775.0   \n",
       "22               -13396.0                          -7.76     18545.0   \n",
       "23                 -512.9                          -2.99       787.6   \n",
       "24                 -330.3                          -4.05       693.3   \n",
       "25                 1264.1                           6.65     13616.5   \n",
       "26                 4197.3                          15.34      2277.8   \n",
       "27                -1534.0                         -11.93      2191.0   \n",
       "28                  451.7                          12.01         0.0   \n",
       "29                 3686.3                           0.06      4307.8   \n",
       "...                   ...                            ...         ...   \n",
       "4970                818.5                           4.54        74.7   \n",
       "4971              -2263.4                          -1.74      6864.1   \n",
       "4972              -1018.0                          -1.61     30309.1   \n",
       "4973                 31.4                           1.09         0.0   \n",
       "4974                -90.0                          -0.62      3149.6   \n",
       "4975                997.2                           7.20       880.5   \n",
       "4976                478.3                          34.16       726.8   \n",
       "4977              24126.0                          34.27     40718.0   \n",
       "4978              -2393.7                          -8.47      3521.2   \n",
       "4979                630.9                          10.08         0.0   \n",
       "4980                644.0                           3.60       223.8   \n",
       "4981               1630.9                          15.07         0.0   \n",
       "4982              61627.1                          96.00     55134.5   \n",
       "4983              -2428.3                          -4.66      8377.0   \n",
       "4984               4566.2                           3.05       549.6   \n",
       "4985               7599.0                          52.44      2741.0   \n",
       "4986               1860.5                           9.71         0.0   \n",
       "4987              29118.0                          62.78     16022.0   \n",
       "4988                900.0                          19.94         0.0   \n",
       "4989               6806.0                           9.82     21375.0   \n",
       "4990                134.3                           9.14         5.2   \n",
       "4991               6820.8                          27.86     11903.3   \n",
       "4992               1488.4                          17.70      1126.9   \n",
       "4993               3334.8                          24.84      1219.9   \n",
       "4994              -5579.0                         -14.57     10162.0   \n",
       "4995               1630.1                           3.06       350.0   \n",
       "4996             -47577.0                          -7.84     42234.0   \n",
       "4997                707.4                           5.29      1921.0   \n",
       "4998                961.4                           7.01       729.1   \n",
       "4999                -12.3                          -0.28       581.5   \n",
       "\n",
       "      Net Debt   Price  \n",
       "0       -274.3   41.99  \n",
       "1       8245.0   24.77  \n",
       "2      -8254.0  236.43  \n",
       "3       -137.4   26.00  \n",
       "4        246.6   34.17  \n",
       "5       1972.9  232.25  \n",
       "6       5790.9   20.15  \n",
       "7       2290.0   26.88  \n",
       "8       2847.0   37.27  \n",
       "9       5858.6  122.63  \n",
       "10       525.0   14.49  \n",
       "11      2678.7  275.90  \n",
       "12      1829.0  144.16  \n",
       "13      -764.0   67.50  \n",
       "14       118.0  105.15  \n",
       "15      2036.1   17.25  \n",
       "16       538.9   78.82  \n",
       "17       148.1   22.64  \n",
       "18       350.6   46.71  \n",
       "19        75.4   36.83  \n",
       "20      -397.4  203.35  \n",
       "21     37137.0  173.82  \n",
       "22     15995.0   78.48  \n",
       "23       713.3   37.78  \n",
       "24       544.6   15.63  \n",
       "25     13522.9  169.16  \n",
       "26      1826.6   11.53  \n",
       "27      1809.0  104.02  \n",
       "28      -258.3  201.75  \n",
       "29      1514.7    8.21  \n",
       "...        ...     ...  \n",
       "4970    -378.5   22.92  \n",
       "4971    6817.8   53.55  \n",
       "4972   21895.9   22.74  \n",
       "4973      -8.9    9.86  \n",
       "4974    2816.1   96.02  \n",
       "4975     319.6   19.32  \n",
       "4976     564.0   40.48  \n",
       "4977   38959.0   63.80  \n",
       "4978    1584.0   61.60  \n",
       "4979   -1016.9  120.56  \n",
       "4980    -318.1   28.20  \n",
       "4981     -91.4   78.88  \n",
       "4982   51796.1   14.75  \n",
       "4983    7824.7   68.29  \n",
       "4984   -1487.4   25.36  \n",
       "4985    2688.0  132.60  \n",
       "4986    -967.4   44.61  \n",
       "4987   15294.0  146.13  \n",
       "4988    -491.7  285.59  \n",
       "4989   20890.0   30.95  \n",
       "4990     -37.0   14.10  \n",
       "4991    9868.1   14.12  \n",
       "4992     915.4   39.83  \n",
       "4993    1183.0   52.10  \n",
       "4994    9877.0   59.00  \n",
       "4995    -168.4   11.48  \n",
       "4996   24358.0   32.48  \n",
       "4997    1856.8   49.01  \n",
       "4998     389.1    8.07  \n",
       "4999     377.9   34.69  \n",
       "\n",
       "[5000 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('BS_data.csv')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Assets\n",
      "Done\n",
      "Total Liabilities\n",
      "Done\n",
      "Total Equity\n",
      "Done\n",
      "Total Shares Out. on Filing Date\n",
      "Done\n",
      "Book Value / Share\n",
      "Done\n",
      "Tangible Book Value\n",
      "Done\n",
      "Tangible Book Value Per Share\n",
      "Done\n",
      "Total Debt\n",
      "Done\n",
      "Net Debt\n",
      "Done\n",
      "X: [[1.63843386e-03 6.82611560e-04 2.81693214e-02 ... 1.34060792e-03\n",
      "  2.92521072e-06 1.85568632e-01]\n",
      " [2.19349988e-02 1.36816489e-02 4.51864494e-02 ... 1.49174313e-03\n",
      "  1.77752519e-02 2.00645972e-01]\n",
      " [1.91761262e-02 6.13437854e-03 5.38134120e-02 ... 1.41116898e-03\n",
      "  5.52237995e-03 1.71446269e-01]\n",
      " ...\n",
      " [6.79067888e-03 4.97604015e-03 3.06086506e-02 ... 1.34050362e-03\n",
      "  4.01380699e-03 1.89340224e-01]\n",
      " [2.35835177e-03 1.36510305e-03 2.83540777e-02 ... 1.34947368e-03\n",
      "  1.52340795e-03 1.86742708e-01]\n",
      " [7.21358632e-04 8.08087212e-04 2.60515545e-02 ... 1.31145520e-03\n",
      "  1.21500717e-03 1.86722887e-01]]\n",
      "\n",
      "\n",
      "Type X: <class 'numpy.ndarray'>\n",
      "Length of Individual X_train Vector: 9\n",
      "Total Number of Training instances: 5000\n",
      "\n",
      "\n",
      "[ 41.99  24.77 236.43 ...  49.01   8.07  34.69]\n",
      "\n",
      "\n",
      "Type y: <class 'numpy.ndarray'>\n",
      "Length of Individual y_train vector 41.99\n",
      "Total number of y values 5000\n"
     ]
    }
   ],
   "source": [
    "prices = data['Price'] \n",
    "data = data.drop(['Company', 'Time', 'Price'], axis = 1)\n",
    "\n",
    "col_list = []\n",
    "for col in data.columns:\n",
    "    col_list.append(col)\n",
    "    \n",
    "for col in col_list:\n",
    "    print(col)\n",
    "    data[col] = data[col].astype(float) # Converting columns to floats\n",
    "    print(\"Done\")\n",
    "\n",
    "# Normalising the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "scaled_values = scaler.fit_transform(data) \n",
    "data.loc[:,:] = scaled_values\n",
    "\n",
    "data.insert(data.shape[1], 'Price', prices)\n",
    "\n",
    "# Converting Data to Numpy Arrays\n",
    "NpMatrix = data.to_numpy(dtype = None, copy = False)\n",
    "X = NpMatrix[:,0:9] # Parameters\n",
    "y = NpMatrix[:,9] # Price\n",
    "print(\"X:\", X)\n",
    "print(\"\\n\")\n",
    "print(\"Type X:\", type(X))\n",
    "print(\"Length of Individual X_train Vector:\", len(X[1]))\n",
    "print(\"Total Number of Training instances:\", len(X))\n",
    "print(\"\\n\")\n",
    "print(y)\n",
    "print(\"\\n\")\n",
    "print(\"Type y:\", type(y))\n",
    "print(\"Length of Individual y_train vector\", y[0])\n",
    "print(\"Total number of y values\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 190\n",
      "Trainable params: 190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/1000\n",
      "3200/3200 [==============================] - 1s 224us/sample - loss: 22066.1958 - mae: 72.8567 - mse: 22066.1973 - val_loss: 38171.3871 - val_mae: 76.1466 - val_mse: 38171.3867\n",
      "Epoch 2/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 21999.7988 - mae: 72.4060 - mse: 21999.8008 - val_loss: 38066.3555 - val_mae: 75.4528 - val_mse: 38066.3555\n",
      "Epoch 3/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 21844.0959 - mae: 71.3221 - mse: 21844.0977 - val_loss: 37830.1005 - val_mae: 73.8780 - val_mse: 37830.1016\n",
      "Epoch 4/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 21529.7862 - mae: 69.1596 - mse: 21529.7871 - val_loss: 37410.6884 - val_mae: 71.0624 - val_mse: 37410.6875\n",
      "Epoch 5/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 21016.1492 - mae: 65.5467 - mse: 21016.1523 - val_loss: 36702.2678 - val_mae: 66.3376 - val_mse: 36702.2656\n",
      "Epoch 6/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 20231.9867 - mae: 60.1960 - mse: 20231.9883 - val_loss: 35795.1837 - val_mae: 60.5371 - val_mse: 35795.1797\n",
      "Epoch 7/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 19388.8539 - mae: 54.6556 - mse: 19388.8516 - val_loss: 34828.2764 - val_mae: 54.9208 - val_mse: 34828.2734\n",
      "Epoch 8/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 18526.2679 - mae: 50.5176 - mse: 18526.2656 - val_loss: 33958.8778 - val_mae: 50.8549 - val_mse: 33958.8789\n",
      "Epoch 9/1000\n",
      "3200/3200 [==============================] - 0s 71us/sample - loss: 17802.0271 - mae: 48.4217 - mse: 17802.0254 - val_loss: 33301.3310 - val_mae: 49.3873 - val_mse: 33301.3320\n",
      "Epoch 10/1000\n",
      "3200/3200 [==============================] - 0s 52us/sample - loss: 17448.3425 - mae: 49.0872 - mse: 17448.3457 - val_loss: 32916.3724 - val_mae: 49.9893 - val_mse: 32916.3750\n",
      "Epoch 11/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 17200.6877 - mae: 49.9085 - mse: 17200.6836 - val_loss: 32693.0845 - val_mae: 51.2864 - val_mse: 32693.0879\n",
      "Epoch 12/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 17038.1942 - mae: 50.8929 - mse: 17038.1934 - val_loss: 32592.2072 - val_mae: 52.3667 - val_mse: 32592.2109\n",
      "Epoch 13/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 17021.6770 - mae: 52.3010 - mse: 17021.6758 - val_loss: 32534.3466 - val_mae: 53.2018 - val_mse: 32534.3477\n",
      "Epoch 14/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16931.9773 - mae: 52.2511 - mse: 16931.9766 - val_loss: 32507.2835 - val_mae: 53.6038 - val_mse: 32507.2832\n",
      "Epoch 15/1000\n",
      "3200/3200 [==============================] - 0s 49us/sample - loss: 17010.2762 - mae: 52.6688 - mse: 17010.2734 - val_loss: 32488.7322 - val_mae: 53.8517 - val_mse: 32488.7305\n",
      "Epoch 16/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 16978.2617 - mae: 52.7968 - mse: 16978.2617 - val_loss: 32481.3945 - val_mae: 53.8128 - val_mse: 32481.3945\n",
      "Epoch 17/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 17049.7174 - mae: 52.9201 - mse: 17049.7168 - val_loss: 32468.8914 - val_mae: 53.9556 - val_mse: 32468.8906\n",
      "Epoch 18/1000\n",
      "3200/3200 [==============================] - 0s 48us/sample - loss: 16946.2503 - mae: 53.1806 - mse: 16946.2500 - val_loss: 32456.3532 - val_mae: 54.1435 - val_mse: 32456.3516\n",
      "Epoch 19/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16964.7773 - mae: 53.0474 - mse: 16964.7734 - val_loss: 32448.1989 - val_mae: 54.1795 - val_mse: 32448.1953\n",
      "Epoch 20/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16993.4471 - mae: 53.4623 - mse: 16993.4473 - val_loss: 32442.6991 - val_mae: 54.1388 - val_mse: 32442.6973\n",
      "Epoch 21/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16907.2650 - mae: 53.0790 - mse: 16907.2637 - val_loss: 32442.0395 - val_mae: 53.9274 - val_mse: 32442.0391\n",
      "Epoch 22/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16886.0543 - mae: 53.2073 - mse: 16886.0527 - val_loss: 32431.0603 - val_mae: 54.1039 - val_mse: 32431.0605\n",
      "Epoch 23/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 17041.2528 - mae: 53.2418 - mse: 17041.2539 - val_loss: 32427.1317 - val_mae: 54.0495 - val_mse: 32427.1309\n",
      "Epoch 24/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16783.1078 - mae: 52.9490 - mse: 16783.1055 - val_loss: 32415.6640 - val_mae: 54.2734 - val_mse: 32415.6641\n",
      "Epoch 25/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16976.9353 - mae: 53.4884 - mse: 16976.9336 - val_loss: 32417.4866 - val_mae: 54.0115 - val_mse: 32417.4883\n",
      "Epoch 26/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16888.6110 - mae: 52.7250 - mse: 16888.6113 - val_loss: 32410.7070 - val_mae: 54.0953 - val_mse: 32410.7051\n",
      "Epoch 27/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16897.8376 - mae: 52.9990 - mse: 16897.8379 - val_loss: 32406.6234 - val_mae: 54.0753 - val_mse: 32406.6230\n",
      "Epoch 28/1000\n",
      "3200/3200 [==============================] - 0s 46us/sample - loss: 17006.1569 - mae: 53.5727 - mse: 17006.1562 - val_loss: 32400.8148 - val_mae: 54.1264 - val_mse: 32400.8145\n",
      "Epoch 29/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16962.8392 - mae: 52.9167 - mse: 16962.8398 - val_loss: 32404.8075 - val_mae: 53.8423 - val_mse: 32404.8066\n",
      "Epoch 30/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 17019.1555 - mae: 53.1696 - mse: 17019.1582 - val_loss: 32407.5478 - val_mae: 53.6251 - val_mse: 32407.5508\n",
      "Epoch 31/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16948.5033 - mae: 52.5473 - mse: 16948.5059 - val_loss: 32396.4317 - val_mae: 53.8491 - val_mse: 32396.4316\n",
      "Epoch 32/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16932.9131 - mae: 53.4135 - mse: 16932.9141 - val_loss: 32386.1167 - val_mae: 54.0748 - val_mse: 32386.1172\n",
      "Epoch 33/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16985.7660 - mae: 53.4208 - mse: 16985.7617 - val_loss: 32388.2858 - val_mae: 53.8667 - val_mse: 32388.2871\n",
      "Epoch 34/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16937.6064 - mae: 52.7601 - mse: 16937.6055 - val_loss: 32395.6626 - val_mae: 53.5570 - val_mse: 32395.6621\n",
      "Epoch 35/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16969.3223 - mae: 53.2005 - mse: 16969.3242 - val_loss: 32376.5828 - val_mae: 54.0402 - val_mse: 32376.5801\n",
      "Epoch 36/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16919.9672 - mae: 52.9917 - mse: 16919.9707 - val_loss: 32377.4423 - val_mae: 53.9084 - val_mse: 32377.4434\n",
      "Epoch 37/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16863.3124 - mae: 52.9886 - mse: 16863.3105 - val_loss: 32368.3903 - val_mae: 54.1028 - val_mse: 32368.3906\n",
      "Epoch 38/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16931.8532 - mae: 53.1970 - mse: 16931.8516 - val_loss: 32372.4258 - val_mae: 53.8559 - val_mse: 32372.4258\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16887.0900 - mae: 52.7672 - mse: 16887.0879 - val_loss: 32370.7820 - val_mae: 53.8115 - val_mse: 32370.7793\n",
      "Epoch 40/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16831.4891 - mae: 53.2201 - mse: 16831.4902 - val_loss: 32358.1730 - val_mae: 54.1433 - val_mse: 32358.1758\n",
      "Epoch 41/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16862.7754 - mae: 53.0292 - mse: 16862.7754 - val_loss: 32358.4178 - val_mae: 54.0432 - val_mse: 32358.4180\n",
      "Epoch 42/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16879.1730 - mae: 53.1601 - mse: 16879.1719 - val_loss: 32355.7137 - val_mae: 54.0327 - val_mse: 32355.7129\n",
      "Epoch 43/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16904.2716 - mae: 52.7845 - mse: 16904.2715 - val_loss: 32350.8076 - val_mae: 54.1188 - val_mse: 32350.8047\n",
      "Epoch 44/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16818.7184 - mae: 53.0561 - mse: 16818.7188 - val_loss: 32349.9841 - val_mae: 54.0507 - val_mse: 32349.9824\n",
      "Epoch 45/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16809.8784 - mae: 53.4109 - mse: 16809.8770 - val_loss: 32337.9876 - val_mae: 54.4287 - val_mse: 32337.9883\n",
      "Epoch 46/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16914.9986 - mae: 52.8280 - mse: 16914.9961 - val_loss: 32345.0000 - val_mae: 54.0405 - val_mse: 32345.0020\n",
      "Epoch 47/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16876.8694 - mae: 52.9220 - mse: 16876.8691 - val_loss: 32340.7683 - val_mae: 54.1111 - val_mse: 32340.7695\n",
      "Epoch 48/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 16855.5061 - mae: 52.7876 - mse: 16855.5059 - val_loss: 32339.3646 - val_mae: 54.0899 - val_mse: 32339.3652\n",
      "Epoch 49/1000\n",
      "3200/3200 [==============================] - 0s 46us/sample - loss: 16841.6378 - mae: 53.1489 - mse: 16841.6387 - val_loss: 32337.1609 - val_mae: 54.0957 - val_mse: 32337.1602\n",
      "Epoch 50/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16757.1719 - mae: 52.7977 - mse: 16757.1719 - val_loss: 32328.5928 - val_mae: 54.3630 - val_mse: 32328.5898\n",
      "Epoch 51/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16926.1945 - mae: 53.5425 - mse: 16926.1953 - val_loss: 32335.1213 - val_mae: 54.0095 - val_mse: 32335.1230\n",
      "Epoch 52/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16904.4245 - mae: 53.2055 - mse: 16904.4258 - val_loss: 32333.3344 - val_mae: 53.9944 - val_mse: 32333.3359\n",
      "Epoch 53/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16985.4174 - mae: 52.9958 - mse: 16985.4180 - val_loss: 32338.4025 - val_mae: 53.7637 - val_mse: 32338.4043\n",
      "Epoch 54/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16914.3179 - mae: 52.9712 - mse: 16914.3184 - val_loss: 32344.2369 - val_mae: 53.5273 - val_mse: 32344.2344\n",
      "Epoch 55/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16881.9013 - mae: 53.2710 - mse: 16881.9023 - val_loss: 32332.1067 - val_mae: 53.8312 - val_mse: 32332.1055\n",
      "Epoch 56/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16860.0103 - mae: 53.0226 - mse: 16860.0098 - val_loss: 32328.2905 - val_mae: 53.9001 - val_mse: 32328.2871\n",
      "Epoch 57/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16854.0110 - mae: 52.6805 - mse: 16854.0098 - val_loss: 32333.4783 - val_mae: 53.6785 - val_mse: 32333.4766\n",
      "Epoch 58/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16792.8581 - mae: 53.6016 - mse: 16792.8594 - val_loss: 32320.7626 - val_mae: 54.0501 - val_mse: 32320.7656\n",
      "Epoch 59/1000\n",
      "3200/3200 [==============================] - 0s 47us/sample - loss: 16811.2977 - mae: 53.0857 - mse: 16811.2930 - val_loss: 32322.7683 - val_mae: 53.9146 - val_mse: 32322.7676\n",
      "Epoch 60/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16891.9516 - mae: 53.1838 - mse: 16891.9473 - val_loss: 32320.7414 - val_mae: 53.9290 - val_mse: 32320.7422\n",
      "Epoch 61/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16793.4534 - mae: 52.8726 - mse: 16793.4570 - val_loss: 32322.7475 - val_mae: 53.8017 - val_mse: 32322.7500\n",
      "Epoch 62/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16842.0922 - mae: 53.0402 - mse: 16842.0898 - val_loss: 32323.1487 - val_mae: 53.7324 - val_mse: 32323.1504\n",
      "Epoch 63/1000\n",
      "3200/3200 [==============================] - 0s 45us/sample - loss: 16915.8341 - mae: 52.9816 - mse: 16915.8340 - val_loss: 32322.6290 - val_mae: 53.7006 - val_mse: 32322.6270\n",
      "Epoch 64/1000\n",
      "3200/3200 [==============================] - 0s 48us/sample - loss: 16801.0122 - mae: 52.7414 - mse: 16801.0137 - val_loss: 32316.7642 - val_mae: 53.8387 - val_mse: 32316.7617\n",
      "Epoch 65/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16764.8146 - mae: 52.5973 - mse: 16764.8145 - val_loss: 32316.2869 - val_mae: 53.8040 - val_mse: 32316.2852\n",
      "Epoch 66/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16825.3169 - mae: 52.8770 - mse: 16825.3203 - val_loss: 32314.4722 - val_mae: 53.8078 - val_mse: 32314.4727\n",
      "Epoch 67/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16742.7660 - mae: 52.7007 - mse: 16742.7656 - val_loss: 32307.9752 - val_mae: 53.9842 - val_mse: 32307.9766\n",
      "Epoch 68/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16858.5542 - mae: 52.7757 - mse: 16858.5547 - val_loss: 32308.0436 - val_mae: 53.9310 - val_mse: 32308.0430\n",
      "Epoch 69/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16900.7569 - mae: 53.2176 - mse: 16900.7559 - val_loss: 32305.6820 - val_mae: 53.9506 - val_mse: 32305.6797\n",
      "Epoch 70/1000\n",
      "3200/3200 [==============================] - 0s 43us/sample - loss: 16782.8439 - mae: 53.0797 - mse: 16782.8438 - val_loss: 32308.7078 - val_mae: 53.7908 - val_mse: 32308.7070\n",
      "Epoch 71/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16853.2364 - mae: 53.2825 - mse: 16853.2383 - val_loss: 32307.0658 - val_mae: 53.7973 - val_mse: 32307.0645\n",
      "Epoch 72/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16784.6405 - mae: 53.0808 - mse: 16784.6406 - val_loss: 32305.5319 - val_mae: 53.7964 - val_mse: 32305.5293\n",
      "Epoch 73/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16767.1317 - mae: 52.2951 - mse: 16767.1309 - val_loss: 32303.9136 - val_mae: 53.8008 - val_mse: 32303.9141\n",
      "Epoch 74/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16808.5072 - mae: 53.1477 - mse: 16808.5078 - val_loss: 32299.4700 - val_mae: 53.9116 - val_mse: 32299.4727\n",
      "Epoch 75/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16944.1250 - mae: 52.5689 - mse: 16944.1250 - val_loss: 32307.6369 - val_mae: 53.5932 - val_mse: 32307.6367\n",
      "Epoch 76/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16810.8206 - mae: 53.0775 - mse: 16810.8184 - val_loss: 32302.6126 - val_mae: 53.7117 - val_mse: 32302.6133\n",
      "Epoch 77/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16839.9048 - mae: 52.9462 - mse: 16839.9023 - val_loss: 32294.4193 - val_mae: 53.9581 - val_mse: 32294.4199\n",
      "Epoch 78/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16776.9547 - mae: 53.2700 - mse: 16776.9531 - val_loss: 32296.8740 - val_mae: 53.8132 - val_mse: 32296.8750\n",
      "Epoch 79/1000\n",
      "3200/3200 [==============================] - 0s 44us/sample - loss: 16816.4198 - mae: 52.7678 - mse: 16816.4180 - val_loss: 32300.9493 - val_mae: 53.6278 - val_mse: 32300.9531\n",
      "Epoch 80/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16839.0669 - mae: 52.7821 - mse: 16839.0664 - val_loss: 32298.6487 - val_mae: 53.6621 - val_mse: 32298.6484\n",
      "Epoch 81/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16740.6526 - mae: 52.7782 - mse: 16740.6543 - val_loss: 32293.0723 - val_mae: 53.8115 - val_mse: 32293.0723\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16838.2433 - mae: 52.8819 - mse: 16838.2422 - val_loss: 32291.2382 - val_mae: 53.8296 - val_mse: 32291.2402\n",
      "Epoch 83/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16886.2184 - mae: 53.1885 - mse: 16886.2188 - val_loss: 32294.6143 - val_mae: 53.6698 - val_mse: 32294.6152\n",
      "Epoch 84/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16718.9711 - mae: 52.6023 - mse: 16718.9707 - val_loss: 32291.3988 - val_mae: 53.7334 - val_mse: 32291.3984\n",
      "Epoch 85/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16832.0164 - mae: 52.8226 - mse: 16832.0176 - val_loss: 32287.5058 - val_mae: 53.8301 - val_mse: 32287.5059\n",
      "Epoch 86/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16849.4380 - mae: 53.1632 - mse: 16849.4375 - val_loss: 32290.8914 - val_mae: 53.6707 - val_mse: 32290.8906\n",
      "Epoch 87/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16791.1382 - mae: 53.1234 - mse: 16791.1406 - val_loss: 32289.1563 - val_mae: 53.6842 - val_mse: 32289.1543\n",
      "Epoch 88/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16837.8134 - mae: 52.5029 - mse: 16837.8105 - val_loss: 32288.1853 - val_mae: 53.6776 - val_mse: 32288.1855\n",
      "Epoch 89/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16705.5652 - mae: 52.9567 - mse: 16705.5645 - val_loss: 32282.1952 - val_mae: 53.8395 - val_mse: 32282.1953\n",
      "Epoch 90/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16831.7173 - mae: 53.0123 - mse: 16831.7168 - val_loss: 32285.3643 - val_mae: 53.6824 - val_mse: 32285.3633\n",
      "Epoch 91/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16798.1453 - mae: 52.6970 - mse: 16798.1445 - val_loss: 32280.2771 - val_mae: 53.8229 - val_mse: 32280.2773\n",
      "Epoch 92/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16801.5737 - mae: 52.8091 - mse: 16801.5742 - val_loss: 32278.2852 - val_mae: 53.8547 - val_mse: 32278.2852\n",
      "Epoch 93/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16742.4682 - mae: 53.0338 - mse: 16742.4707 - val_loss: 32276.0779 - val_mae: 53.8919 - val_mse: 32276.0781\n",
      "Epoch 94/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16819.1122 - mae: 53.1979 - mse: 16819.1113 - val_loss: 32278.1336 - val_mae: 53.7660 - val_mse: 32278.1348\n",
      "Epoch 95/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16728.8684 - mae: 52.6084 - mse: 16728.8652 - val_loss: 32279.4486 - val_mae: 53.6787 - val_mse: 32279.4492\n",
      "Epoch 96/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16732.9386 - mae: 52.5773 - mse: 16732.9355 - val_loss: 32277.0491 - val_mae: 53.7222 - val_mse: 32277.0469\n",
      "Epoch 97/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16818.4341 - mae: 52.9574 - mse: 16818.4355 - val_loss: 32274.5228 - val_mae: 53.7685 - val_mse: 32274.5254\n",
      "Epoch 98/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16757.7761 - mae: 52.6716 - mse: 16757.7773 - val_loss: 32271.0010 - val_mae: 53.8567 - val_mse: 32271.0000\n",
      "Epoch 99/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16909.6556 - mae: 53.1913 - mse: 16909.6582 - val_loss: 32277.5331 - val_mae: 53.5820 - val_mse: 32277.5352\n",
      "Epoch 100/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16779.6350 - mae: 53.1029 - mse: 16779.6348 - val_loss: 32269.1049 - val_mae: 53.8483 - val_mse: 32269.1016\n",
      "Epoch 101/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16835.0658 - mae: 52.6608 - mse: 16835.0664 - val_loss: 32274.7968 - val_mae: 53.5998 - val_mse: 32274.7969\n",
      "Epoch 102/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16770.7067 - mae: 52.7380 - mse: 16770.7070 - val_loss: 32271.5564 - val_mae: 53.6780 - val_mse: 32271.5547\n",
      "Epoch 103/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16888.7775 - mae: 52.8921 - mse: 16888.7793 - val_loss: 32271.3074 - val_mae: 53.6483 - val_mse: 32271.3047\n",
      "Epoch 104/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16745.9470 - mae: 52.5492 - mse: 16745.9434 - val_loss: 32269.0398 - val_mae: 53.6903 - val_mse: 32269.0391\n",
      "Epoch 105/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16854.6010 - mae: 52.5591 - mse: 16854.6016 - val_loss: 32272.9433 - val_mae: 53.5203 - val_mse: 32272.9453\n",
      "Epoch 106/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16750.6807 - mae: 52.7752 - mse: 16750.6816 - val_loss: 32261.8598 - val_mae: 53.8932 - val_mse: 32261.8594\n",
      "Epoch 107/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16797.4993 - mae: 52.9414 - mse: 16797.4980 - val_loss: 32267.3423 - val_mae: 53.6417 - val_mse: 32267.3398\n",
      "Epoch 108/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16772.5106 - mae: 53.1210 - mse: 16772.5117 - val_loss: 32265.2307 - val_mae: 53.6778 - val_mse: 32265.2305\n",
      "Epoch 109/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16697.2929 - mae: 52.7511 - mse: 16697.2949 - val_loss: 32267.0567 - val_mae: 53.5785 - val_mse: 32267.0566\n",
      "Epoch 110/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16674.1700 - mae: 52.7833 - mse: 16674.1699 - val_loss: 32256.4087 - val_mae: 53.9453 - val_mse: 32256.4102\n",
      "Epoch 111/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16832.8276 - mae: 53.0323 - mse: 16832.8281 - val_loss: 32263.9967 - val_mae: 53.6183 - val_mse: 32263.9980\n",
      "Epoch 112/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16743.2848 - mae: 52.6268 - mse: 16743.2871 - val_loss: 32259.3563 - val_mae: 53.7507 - val_mse: 32259.3574\n",
      "Epoch 113/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16809.0812 - mae: 52.9971 - mse: 16809.0820 - val_loss: 32266.5360 - val_mae: 53.4667 - val_mse: 32266.5352\n",
      "Epoch 114/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16811.2763 - mae: 52.7018 - mse: 16811.2754 - val_loss: 32260.0958 - val_mae: 53.6522 - val_mse: 32260.0957\n",
      "Epoch 115/1000\n",
      "3200/3200 [==============================] - 0s 45us/sample - loss: 16756.6060 - mae: 52.3293 - mse: 16756.6055 - val_loss: 32260.3984 - val_mae: 53.6092 - val_mse: 32260.4004\n",
      "Epoch 116/1000\n",
      "3200/3200 [==============================] - 0s 44us/sample - loss: 16774.0159 - mae: 52.7014 - mse: 16774.0176 - val_loss: 32255.1315 - val_mae: 53.7689 - val_mse: 32255.1328\n",
      "Epoch 117/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16789.1607 - mae: 52.5558 - mse: 16789.1621 - val_loss: 32257.1804 - val_mae: 53.6587 - val_mse: 32257.1816\n",
      "Epoch 118/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16824.8470 - mae: 52.9438 - mse: 16824.8457 - val_loss: 32255.5261 - val_mae: 53.6852 - val_mse: 32255.5254\n",
      "Epoch 119/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16765.7930 - mae: 52.4787 - mse: 16765.7910 - val_loss: 32261.1811 - val_mae: 53.4587 - val_mse: 32261.1816\n",
      "Epoch 120/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16745.2931 - mae: 52.9427 - mse: 16745.2930 - val_loss: 32250.6126 - val_mae: 53.7953 - val_mse: 32250.6133\n",
      "Epoch 121/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16752.3943 - mae: 52.8212 - mse: 16752.3945 - val_loss: 32249.0404 - val_mae: 53.8227 - val_mse: 32249.0391\n",
      "Epoch 122/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 16810.8416 - mae: 52.7548 - mse: 16810.8418 - val_loss: 32247.7053 - val_mae: 53.8423 - val_mse: 32247.7051\n",
      "Epoch 123/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16740.2883 - mae: 52.6196 - mse: 16740.2871 - val_loss: 32253.7044 - val_mae: 53.5795 - val_mse: 32253.7051\n",
      "Epoch 124/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16731.2105 - mae: 52.6857 - mse: 16731.2070 - val_loss: 32246.2164 - val_mae: 53.8207 - val_mse: 32246.2207\n",
      "Epoch 125/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16718.0477 - mae: 52.7248 - mse: 16718.0527 - val_loss: 32244.5267 - val_mae: 53.8449 - val_mse: 32244.5273\n",
      "Epoch 126/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16755.0361 - mae: 52.9572 - mse: 16755.0391 - val_loss: 32246.0643 - val_mae: 53.7457 - val_mse: 32246.0645\n",
      "Epoch 127/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16785.5255 - mae: 52.3143 - mse: 16785.5293 - val_loss: 32256.0881 - val_mae: 53.3600 - val_mse: 32256.0859\n",
      "Epoch 128/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16687.5469 - mae: 52.4815 - mse: 16687.5469 - val_loss: 32245.7724 - val_mae: 53.6821 - val_mse: 32245.7734\n",
      "Epoch 129/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16772.9902 - mae: 52.6836 - mse: 16772.9902 - val_loss: 32248.0324 - val_mae: 53.5670 - val_mse: 32248.0332\n",
      "Epoch 130/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16763.7577 - mae: 52.6901 - mse: 16763.7520 - val_loss: 32245.0703 - val_mae: 53.6324 - val_mse: 32245.0703\n",
      "Epoch 131/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16709.8642 - mae: 52.4643 - mse: 16709.8672 - val_loss: 32246.8691 - val_mae: 53.5342 - val_mse: 32246.8691\n",
      "Epoch 132/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16705.6251 - mae: 52.5893 - mse: 16705.6289 - val_loss: 32237.5995 - val_mae: 53.8419 - val_mse: 32237.5996\n",
      "Epoch 133/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16801.0241 - mae: 53.2707 - mse: 16801.0215 - val_loss: 32244.9234 - val_mae: 53.5310 - val_mse: 32244.9258\n",
      "Epoch 134/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16662.1622 - mae: 52.1821 - mse: 16662.1602 - val_loss: 32241.5740 - val_mae: 53.6180 - val_mse: 32241.5742\n",
      "Epoch 135/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16761.4349 - mae: 53.1233 - mse: 16761.4355 - val_loss: 32239.9139 - val_mae: 53.6415 - val_mse: 32239.9121\n",
      "Epoch 136/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16699.5930 - mae: 52.7622 - mse: 16699.5898 - val_loss: 32245.4892 - val_mae: 53.4062 - val_mse: 32245.4902\n",
      "Epoch 137/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16693.6181 - mae: 52.7232 - mse: 16693.6211 - val_loss: 32239.1488 - val_mae: 53.5920 - val_mse: 32239.1484\n",
      "Epoch 138/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16697.1871 - mae: 52.2868 - mse: 16697.1875 - val_loss: 32232.7684 - val_mae: 53.7983 - val_mse: 32232.7676\n",
      "Epoch 139/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16772.8044 - mae: 52.7407 - mse: 16772.8008 - val_loss: 32238.1691 - val_mae: 53.5502 - val_mse: 32238.1680\n",
      "Epoch 140/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16839.6513 - mae: 52.8257 - mse: 16839.6484 - val_loss: 32242.0575 - val_mae: 53.3885 - val_mse: 32242.0605\n",
      "Epoch 141/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16677.0885 - mae: 52.3454 - mse: 16677.0879 - val_loss: 32236.9379 - val_mae: 53.5261 - val_mse: 32236.9375\n",
      "Epoch 142/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16722.3423 - mae: 52.6511 - mse: 16722.3418 - val_loss: 32229.3646 - val_mae: 53.7708 - val_mse: 32229.3633\n",
      "Epoch 143/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16767.9864 - mae: 52.8582 - mse: 16767.9883 - val_loss: 32234.7667 - val_mae: 53.5301 - val_mse: 32234.7656\n",
      "Epoch 144/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16705.0544 - mae: 52.8142 - mse: 16705.0547 - val_loss: 32230.3516 - val_mae: 53.6579 - val_mse: 32230.3496\n",
      "Epoch 145/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16666.4574 - mae: 52.4559 - mse: 16666.4570 - val_loss: 32229.7171 - val_mae: 53.6420 - val_mse: 32229.7168\n",
      "Epoch 146/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16755.6265 - mae: 52.9095 - mse: 16755.6270 - val_loss: 32230.0609 - val_mae: 53.5918 - val_mse: 32230.0605\n",
      "Epoch 147/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16745.0192 - mae: 52.6817 - mse: 16745.0156 - val_loss: 32233.0769 - val_mae: 53.4453 - val_mse: 32233.0742\n",
      "Epoch 148/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16672.7737 - mae: 52.1506 - mse: 16672.7734 - val_loss: 32224.4726 - val_mae: 53.7307 - val_mse: 32224.4727\n",
      "Epoch 149/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16716.7303 - mae: 52.8787 - mse: 16716.7324 - val_loss: 32226.0593 - val_mae: 53.6334 - val_mse: 32226.0547\n",
      "Epoch 150/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16745.3600 - mae: 52.5892 - mse: 16745.3594 - val_loss: 32221.5779 - val_mae: 53.7685 - val_mse: 32221.5801\n",
      "Epoch 151/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16762.3414 - mae: 52.7819 - mse: 16762.3418 - val_loss: 32221.1003 - val_mae: 53.7515 - val_mse: 32221.0996\n",
      "Epoch 152/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16745.6836 - mae: 52.7926 - mse: 16745.6875 - val_loss: 32223.7500 - val_mae: 53.6074 - val_mse: 32223.7520\n",
      "Epoch 153/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16647.9441 - mae: 52.3300 - mse: 16647.9453 - val_loss: 32222.0733 - val_mae: 53.6308 - val_mse: 32222.0723\n",
      "Epoch 154/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16689.7017 - mae: 52.5785 - mse: 16689.7012 - val_loss: 32219.1273 - val_mae: 53.7060 - val_mse: 32219.1270\n",
      "Epoch 155/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16742.1360 - mae: 53.0044 - mse: 16742.1328 - val_loss: 32218.4773 - val_mae: 53.6902 - val_mse: 32218.4746\n",
      "Epoch 156/1000\n",
      "3200/3200 [==============================] - 0s 43us/sample - loss: 16684.0471 - mae: 52.6472 - mse: 16684.0469 - val_loss: 32222.7234 - val_mae: 53.4955 - val_mse: 32222.7246\n",
      "Epoch 157/1000\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 20684.5287 - mae: 55.4503 - mse: 20684.52 - 0s 30us/sample - loss: 16705.6727 - mae: 52.8253 - mse: 16705.6738 - val_loss: 32215.6971 - val_mae: 53.7195 - val_mse: 32215.6973\n",
      "Epoch 158/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16818.3167 - mae: 52.5922 - mse: 16818.3145 - val_loss: 32220.9980 - val_mae: 53.4828 - val_mse: 32220.9980\n",
      "Epoch 159/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16705.4029 - mae: 52.6169 - mse: 16705.4023 - val_loss: 32218.0147 - val_mae: 53.5515 - val_mse: 32218.0156\n",
      "Epoch 160/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16680.6394 - mae: 52.1559 - mse: 16680.6387 - val_loss: 32222.9503 - val_mae: 53.3431 - val_mse: 32222.9492\n",
      "Epoch 161/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16776.4631 - mae: 52.6135 - mse: 16776.4629 - val_loss: 32216.9338 - val_mae: 53.5114 - val_mse: 32216.9355\n",
      "Epoch 162/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16706.3022 - mae: 52.5758 - mse: 16706.3047 - val_loss: 32215.6853 - val_mae: 53.5201 - val_mse: 32215.6875\n",
      "Epoch 163/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16680.4735 - mae: 51.9077 - mse: 16680.4746 - val_loss: 32212.9709 - val_mae: 53.5852 - val_mse: 32212.9707\n",
      "Epoch 164/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16795.8371 - mae: 52.7404 - mse: 16795.8359 - val_loss: 32214.0380 - val_mae: 53.5094 - val_mse: 32214.0371\n",
      "Epoch 165/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16646.4110 - mae: 52.7172 - mse: 16646.4121 - val_loss: 32207.8247 - val_mae: 53.6986 - val_mse: 32207.8223\n",
      "Epoch 166/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16628.7095 - mae: 52.2259 - mse: 16628.7090 - val_loss: 32210.5673 - val_mae: 53.5546 - val_mse: 32210.5684\n",
      "Epoch 167/1000\n",
      "3200/3200 [==============================] - 0s 55us/sample - loss: 16624.8189 - mae: 52.6443 - mse: 16624.8203 - val_loss: 32204.3535 - val_mae: 53.7509 - val_mse: 32204.3496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 16701.4504 - mae: 52.5459 - mse: 16701.4492 - val_loss: 32202.4269 - val_mae: 53.7870 - val_mse: 32202.4277\n",
      "Epoch 169/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16678.7676 - mae: 52.5760 - mse: 16678.7656 - val_loss: 32203.4803 - val_mae: 53.6989 - val_mse: 32203.4805\n",
      "Epoch 170/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16722.2669 - mae: 52.7004 - mse: 16722.2676 - val_loss: 32204.3620 - val_mae: 53.6210 - val_mse: 32204.3633\n",
      "Epoch 171/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16783.4680 - mae: 52.6576 - mse: 16783.4668 - val_loss: 32209.5398 - val_mae: 53.3968 - val_mse: 32209.5391\n",
      "Epoch 172/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16672.9276 - mae: 52.1263 - mse: 16672.9297 - val_loss: 32202.4831 - val_mae: 53.6111 - val_mse: 32202.4844\n",
      "Epoch 173/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16682.2231 - mae: 52.7861 - mse: 16682.2227 - val_loss: 32197.7510 - val_mae: 53.7535 - val_mse: 32197.7500\n",
      "Epoch 174/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16724.9919 - mae: 52.9681 - mse: 16724.9902 - val_loss: 32207.8825 - val_mae: 53.3327 - val_mse: 32207.8828\n",
      "Epoch 175/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16611.4756 - mae: 52.1639 - mse: 16611.4766 - val_loss: 32206.1870 - val_mae: 53.3569 - val_mse: 32206.1895\n",
      "Epoch 176/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16749.1404 - mae: 52.1920 - mse: 16749.1406 - val_loss: 32205.0184 - val_mae: 53.3587 - val_mse: 32205.0195\n",
      "Epoch 177/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16746.5141 - mae: 52.4963 - mse: 16746.5117 - val_loss: 32197.6083 - val_mae: 53.5852 - val_mse: 32197.6074\n",
      "Epoch 178/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16651.3817 - mae: 52.4130 - mse: 16651.3809 - val_loss: 32196.5467 - val_mae: 53.5843 - val_mse: 32196.5449\n",
      "Epoch 179/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16596.2138 - mae: 52.1288 - mse: 16596.2148 - val_loss: 32201.3385 - val_mae: 53.3764 - val_mse: 32201.3398\n",
      "Epoch 180/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16708.4565 - mae: 53.0164 - mse: 16708.4551 - val_loss: 32193.4818 - val_mae: 53.6155 - val_mse: 32193.4824\n",
      "Epoch 181/1000\n",
      "3200/3200 [==============================] - 0s 30us/sample - loss: 16630.8165 - mae: 52.6874 - mse: 16630.8164 - val_loss: 32194.2726 - val_mae: 53.5432 - val_mse: 32194.2695\n",
      "Epoch 182/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16681.6535 - mae: 52.4530 - mse: 16681.6504 - val_loss: 32191.1919 - val_mae: 53.6178 - val_mse: 32191.1895\n",
      "Epoch 183/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16693.2049 - mae: 52.7036 - mse: 16693.2051 - val_loss: 32185.8381 - val_mae: 53.7913 - val_mse: 32185.8379\n",
      "Epoch 184/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16771.1124 - mae: 52.7575 - mse: 16771.1094 - val_loss: 32189.5766 - val_mae: 53.5932 - val_mse: 32189.5781\n",
      "Epoch 185/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16632.3679 - mae: 52.0948 - mse: 16632.3672 - val_loss: 32194.9562 - val_mae: 53.3499 - val_mse: 32194.9551\n",
      "Epoch 186/1000\n",
      "3200/3200 [==============================] - 0s 29us/sample - loss: 16664.7759 - mae: 52.4662 - mse: 16664.7754 - val_loss: 32185.8603 - val_mae: 53.6465 - val_mse: 32185.8633\n",
      "Epoch 187/1000\n",
      "3200/3200 [==============================] - 0s 28us/sample - loss: 16629.6716 - mae: 52.6044 - mse: 16629.6719 - val_loss: 32181.4025 - val_mae: 53.7789 - val_mse: 32181.4023\n",
      "Epoch 188/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16648.5541 - mae: 52.4690 - mse: 16648.5527 - val_loss: 32180.0299 - val_mae: 53.7851 - val_mse: 32180.0332\n",
      "Epoch 189/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16651.5688 - mae: 52.5988 - mse: 16651.5664 - val_loss: 32183.9645 - val_mae: 53.5800 - val_mse: 32183.9648\n",
      "Epoch 190/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16678.4349 - mae: 52.9136 - mse: 16678.4336 - val_loss: 32181.4782 - val_mae: 53.6313 - val_mse: 32181.4805\n",
      "Epoch 191/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16661.0889 - mae: 52.7262 - mse: 16661.0859 - val_loss: 32180.9295 - val_mae: 53.6049 - val_mse: 32180.9297\n",
      "Epoch 192/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16735.8252 - mae: 52.3597 - mse: 16735.8281 - val_loss: 32186.4652 - val_mae: 53.3586 - val_mse: 32186.4648\n",
      "Epoch 193/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16666.2693 - mae: 52.3527 - mse: 16666.2695 - val_loss: 32182.7554 - val_mae: 53.4482 - val_mse: 32182.7559\n",
      "Epoch 194/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16613.8298 - mae: 52.3375 - mse: 16613.8281 - val_loss: 32180.4097 - val_mae: 53.4882 - val_mse: 32180.4102\n",
      "Epoch 195/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16627.2343 - mae: 52.2318 - mse: 16627.2344 - val_loss: 32180.6589 - val_mae: 53.4403 - val_mse: 32180.6582\n",
      "Epoch 196/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16596.6065 - mae: 52.2185 - mse: 16596.6055 - val_loss: 32177.4093 - val_mae: 53.5185 - val_mse: 32177.4102\n",
      "Epoch 197/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16727.3394 - mae: 52.7442 - mse: 16727.3418 - val_loss: 32174.8637 - val_mae: 53.5696 - val_mse: 32174.8652\n",
      "Epoch 198/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16730.6534 - mae: 52.4417 - mse: 16730.6543 - val_loss: 32177.9804 - val_mae: 53.4118 - val_mse: 32177.9805\n",
      "Epoch 199/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16639.8820 - mae: 52.4089 - mse: 16639.8809 - val_loss: 32172.4753 - val_mae: 53.5685 - val_mse: 32172.4746\n",
      "Epoch 200/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16625.0403 - mae: 52.2785 - mse: 16625.0410 - val_loss: 32169.1528 - val_mae: 53.6563 - val_mse: 32169.1523\n",
      "Epoch 201/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16618.7297 - mae: 52.0723 - mse: 16618.7305 - val_loss: 32172.6009 - val_mae: 53.4707 - val_mse: 32172.6016\n",
      "Epoch 202/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16744.2269 - mae: 52.9063 - mse: 16744.2324 - val_loss: 32175.3219 - val_mae: 53.3315 - val_mse: 32175.3223\n",
      "Epoch 203/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16593.7701 - mae: 52.1759 - mse: 16593.7695 - val_loss: 32169.3060 - val_mae: 53.5042 - val_mse: 32169.3047\n",
      "Epoch 204/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16624.9575 - mae: 52.1136 - mse: 16624.9590 - val_loss: 32168.5249 - val_mae: 53.4854 - val_mse: 32168.5254\n",
      "Epoch 205/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16643.5656 - mae: 52.3189 - mse: 16643.5684 - val_loss: 32170.1053 - val_mae: 53.3833 - val_mse: 32170.1055\n",
      "Epoch 206/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16635.0623 - mae: 52.5718 - mse: 16635.0625 - val_loss: 32166.8274 - val_mae: 53.4591 - val_mse: 32166.8301\n",
      "Epoch 207/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16658.6225 - mae: 52.3816 - mse: 16658.6211 - val_loss: 32168.3870 - val_mae: 53.3544 - val_mse: 32168.3867\n",
      "Epoch 208/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16704.8281 - mae: 52.2509 - mse: 16704.8281 - val_loss: 32172.1393 - val_mae: 53.1874 - val_mse: 32172.1406\n",
      "Epoch 209/1000\n",
      "3200/3200 [==============================] - 0s 44us/sample - loss: 16698.8555 - mae: 52.1628 - mse: 16698.8555 - val_loss: 32161.9598 - val_mae: 53.5085 - val_mse: 32161.9609\n",
      "Epoch 210/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16618.7096 - mae: 52.1769 - mse: 16618.7070 - val_loss: 32160.4470 - val_mae: 53.5076 - val_mse: 32160.4473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16659.5103 - mae: 52.4557 - mse: 16659.5117 - val_loss: 32163.1766 - val_mae: 53.3585 - val_mse: 32163.1758\n",
      "Epoch 212/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16672.3724 - mae: 52.5082 - mse: 16672.3730 - val_loss: 32166.4463 - val_mae: 53.2030 - val_mse: 32166.4473\n",
      "Epoch 213/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16744.6247 - mae: 52.3158 - mse: 16744.6250 - val_loss: 32166.8569 - val_mae: 53.1448 - val_mse: 32166.8574\n",
      "Epoch 214/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16665.4708 - mae: 52.1934 - mse: 16665.4746 - val_loss: 32169.4156 - val_mae: 53.0256 - val_mse: 32169.4180\n",
      "Epoch 215/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16584.7881 - mae: 52.0620 - mse: 16584.7891 - val_loss: 32152.8295 - val_mae: 53.5537 - val_mse: 32152.8301\n",
      "Epoch 216/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16594.7705 - mae: 52.0062 - mse: 16594.7695 - val_loss: 32156.4208 - val_mae: 53.3707 - val_mse: 32156.4219\n",
      "Epoch 217/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16585.8228 - mae: 52.5238 - mse: 16585.8223 - val_loss: 32148.9150 - val_mae: 53.6091 - val_mse: 32148.9141\n",
      "Epoch 218/1000\n",
      "3200/3200 [==============================] - 0s 52us/sample - loss: 16623.3469 - mae: 52.4687 - mse: 16623.3496 - val_loss: 32147.7573 - val_mae: 53.6076 - val_mse: 32147.7578\n",
      "Epoch 219/1000\n",
      "3200/3200 [==============================] - 0s 69us/sample - loss: 16619.7014 - mae: 52.1486 - mse: 16619.6992 - val_loss: 32152.5966 - val_mae: 53.3686 - val_mse: 32152.5957\n",
      "Epoch 220/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16592.8982 - mae: 52.2232 - mse: 16592.8965 - val_loss: 32141.7300 - val_mae: 53.7606 - val_mse: 32141.7324\n",
      "Epoch 221/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16556.4242 - mae: 52.3734 - mse: 16556.4219 - val_loss: 32145.8170 - val_mae: 53.5351 - val_mse: 32145.8184\n",
      "Epoch 222/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16674.2858 - mae: 52.7442 - mse: 16674.2871 - val_loss: 32144.0157 - val_mae: 53.5568 - val_mse: 32144.0176\n",
      "Epoch 223/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16736.3811 - mae: 52.1510 - mse: 16736.3770 - val_loss: 32151.9287 - val_mae: 53.2199 - val_mse: 32151.9277\n",
      "Epoch 224/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16567.0536 - mae: 52.3360 - mse: 16567.0547 - val_loss: 32145.6674 - val_mae: 53.3983 - val_mse: 32145.6641\n",
      "Epoch 225/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16645.1669 - mae: 52.2995 - mse: 16645.1680 - val_loss: 32146.2602 - val_mae: 53.3322 - val_mse: 32146.2598\n",
      "Epoch 226/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16639.2889 - mae: 52.1892 - mse: 16639.2871 - val_loss: 32144.8572 - val_mae: 53.3408 - val_mse: 32144.8574\n",
      "Epoch 227/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 16729.7841 - mae: 52.5994 - mse: 16729.7832 - val_loss: 32144.5502 - val_mae: 53.3075 - val_mse: 32144.5469\n",
      "Epoch 228/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16572.7399 - mae: 52.1418 - mse: 16572.7383 - val_loss: 32139.4988 - val_mae: 53.4424 - val_mse: 32139.5000\n",
      "Epoch 229/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16633.4303 - mae: 52.4468 - mse: 16633.4316 - val_loss: 32139.4881 - val_mae: 53.3947 - val_mse: 32139.4883\n",
      "Epoch 230/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16548.4397 - mae: 51.8510 - mse: 16548.4395 - val_loss: 32141.2004 - val_mae: 53.2869 - val_mse: 32141.1992\n",
      "Epoch 231/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16612.5628 - mae: 52.2357 - mse: 16612.5645 - val_loss: 32137.6604 - val_mae: 53.3665 - val_mse: 32137.6621\n",
      "Epoch 232/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16684.3185 - mae: 52.3753 - mse: 16684.3203 - val_loss: 32136.4063 - val_mae: 53.3638 - val_mse: 32136.4082\n",
      "Epoch 233/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16612.2275 - mae: 52.5914 - mse: 16612.2285 - val_loss: 32138.5595 - val_mae: 53.2421 - val_mse: 32138.5566\n",
      "Epoch 234/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16576.5350 - mae: 51.6570 - mse: 16576.5352 - val_loss: 32141.4210 - val_mae: 53.1061 - val_mse: 32141.4199\n",
      "Epoch 235/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16560.7784 - mae: 52.2084 - mse: 16560.7773 - val_loss: 32125.9171 - val_mae: 53.6166 - val_mse: 32125.9180\n",
      "Epoch 236/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16550.6221 - mae: 52.3695 - mse: 16550.6211 - val_loss: 32125.1870 - val_mae: 53.5917 - val_mse: 32125.1875\n",
      "Epoch 237/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16714.8595 - mae: 52.5239 - mse: 16714.8594 - val_loss: 32125.1423 - val_mae: 53.5349 - val_mse: 32125.1426\n",
      "Epoch 238/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16479.6275 - mae: 52.0376 - mse: 16479.6289 - val_loss: 32120.0181 - val_mae: 53.6890 - val_mse: 32120.0195\n",
      "Epoch 239/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16616.8896 - mae: 52.0368 - mse: 16616.8906 - val_loss: 32120.9799 - val_mae: 53.5938 - val_mse: 32120.9805\n",
      "Epoch 240/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16665.8343 - mae: 52.5010 - mse: 16665.8320 - val_loss: 32120.4201 - val_mae: 53.5567 - val_mse: 32120.4199\n",
      "Epoch 241/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16690.1699 - mae: 52.3256 - mse: 16690.1719 - val_loss: 32126.0670 - val_mae: 53.2990 - val_mse: 32126.0684\n",
      "Epoch 242/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16595.3542 - mae: 51.8948 - mse: 16595.3555 - val_loss: 32124.2844 - val_mae: 53.3139 - val_mse: 32124.2852\n",
      "Epoch 243/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16623.0038 - mae: 52.3549 - mse: 16623.0000 - val_loss: 32120.1944 - val_mae: 53.4060 - val_mse: 32120.1953\n",
      "Epoch 244/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16576.5203 - mae: 51.6480 - mse: 16576.5156 - val_loss: 32116.2792 - val_mae: 53.5070 - val_mse: 32116.2793\n",
      "Epoch 245/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16602.1259 - mae: 52.0595 - mse: 16602.1250 - val_loss: 32114.9839 - val_mae: 53.5078 - val_mse: 32114.9824\n",
      "Epoch 246/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16564.2047 - mae: 52.0058 - mse: 16564.2031 - val_loss: 32116.4013 - val_mae: 53.4056 - val_mse: 32116.4023\n",
      "Epoch 247/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16591.4846 - mae: 52.4665 - mse: 16591.4844 - val_loss: 32110.6000 - val_mae: 53.5772 - val_mse: 32110.5996\n",
      "Epoch 248/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16621.4646 - mae: 52.4666 - mse: 16621.4629 - val_loss: 32115.1414 - val_mae: 53.3448 - val_mse: 32115.1426\n",
      "Epoch 249/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16585.9608 - mae: 52.0864 - mse: 16585.9629 - val_loss: 32112.5309 - val_mae: 53.3869 - val_mse: 32112.5332\n",
      "Epoch 250/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16736.5498 - mae: 52.3580 - mse: 16736.5508 - val_loss: 32120.8426 - val_mae: 53.0610 - val_mse: 32120.8418\n",
      "Epoch 251/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16648.2853 - mae: 51.8368 - mse: 16648.2871 - val_loss: 32122.2082 - val_mae: 52.9788 - val_mse: 32122.2070\n",
      "Epoch 252/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16545.3056 - mae: 51.9177 - mse: 16545.3066 - val_loss: 32116.4247 - val_mae: 53.1192 - val_mse: 32116.4258\n",
      "Epoch 253/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16520.8392 - mae: 52.3658 - mse: 16520.8379 - val_loss: 32100.9279 - val_mae: 53.6357 - val_mse: 32100.9297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16599.8494 - mae: 52.4225 - mse: 16599.8457 - val_loss: 32105.6704 - val_mae: 53.3854 - val_mse: 32105.6699\n",
      "Epoch 255/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16689.2216 - mae: 51.9681 - mse: 16689.2246 - val_loss: 32105.5110 - val_mae: 53.3386 - val_mse: 32105.5098\n",
      "Epoch 256/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16519.4407 - mae: 51.5834 - mse: 16519.4434 - val_loss: 32102.0886 - val_mae: 53.4169 - val_mse: 32102.0918\n",
      "Epoch 257/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16561.2205 - mae: 52.1187 - mse: 16561.2207 - val_loss: 32097.8585 - val_mae: 53.5214 - val_mse: 32097.8574\n",
      "Epoch 258/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16549.9518 - mae: 52.1985 - mse: 16549.9531 - val_loss: 32100.5534 - val_mae: 53.3639 - val_mse: 32100.5527\n",
      "Epoch 259/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16607.4520 - mae: 52.1289 - mse: 16607.4512 - val_loss: 32096.5081 - val_mae: 53.4729 - val_mse: 32096.5078\n",
      "Epoch 260/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16532.0214 - mae: 51.9585 - mse: 16532.0234 - val_loss: 32095.3849 - val_mae: 53.4561 - val_mse: 32095.3848\n",
      "Epoch 261/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16535.0878 - mae: 52.2318 - mse: 16535.0898 - val_loss: 32091.7201 - val_mae: 53.5423 - val_mse: 32091.7207\n",
      "Epoch 262/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16532.7817 - mae: 52.2692 - mse: 16532.7793 - val_loss: 32089.3034 - val_mae: 53.5808 - val_mse: 32089.3027\n",
      "Epoch 263/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16610.4167 - mae: 52.2497 - mse: 16610.4180 - val_loss: 32089.6262 - val_mae: 53.5197 - val_mse: 32089.6270\n",
      "Epoch 264/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16541.1452 - mae: 51.9127 - mse: 16541.1465 - val_loss: 32087.3330 - val_mae: 53.5490 - val_mse: 32087.3359\n",
      "Epoch 265/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16560.8906 - mae: 51.9482 - mse: 16560.8906 - val_loss: 32088.1158 - val_mae: 53.4578 - val_mse: 32088.1172\n",
      "Epoch 266/1000\n",
      "3200/3200 [==============================] - 0s 57us/sample - loss: 16576.1184 - mae: 52.0303 - mse: 16576.1191 - val_loss: 32085.2774 - val_mae: 53.5202 - val_mse: 32085.2793\n",
      "Epoch 267/1000\n",
      "3200/3200 [==============================] - 0s 62us/sample - loss: 16655.2215 - mae: 52.3234 - mse: 16655.2207 - val_loss: 32092.3374 - val_mae: 53.2086 - val_mse: 32092.3379\n",
      "Epoch 268/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16518.1129 - mae: 51.6457 - mse: 16518.1133 - val_loss: 32087.0096 - val_mae: 53.3428 - val_mse: 32087.0098\n",
      "Epoch 269/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16568.3282 - mae: 51.8749 - mse: 16568.3262 - val_loss: 32085.3495 - val_mae: 53.3590 - val_mse: 32085.3496\n",
      "Epoch 270/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16536.7535 - mae: 52.1881 - mse: 16536.7559 - val_loss: 32080.0204 - val_mae: 53.4878 - val_mse: 32080.0195\n",
      "Epoch 271/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16451.4026 - mae: 52.0132 - mse: 16451.4062 - val_loss: 32074.3686 - val_mae: 53.6509 - val_mse: 32074.3730\n",
      "Epoch 272/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16545.8842 - mae: 52.3631 - mse: 16545.8867 - val_loss: 32071.1237 - val_mae: 53.7163 - val_mse: 32071.1250\n",
      "Epoch 273/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16543.6854 - mae: 52.1729 - mse: 16543.6855 - val_loss: 32073.3669 - val_mae: 53.5587 - val_mse: 32073.3691\n",
      "Epoch 274/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16619.9451 - mae: 51.8758 - mse: 16619.9473 - val_loss: 32082.9150 - val_mae: 53.1731 - val_mse: 32082.9141\n",
      "Epoch 275/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16495.2491 - mae: 51.5038 - mse: 16495.2520 - val_loss: 32076.2957 - val_mae: 53.3587 - val_mse: 32076.2949\n",
      "Epoch 276/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16611.6033 - mae: 52.0673 - mse: 16611.6055 - val_loss: 32071.7977 - val_mae: 53.4656 - val_mse: 32071.7969\n",
      "Epoch 277/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16600.1581 - mae: 51.8389 - mse: 16600.1582 - val_loss: 32080.4284 - val_mae: 53.1065 - val_mse: 32080.4277\n",
      "Epoch 278/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16574.6465 - mae: 51.7283 - mse: 16574.6426 - val_loss: 32069.7696 - val_mae: 53.3898 - val_mse: 32069.7695\n",
      "Epoch 279/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16532.3552 - mae: 51.9231 - mse: 16532.3555 - val_loss: 32058.4834 - val_mae: 53.7878 - val_mse: 32058.4824\n",
      "Epoch 280/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16544.0929 - mae: 51.9848 - mse: 16544.0938 - val_loss: 32065.5576 - val_mae: 53.4355 - val_mse: 32065.5566\n",
      "Epoch 281/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16454.0462 - mae: 52.1564 - mse: 16454.0469 - val_loss: 32059.5974 - val_mae: 53.5990 - val_mse: 32059.5977\n",
      "Epoch 282/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16635.9826 - mae: 52.0828 - mse: 16635.9805 - val_loss: 32065.4628 - val_mae: 53.3150 - val_mse: 32065.4629\n",
      "Epoch 283/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16452.6301 - mae: 51.4857 - mse: 16452.6309 - val_loss: 32056.9376 - val_mae: 53.5789 - val_mse: 32056.9375\n",
      "Epoch 284/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16539.2260 - mae: 51.9852 - mse: 16539.2266 - val_loss: 32052.4825 - val_mae: 53.6851 - val_mse: 32052.4824\n",
      "Epoch 285/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16489.8172 - mae: 51.8671 - mse: 16489.8145 - val_loss: 32052.8789 - val_mae: 53.6006 - val_mse: 32052.8770\n",
      "Epoch 286/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 16499.6865 - mae: 52.1573 - mse: 16499.6895 - val_loss: 32055.6398 - val_mae: 53.4315 - val_mse: 32055.6406\n",
      "Epoch 287/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16567.9136 - mae: 51.9199 - mse: 16567.9141 - val_loss: 32050.6634 - val_mae: 53.5585 - val_mse: 32050.6641\n",
      "Epoch 288/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16553.1958 - mae: 51.6163 - mse: 16553.1973 - val_loss: 32050.5282 - val_mae: 53.4963 - val_mse: 32050.5273\n",
      "Epoch 289/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16481.9505 - mae: 51.6906 - mse: 16481.9492 - val_loss: 32049.0252 - val_mae: 53.4879 - val_mse: 32049.0254\n",
      "Epoch 290/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16520.5573 - mae: 52.3123 - mse: 16520.5605 - val_loss: 32042.1181 - val_mae: 53.7124 - val_mse: 32042.1152\n",
      "Epoch 291/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16487.8441 - mae: 51.9923 - mse: 16487.8457 - val_loss: 32043.6719 - val_mae: 53.5658 - val_mse: 32043.6699\n",
      "Epoch 292/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16469.2637 - mae: 51.9804 - mse: 16469.2598 - val_loss: 32042.9812 - val_mae: 53.5269 - val_mse: 32042.9805\n",
      "Epoch 293/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16629.4014 - mae: 51.7108 - mse: 16629.4023 - val_loss: 32053.2084 - val_mae: 53.1160 - val_mse: 32053.2051\n",
      "Epoch 294/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16458.8758 - mae: 51.7046 - mse: 16458.8730 - val_loss: 32041.9117 - val_mae: 53.4414 - val_mse: 32041.9102\n",
      "Epoch 295/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16481.9782 - mae: 51.9450 - mse: 16481.9766 - val_loss: 32036.0360 - val_mae: 53.6011 - val_mse: 32036.0371\n",
      "Epoch 296/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 16430.1152 - mae: 51.7061 - mse: 16430.1172 - val_loss: 32038.1318 - val_mae: 53.4534 - val_mse: 32038.1348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16447.6125 - mae: 51.8281 - mse: 16447.6133 - val_loss: 32027.3994 - val_mae: 53.8150 - val_mse: 32027.3984\n",
      "Epoch 298/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16499.7513 - mae: 52.2397 - mse: 16499.7520 - val_loss: 32025.4536 - val_mae: 53.8235 - val_mse: 32025.4551\n",
      "Epoch 299/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16477.9302 - mae: 52.4813 - mse: 16477.9316 - val_loss: 32028.2809 - val_mae: 53.6131 - val_mse: 32028.2793\n",
      "Epoch 300/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16468.5947 - mae: 51.8870 - mse: 16468.5938 - val_loss: 32026.7632 - val_mae: 53.5971 - val_mse: 32026.7617\n",
      "Epoch 301/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16372.3189 - mae: 52.0465 - mse: 16372.3223 - val_loss: 32019.9240 - val_mae: 53.7907 - val_mse: 32019.9219\n",
      "Epoch 302/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16568.5654 - mae: 51.7672 - mse: 16568.5664 - val_loss: 32024.1378 - val_mae: 53.5341 - val_mse: 32024.1406\n",
      "Epoch 303/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16516.2260 - mae: 51.8376 - mse: 16516.2266 - val_loss: 32025.5805 - val_mae: 53.4119 - val_mse: 32025.5801\n",
      "Epoch 304/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16453.5481 - mae: 51.9997 - mse: 16453.5488 - val_loss: 32020.6649 - val_mae: 53.5302 - val_mse: 32020.6641\n",
      "Epoch 305/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16473.0199 - mae: 51.4638 - mse: 16473.0195 - val_loss: 32023.8412 - val_mae: 53.3472 - val_mse: 32023.8398\n",
      "Epoch 306/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 16484.7293 - mae: 51.9154 - mse: 16484.7305 - val_loss: 32013.3341 - val_mae: 53.6721 - val_mse: 32013.3359\n",
      "Epoch 307/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16506.6409 - mae: 51.9433 - mse: 16506.6406 - val_loss: 32016.6347 - val_mae: 53.4717 - val_mse: 32016.6328\n",
      "Epoch 308/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16380.0577 - mae: 52.0213 - mse: 16380.0566 - val_loss: 32005.4981 - val_mae: 53.8528 - val_mse: 32005.4980\n",
      "Epoch 309/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16443.6163 - mae: 51.6849 - mse: 16443.6152 - val_loss: 32011.8478 - val_mae: 53.5071 - val_mse: 32011.8477\n",
      "Epoch 310/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16399.2717 - mae: 52.1788 - mse: 16399.2734 - val_loss: 32004.0930 - val_mae: 53.7370 - val_mse: 32004.0898\n",
      "Epoch 311/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16507.5450 - mae: 51.5850 - mse: 16507.5449 - val_loss: 32014.2744 - val_mae: 53.2868 - val_mse: 32014.2773\n",
      "Epoch 312/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16486.9492 - mae: 52.1172 - mse: 16486.9551 - val_loss: 31999.7408 - val_mae: 53.7714 - val_mse: 31999.7402\n",
      "Epoch 313/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16510.2730 - mae: 52.2139 - mse: 16510.2754 - val_loss: 32001.0196 - val_mae: 53.6158 - val_mse: 32001.0195\n",
      "Epoch 314/1000\n",
      "3200/3200 [==============================] - 0s 54us/sample - loss: 16427.1562 - mae: 51.4567 - mse: 16427.1582 - val_loss: 32004.6174 - val_mae: 53.4003 - val_mse: 32004.6172\n",
      "Epoch 315/1000\n",
      "3200/3200 [==============================] - 0s 59us/sample - loss: 16432.9240 - mae: 51.8949 - mse: 16432.9258 - val_loss: 31996.2055 - val_mae: 53.6520 - val_mse: 31996.2051\n",
      "Epoch 316/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16423.5583 - mae: 51.9734 - mse: 16423.5586 - val_loss: 31997.5629 - val_mae: 53.5216 - val_mse: 31997.5625\n",
      "Epoch 317/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16474.1652 - mae: 51.4964 - mse: 16474.1641 - val_loss: 31999.9862 - val_mae: 53.3713 - val_mse: 31999.9883\n",
      "Epoch 318/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16505.2031 - mae: 51.7980 - mse: 16505.2031 - val_loss: 31991.8200 - val_mae: 53.6107 - val_mse: 31991.8203\n",
      "Epoch 319/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16392.2756 - mae: 52.2043 - mse: 16392.2773 - val_loss: 31986.8947 - val_mae: 53.7212 - val_mse: 31986.8945\n",
      "Epoch 320/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16386.9693 - mae: 51.7715 - mse: 16386.9688 - val_loss: 31987.0934 - val_mae: 53.6240 - val_mse: 31987.0918\n",
      "Epoch 321/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16385.4455 - mae: 51.9658 - mse: 16385.4453 - val_loss: 31979.1232 - val_mae: 53.8827 - val_mse: 31979.1230\n",
      "Epoch 322/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16387.7515 - mae: 51.8879 - mse: 16387.7539 - val_loss: 31981.3478 - val_mae: 53.6739 - val_mse: 31981.3496\n",
      "Epoch 323/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16412.2046 - mae: 52.2759 - mse: 16412.2070 - val_loss: 31979.3642 - val_mae: 53.6664 - val_mse: 31979.3672\n",
      "Epoch 324/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16449.1177 - mae: 51.4425 - mse: 16449.1172 - val_loss: 31976.8347 - val_mae: 53.6919 - val_mse: 31976.8359\n",
      "Epoch 325/1000\n",
      "3200/3200 [==============================] - 0s 43us/sample - loss: 16479.7814 - mae: 52.0386 - mse: 16479.7793 - val_loss: 31982.5626 - val_mae: 53.3755 - val_mse: 31982.5625\n",
      "Epoch 326/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16452.5036 - mae: 51.2623 - mse: 16452.5039 - val_loss: 31982.6633 - val_mae: 53.3050 - val_mse: 31982.6641\n",
      "Epoch 327/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16471.5557 - mae: 51.7137 - mse: 16471.5566 - val_loss: 31977.0366 - val_mae: 53.4371 - val_mse: 31977.0352\n",
      "Epoch 328/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16469.9863 - mae: 51.7622 - mse: 16469.9863 - val_loss: 31972.7460 - val_mae: 53.5063 - val_mse: 31972.7422\n",
      "Epoch 329/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16392.2006 - mae: 51.5603 - mse: 16392.1992 - val_loss: 31968.2662 - val_mae: 53.6031 - val_mse: 31968.2656\n",
      "Epoch 330/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16467.9615 - mae: 51.5302 - mse: 16467.9609 - val_loss: 31970.6325 - val_mae: 53.4230 - val_mse: 31970.6328\n",
      "Epoch 331/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16408.1788 - mae: 52.0398 - mse: 16408.1797 - val_loss: 31962.3480 - val_mae: 53.6590 - val_mse: 31962.3477\n",
      "Epoch 332/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16390.1861 - mae: 51.4008 - mse: 16390.1855 - val_loss: 31959.2480 - val_mae: 53.6931 - val_mse: 31959.2500\n",
      "Epoch 333/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 16355.4149 - mae: 52.1883 - mse: 16355.4121 - val_loss: 31954.2079 - val_mae: 53.8248 - val_mse: 31954.2109\n",
      "Epoch 334/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 16348.5651 - mae: 51.7634 - mse: 16348.5674 - val_loss: 31952.2200 - val_mae: 53.8168 - val_mse: 31952.2207\n",
      "Epoch 335/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16371.4558 - mae: 51.6371 - mse: 16371.4541 - val_loss: 31949.4495 - val_mae: 53.8288 - val_mse: 31949.4492\n",
      "Epoch 336/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16406.8010 - mae: 51.3106 - mse: 16406.8008 - val_loss: 31954.8937 - val_mae: 53.4977 - val_mse: 31954.8945\n",
      "Epoch 337/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16439.7663 - mae: 52.1814 - mse: 16439.7695 - val_loss: 31945.1132 - val_mae: 53.8166 - val_mse: 31945.1133\n",
      "Epoch 338/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16351.1840 - mae: 51.6328 - mse: 16351.1836 - val_loss: 31947.2326 - val_mae: 53.6190 - val_mse: 31947.2344\n",
      "Epoch 339/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16373.8936 - mae: 51.8351 - mse: 16373.8926 - val_loss: 31939.3044 - val_mae: 53.8664 - val_mse: 31939.3027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16406.2061 - mae: 51.7165 - mse: 16406.2031 - val_loss: 31939.9094 - val_mae: 53.7314 - val_mse: 31939.9082\n",
      "Epoch 341/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16436.4699 - mae: 51.6978 - mse: 16436.4688 - val_loss: 31942.4681 - val_mae: 53.5200 - val_mse: 31942.4668\n",
      "Epoch 342/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16331.3393 - mae: 51.3790 - mse: 16331.3398 - val_loss: 31932.6129 - val_mae: 53.8530 - val_mse: 31932.6152\n",
      "Epoch 343/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16375.5906 - mae: 52.2883 - mse: 16375.5898 - val_loss: 31934.6314 - val_mae: 53.6202 - val_mse: 31934.6309\n",
      "Epoch 344/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16395.0081 - mae: 51.5619 - mse: 16395.0078 - val_loss: 31928.0807 - val_mae: 53.8140 - val_mse: 31928.0801\n",
      "Epoch 345/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16387.4672 - mae: 51.6379 - mse: 16387.4668 - val_loss: 31928.6336 - val_mae: 53.6790 - val_mse: 31928.6348\n",
      "Epoch 346/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16319.1777 - mae: 51.7289 - mse: 16319.1797 - val_loss: 31923.6966 - val_mae: 53.7916 - val_mse: 31923.6953\n",
      "Epoch 347/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16400.1916 - mae: 51.0851 - mse: 16400.1875 - val_loss: 31925.0159 - val_mae: 53.6252 - val_mse: 31925.0176\n",
      "Epoch 348/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16375.4534 - mae: 51.6184 - mse: 16375.4502 - val_loss: 31916.4212 - val_mae: 53.9330 - val_mse: 31916.4199\n",
      "Epoch 349/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16379.8655 - mae: 51.6406 - mse: 16379.8652 - val_loss: 31919.4391 - val_mae: 53.6595 - val_mse: 31919.4395\n",
      "Epoch 350/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16399.4256 - mae: 51.8105 - mse: 16399.4258 - val_loss: 31913.6644 - val_mae: 53.8200 - val_mse: 31913.6641\n",
      "Epoch 351/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16353.3105 - mae: 51.9035 - mse: 16353.3115 - val_loss: 31915.3998 - val_mae: 53.5958 - val_mse: 31915.4023\n",
      "Epoch 352/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16443.4054 - mae: 51.5013 - mse: 16443.4062 - val_loss: 31913.9371 - val_mae: 53.5615 - val_mse: 31913.9375\n",
      "Epoch 353/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16402.5232 - mae: 51.3904 - mse: 16402.5234 - val_loss: 31914.2621 - val_mae: 53.4512 - val_mse: 31914.2617\n",
      "Epoch 354/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16338.1478 - mae: 51.8934 - mse: 16338.1445 - val_loss: 31908.0076 - val_mae: 53.5978 - val_mse: 31908.0078\n",
      "Epoch 355/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16439.1174 - mae: 51.6484 - mse: 16439.1152 - val_loss: 31912.1881 - val_mae: 53.3255 - val_mse: 31912.1875\n",
      "Epoch 356/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16414.1621 - mae: 51.1959 - mse: 16414.1621 - val_loss: 31916.3634 - val_mae: 53.1022 - val_mse: 31916.3652\n",
      "Epoch 357/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16422.8300 - mae: 50.9833 - mse: 16422.8281 - val_loss: 31901.8813 - val_mae: 53.5292 - val_mse: 31901.8809\n",
      "Epoch 358/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16419.0488 - mae: 51.6247 - mse: 16419.0469 - val_loss: 31903.1015 - val_mae: 53.3690 - val_mse: 31903.1016\n",
      "Epoch 359/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16406.9323 - mae: 51.5141 - mse: 16406.9336 - val_loss: 31907.3432 - val_mae: 53.1145 - val_mse: 31907.3418\n",
      "Epoch 360/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16321.2251 - mae: 51.3431 - mse: 16321.2275 - val_loss: 31884.9478 - val_mae: 53.9117 - val_mse: 31884.9473\n",
      "Epoch 361/1000\n",
      "3200/3200 [==============================] - 0s 50us/sample - loss: 16359.0839 - mae: 51.2276 - mse: 16359.0811 - val_loss: 31887.5329 - val_mae: 53.6508 - val_mse: 31887.5332\n",
      "Epoch 362/1000\n",
      "3200/3200 [==============================] - 0s 55us/sample - loss: 16258.9447 - mae: 51.3758 - mse: 16258.9473 - val_loss: 31874.0548 - val_mae: 54.2158 - val_mse: 31874.0527\n",
      "Epoch 363/1000\n",
      "3200/3200 [==============================] - 0s 52us/sample - loss: 16346.2555 - mae: 51.9144 - mse: 16346.2539 - val_loss: 31872.3646 - val_mae: 54.1053 - val_mse: 31872.3652\n",
      "Epoch 364/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16398.7956 - mae: 51.8706 - mse: 16398.7988 - val_loss: 31874.3205 - val_mae: 53.8182 - val_mse: 31874.3203\n",
      "Epoch 365/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16440.8232 - mae: 51.3312 - mse: 16440.8203 - val_loss: 31883.6813 - val_mae: 53.3128 - val_mse: 31883.6816\n",
      "Epoch 366/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16301.7418 - mae: 51.1226 - mse: 16301.7422 - val_loss: 31872.5007 - val_mae: 53.6420 - val_mse: 31872.5000\n",
      "Epoch 367/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16285.4258 - mae: 51.5130 - mse: 16285.4238 - val_loss: 31870.7673 - val_mae: 53.6044 - val_mse: 31870.7676\n",
      "Epoch 368/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16341.8549 - mae: 51.2544 - mse: 16341.8555 - val_loss: 31869.6794 - val_mae: 53.5154 - val_mse: 31869.6797\n",
      "Epoch 369/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16275.8290 - mae: 51.2537 - mse: 16275.8301 - val_loss: 31865.1466 - val_mae: 53.5801 - val_mse: 31865.1484\n",
      "Epoch 370/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16345.6150 - mae: 51.9390 - mse: 16345.6133 - val_loss: 31854.1567 - val_mae: 53.9600 - val_mse: 31854.1582\n",
      "Epoch 371/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16355.3322 - mae: 51.8739 - mse: 16355.3350 - val_loss: 31861.3186 - val_mae: 53.4650 - val_mse: 31861.3184\n",
      "Epoch 372/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16285.2170 - mae: 51.1357 - mse: 16285.2148 - val_loss: 31854.3539 - val_mae: 53.6476 - val_mse: 31854.3555\n",
      "Epoch 373/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16425.1261 - mae: 51.8150 - mse: 16425.1270 - val_loss: 31855.0396 - val_mae: 53.5004 - val_mse: 31855.0391\n",
      "Epoch 374/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 16252.0224 - mae: 50.8063 - mse: 16252.0254 - val_loss: 31852.2318 - val_mae: 53.5238 - val_mse: 31852.2324\n",
      "Epoch 375/1000\n",
      "3200/3200 [==============================] - 0s 49us/sample - loss: 16346.5712 - mae: 52.0755 - mse: 16346.5713 - val_loss: 31842.3524 - val_mae: 53.8291 - val_mse: 31842.3477\n",
      "Epoch 376/1000\n",
      "3200/3200 [==============================] - 0s 52us/sample - loss: 16268.6200 - mae: 51.2886 - mse: 16268.6211 - val_loss: 31835.3028 - val_mae: 54.0484 - val_mse: 31835.3047\n",
      "Epoch 377/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 16376.8734 - mae: 51.9696 - mse: 16376.8711 - val_loss: 31839.4117 - val_mae: 53.6658 - val_mse: 31839.4102\n",
      "Epoch 378/1000\n",
      "3200/3200 [==============================] - 0s 54us/sample - loss: 16385.9984 - mae: 51.4287 - mse: 16385.9980 - val_loss: 31846.8923 - val_mae: 53.2474 - val_mse: 31846.8926\n",
      "Epoch 379/1000\n",
      "3200/3200 [==============================] - 0s 57us/sample - loss: 16338.1467 - mae: 50.9703 - mse: 16338.1465 - val_loss: 31840.5548 - val_mae: 53.3740 - val_mse: 31840.5547\n",
      "Epoch 380/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 16278.8893 - mae: 51.3547 - mse: 16278.8896 - val_loss: 31828.8139 - val_mae: 53.7381 - val_mse: 31828.8145\n",
      "Epoch 381/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16184.1194 - mae: 51.5505 - mse: 16184.1201 - val_loss: 31823.5605 - val_mae: 53.8206 - val_mse: 31823.5605\n",
      "Epoch 382/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16338.1120 - mae: 51.2732 - mse: 16338.1084 - val_loss: 31822.3143 - val_mae: 53.7118 - val_mse: 31822.3145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16296.7236 - mae: 51.4330 - mse: 16296.7266 - val_loss: 31818.8520 - val_mae: 53.7316 - val_mse: 31818.8555\n",
      "Epoch 384/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16306.6901 - mae: 51.4736 - mse: 16306.6904 - val_loss: 31818.9831 - val_mae: 53.5832 - val_mse: 31818.9805\n",
      "Epoch 385/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16337.6762 - mae: 51.4047 - mse: 16337.6777 - val_loss: 31807.9568 - val_mae: 54.0036 - val_mse: 31807.9570\n",
      "Epoch 386/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16323.2471 - mae: 51.6783 - mse: 16323.2500 - val_loss: 31808.7718 - val_mae: 53.7563 - val_mse: 31808.7695\n",
      "Epoch 387/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16278.3079 - mae: 50.9769 - mse: 16278.3047 - val_loss: 31807.7056 - val_mae: 53.6577 - val_mse: 31807.7051\n",
      "Epoch 388/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16287.7259 - mae: 51.5704 - mse: 16287.7285 - val_loss: 31800.2923 - val_mae: 53.8400 - val_mse: 31800.2930\n",
      "Epoch 389/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16233.1097 - mae: 51.3873 - mse: 16233.1084 - val_loss: 31793.0882 - val_mae: 54.0525 - val_mse: 31793.0898\n",
      "Epoch 390/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16288.0844 - mae: 51.3249 - mse: 16288.0859 - val_loss: 31803.0037 - val_mae: 53.3986 - val_mse: 31803.0020\n",
      "Epoch 391/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16240.3023 - mae: 51.0573 - mse: 16240.2998 - val_loss: 31793.4203 - val_mae: 53.6864 - val_mse: 31793.4199\n",
      "Epoch 392/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16256.8220 - mae: 51.2020 - mse: 16256.8242 - val_loss: 31786.9883 - val_mae: 53.8362 - val_mse: 31786.9883\n",
      "Epoch 393/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16252.1971 - mae: 51.4489 - mse: 16252.1973 - val_loss: 31780.4129 - val_mae: 53.9979 - val_mse: 31780.4121\n",
      "Epoch 394/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16280.0276 - mae: 51.0713 - mse: 16280.0283 - val_loss: 31785.5887 - val_mae: 53.5792 - val_mse: 31785.5898\n",
      "Epoch 395/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16261.9973 - mae: 51.0019 - mse: 16261.9971 - val_loss: 31773.4032 - val_mae: 54.0685 - val_mse: 31773.4023\n",
      "Epoch 396/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16278.8855 - mae: 51.5837 - mse: 16278.8887 - val_loss: 31773.9172 - val_mae: 53.8202 - val_mse: 31773.9180\n",
      "Epoch 397/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16208.8473 - mae: 51.1902 - mse: 16208.8477 - val_loss: 31767.7115 - val_mae: 53.9329 - val_mse: 31767.7129\n",
      "Epoch 398/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16283.6625 - mae: 51.7013 - mse: 16283.6611 - val_loss: 31767.3884 - val_mae: 53.7491 - val_mse: 31767.3906\n",
      "Epoch 399/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16282.5824 - mae: 50.9836 - mse: 16282.5811 - val_loss: 31766.9429 - val_mae: 53.6274 - val_mse: 31766.9434\n",
      "Epoch 400/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16235.5013 - mae: 51.4710 - mse: 16235.5000 - val_loss: 31759.2726 - val_mae: 53.8311 - val_mse: 31759.2734\n",
      "Epoch 401/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16233.3074 - mae: 51.3361 - mse: 16233.3047 - val_loss: 31752.1347 - val_mae: 54.0134 - val_mse: 31752.1367\n",
      "Epoch 402/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16271.8995 - mae: 51.9116 - mse: 16271.9004 - val_loss: 31754.8544 - val_mae: 53.6622 - val_mse: 31754.8555\n",
      "Epoch 403/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16218.0263 - mae: 50.7778 - mse: 16218.0264 - val_loss: 31752.3798 - val_mae: 53.6350 - val_mse: 31752.3828\n",
      "Epoch 404/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 16191.7721 - mae: 51.2474 - mse: 16191.7715 - val_loss: 31742.0010 - val_mae: 53.9575 - val_mse: 31742.0020\n",
      "Epoch 405/1000\n",
      "3200/3200 [==============================] - 0s 49us/sample - loss: 16154.0045 - mae: 50.9891 - mse: 16154.0049 - val_loss: 31745.6187 - val_mae: 53.5634 - val_mse: 31745.6191\n",
      "Epoch 406/1000\n",
      "3200/3200 [==============================] - 0s 55us/sample - loss: 16220.9974 - mae: 51.5133 - mse: 16220.9971 - val_loss: 31741.8185 - val_mae: 53.5869 - val_mse: 31741.8203\n",
      "Epoch 407/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16200.0308 - mae: 50.9342 - mse: 16200.0322 - val_loss: 31734.1875 - val_mae: 53.7288 - val_mse: 31734.1875\n",
      "Epoch 408/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16220.2732 - mae: 51.2308 - mse: 16220.2725 - val_loss: 31732.0970 - val_mae: 53.6302 - val_mse: 31732.0996\n",
      "Epoch 409/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16150.3322 - mae: 50.8106 - mse: 16150.3311 - val_loss: 31722.1394 - val_mae: 53.9947 - val_mse: 31722.1367\n",
      "Epoch 410/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16178.4226 - mae: 51.3136 - mse: 16178.4189 - val_loss: 31720.0074 - val_mae: 53.9126 - val_mse: 31720.0078\n",
      "Epoch 411/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16261.4531 - mae: 51.6313 - mse: 16261.4521 - val_loss: 31719.0157 - val_mae: 53.7735 - val_mse: 31719.0156\n",
      "Epoch 412/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16223.2235 - mae: 50.7659 - mse: 16223.2236 - val_loss: 31713.7366 - val_mae: 53.8959 - val_mse: 31713.7344\n",
      "Epoch 413/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16272.9758 - mae: 50.9463 - mse: 16272.9766 - val_loss: 31711.1616 - val_mae: 53.8347 - val_mse: 31711.1621\n",
      "Epoch 414/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16113.3624 - mae: 50.9170 - mse: 16113.3613 - val_loss: 31705.1073 - val_mae: 53.9782 - val_mse: 31705.1094\n",
      "Epoch 415/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16205.2993 - mae: 51.2591 - mse: 16205.2988 - val_loss: 31710.2654 - val_mae: 53.4963 - val_mse: 31710.2656\n",
      "Epoch 416/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16133.1824 - mae: 51.2084 - mse: 16133.1826 - val_loss: 31697.1696 - val_mae: 54.0086 - val_mse: 31697.1699\n",
      "Epoch 417/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 16280.2299 - mae: 51.4359 - mse: 16280.2305 - val_loss: 31706.9508 - val_mae: 53.2979 - val_mse: 31706.9531\n",
      "Epoch 418/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16130.3296 - mae: 50.7181 - mse: 16130.3301 - val_loss: 31698.9807 - val_mae: 53.4345 - val_mse: 31698.9824\n",
      "Epoch 419/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16147.6196 - mae: 50.6046 - mse: 16147.6201 - val_loss: 31686.8691 - val_mae: 53.8289 - val_mse: 31686.8672\n",
      "Epoch 420/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16152.8539 - mae: 51.2344 - mse: 16152.8555 - val_loss: 31679.6786 - val_mae: 54.0779 - val_mse: 31679.6797\n",
      "Epoch 421/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16186.9262 - mae: 51.2846 - mse: 16186.9287 - val_loss: 31676.9726 - val_mae: 53.9334 - val_mse: 31676.9727\n",
      "Epoch 422/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16176.7943 - mae: 51.1175 - mse: 16176.7959 - val_loss: 31676.0927 - val_mae: 53.7395 - val_mse: 31676.0918\n",
      "Epoch 423/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16126.2799 - mae: 50.7371 - mse: 16126.2803 - val_loss: 31669.6115 - val_mae: 53.9344 - val_mse: 31669.6133\n",
      "Epoch 424/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16146.7771 - mae: 51.3890 - mse: 16146.7754 - val_loss: 31666.9869 - val_mae: 53.8490 - val_mse: 31666.9883\n",
      "Epoch 425/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16112.3876 - mae: 51.1799 - mse: 16112.3896 - val_loss: 31661.1787 - val_mae: 53.9215 - val_mse: 31661.1797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16190.1962 - mae: 51.2277 - mse: 16190.1934 - val_loss: 31659.0997 - val_mae: 53.8316 - val_mse: 31659.0977\n",
      "Epoch 427/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16067.4967 - mae: 51.0346 - mse: 16067.4971 - val_loss: 31653.5521 - val_mae: 53.9019 - val_mse: 31653.5508\n",
      "Epoch 428/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16114.8338 - mae: 51.0768 - mse: 16114.8340 - val_loss: 31646.9806 - val_mae: 54.0924 - val_mse: 31646.9805\n",
      "Epoch 429/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16162.2220 - mae: 51.2097 - mse: 16162.2227 - val_loss: 31643.7429 - val_mae: 53.9889 - val_mse: 31643.7422\n",
      "Epoch 430/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16146.0875 - mae: 50.5907 - mse: 16146.0889 - val_loss: 31640.2227 - val_mae: 53.9088 - val_mse: 31640.2227\n",
      "Epoch 431/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16139.4273 - mae: 50.9243 - mse: 16139.4258 - val_loss: 31636.3176 - val_mae: 53.8715 - val_mse: 31636.3184\n",
      "Epoch 432/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16169.1895 - mae: 50.8494 - mse: 16169.1875 - val_loss: 31634.2171 - val_mae: 53.7238 - val_mse: 31634.2148\n",
      "Epoch 433/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16196.0517 - mae: 51.1576 - mse: 16196.0527 - val_loss: 31634.8559 - val_mae: 53.4099 - val_mse: 31634.8555\n",
      "Epoch 434/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16068.2474 - mae: 50.3820 - mse: 16068.2471 - val_loss: 31623.3125 - val_mae: 53.8863 - val_mse: 31623.3125\n",
      "Epoch 435/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16042.7845 - mae: 50.5293 - mse: 16042.7852 - val_loss: 31616.1058 - val_mae: 54.0533 - val_mse: 31616.1074\n",
      "Epoch 436/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16067.2897 - mae: 51.1408 - mse: 16067.2930 - val_loss: 31618.0093 - val_mae: 53.5658 - val_mse: 31618.0098\n",
      "Epoch 437/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16063.0993 - mae: 50.1111 - mse: 16063.0996 - val_loss: 31613.1616 - val_mae: 53.5718 - val_mse: 31613.1621\n",
      "Epoch 438/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16179.3346 - mae: 51.2645 - mse: 16179.3398 - val_loss: 31604.4790 - val_mae: 53.7715 - val_mse: 31604.4805\n",
      "Epoch 439/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16090.1330 - mae: 50.9141 - mse: 16090.1348 - val_loss: 31601.8263 - val_mae: 53.6328 - val_mse: 31601.8301\n",
      "Epoch 440/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16196.7353 - mae: 50.7993 - mse: 16196.7373 - val_loss: 31600.0453 - val_mae: 53.4685 - val_mse: 31600.0449\n",
      "Epoch 441/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16080.6605 - mae: 50.8185 - mse: 16080.6592 - val_loss: 31588.9986 - val_mae: 53.9233 - val_mse: 31588.9980\n",
      "Epoch 442/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16034.8025 - mae: 50.9740 - mse: 16034.8027 - val_loss: 31584.7209 - val_mae: 53.8666 - val_mse: 31584.7227\n",
      "Epoch 443/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16122.2323 - mae: 51.0706 - mse: 16122.2334 - val_loss: 31587.4149 - val_mae: 53.4408 - val_mse: 31587.4141\n",
      "Epoch 444/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16127.5806 - mae: 50.6801 - mse: 16127.5771 - val_loss: 31580.7930 - val_mae: 53.5683 - val_mse: 31580.7949\n",
      "Epoch 445/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 16120.3671 - mae: 50.8681 - mse: 16120.3701 - val_loss: 31575.9951 - val_mae: 53.5250 - val_mse: 31575.9980\n",
      "Epoch 446/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16197.5039 - mae: 50.5753 - mse: 16197.5059 - val_loss: 31585.3770 - val_mae: 52.8609 - val_mse: 31585.3770\n",
      "Epoch 447/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 16100.9958 - mae: 50.3561 - mse: 16100.9951 - val_loss: 31563.1712 - val_mae: 53.7914 - val_mse: 31563.1719\n",
      "Epoch 448/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16053.7349 - mae: 50.8322 - mse: 16053.7354 - val_loss: 31563.7910 - val_mae: 53.4570 - val_mse: 31563.7891\n",
      "Epoch 449/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16047.1310 - mae: 50.9149 - mse: 16047.1299 - val_loss: 31552.3020 - val_mae: 54.0019 - val_mse: 31552.3008\n",
      "Epoch 450/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16033.6279 - mae: 51.1589 - mse: 16033.6309 - val_loss: 31546.5332 - val_mae: 53.9631 - val_mse: 31546.5352\n",
      "Epoch 451/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16064.8165 - mae: 51.4166 - mse: 16064.8184 - val_loss: 31545.7130 - val_mae: 53.5993 - val_mse: 31545.7129\n",
      "Epoch 452/1000\n",
      "3200/3200 [==============================] - 0s 47us/sample - loss: 16003.2860 - mae: 50.8409 - mse: 16003.2891 - val_loss: 31540.5811 - val_mae: 53.6686 - val_mse: 31540.5801\n",
      "Epoch 453/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 16047.7322 - mae: 51.0577 - mse: 16047.7324 - val_loss: 31540.8094 - val_mae: 53.3353 - val_mse: 31540.8105\n",
      "Epoch 454/1000\n",
      "3200/3200 [==============================] - 0s 49us/sample - loss: 16019.6739 - mae: 50.5936 - mse: 16019.6748 - val_loss: 31546.0978 - val_mae: 52.8399 - val_mse: 31546.0977\n",
      "Epoch 455/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 16025.5548 - mae: 50.2870 - mse: 16025.5537 - val_loss: 31529.7112 - val_mae: 53.4266 - val_mse: 31529.7109\n",
      "Epoch 456/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 16081.5412 - mae: 51.0543 - mse: 16081.5410 - val_loss: 31523.5806 - val_mae: 53.4633 - val_mse: 31523.5801\n",
      "Epoch 457/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15980.3273 - mae: 50.6000 - mse: 15980.3291 - val_loss: 31518.4594 - val_mae: 53.4903 - val_mse: 31518.4609\n",
      "Epoch 458/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16004.1533 - mae: 50.4114 - mse: 16004.1533 - val_loss: 31515.1792 - val_mae: 53.4305 - val_mse: 31515.1777\n",
      "Epoch 459/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16018.1206 - mae: 50.6876 - mse: 16018.1211 - val_loss: 31509.2760 - val_mae: 53.4538 - val_mse: 31509.2754\n",
      "Epoch 460/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16038.2142 - mae: 51.1883 - mse: 16038.2148 - val_loss: 31499.4131 - val_mae: 53.8451 - val_mse: 31499.4141\n",
      "Epoch 461/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15956.6598 - mae: 50.7452 - mse: 15956.6572 - val_loss: 31501.2262 - val_mae: 53.3174 - val_mse: 31501.2246\n",
      "Epoch 462/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16083.3812 - mae: 50.8213 - mse: 16083.3799 - val_loss: 31491.0365 - val_mae: 53.6832 - val_mse: 31491.0352\n",
      "Epoch 463/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16053.7929 - mae: 50.6028 - mse: 16053.7959 - val_loss: 31490.2308 - val_mae: 53.3557 - val_mse: 31490.2305\n",
      "Epoch 464/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 16021.2740 - mae: 49.9580 - mse: 16021.2725 - val_loss: 31486.6702 - val_mae: 53.3022 - val_mse: 31486.6699\n",
      "Epoch 465/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 16024.4371 - mae: 50.7207 - mse: 16024.4414 - val_loss: 31479.0829 - val_mae: 53.4599 - val_mse: 31479.0820\n",
      "Epoch 466/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15998.8348 - mae: 50.4904 - mse: 15998.8359 - val_loss: 31485.0764 - val_mae: 52.8819 - val_mse: 31485.0781\n",
      "Epoch 467/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15981.9853 - mae: 50.3237 - mse: 15981.9824 - val_loss: 31472.1071 - val_mae: 53.2827 - val_mse: 31472.1055\n",
      "Epoch 468/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 16010.9208 - mae: 50.4595 - mse: 16010.9209 - val_loss: 31462.1536 - val_mae: 53.6740 - val_mse: 31462.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 16035.2363 - mae: 50.7333 - mse: 16035.2363 - val_loss: 31459.4023 - val_mae: 53.4458 - val_mse: 31459.4023\n",
      "Epoch 470/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 16086.7337 - mae: 50.4231 - mse: 16086.7363 - val_loss: 31464.5491 - val_mae: 52.9055 - val_mse: 31464.5508\n",
      "Epoch 471/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15983.3797 - mae: 50.2418 - mse: 15983.3789 - val_loss: 31451.0088 - val_mae: 53.3666 - val_mse: 31451.0098\n",
      "Epoch 472/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15989.9384 - mae: 50.6049 - mse: 15989.9375 - val_loss: 31450.3238 - val_mae: 53.1257 - val_mse: 31450.3223\n",
      "Epoch 473/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15896.9344 - mae: 50.3419 - mse: 15896.9346 - val_loss: 31437.5797 - val_mae: 53.6254 - val_mse: 31437.5781\n",
      "Epoch 474/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15864.8628 - mae: 50.9910 - mse: 15864.8613 - val_loss: 31428.7001 - val_mae: 53.9334 - val_mse: 31428.6992\n",
      "Epoch 475/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15996.5653 - mae: 50.4094 - mse: 15996.5674 - val_loss: 31433.8223 - val_mae: 53.2542 - val_mse: 31433.8223\n",
      "Epoch 476/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15925.6744 - mae: 50.8741 - mse: 15925.6729 - val_loss: 31420.7203 - val_mae: 53.9300 - val_mse: 31420.7207\n",
      "Epoch 477/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15898.1474 - mae: 50.6988 - mse: 15898.1504 - val_loss: 31421.2669 - val_mae: 53.4657 - val_mse: 31421.2676\n",
      "Epoch 478/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15899.3842 - mae: 50.2900 - mse: 15899.3838 - val_loss: 31414.3405 - val_mae: 53.4886 - val_mse: 31414.3398\n",
      "Epoch 479/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15925.1949 - mae: 50.3697 - mse: 15925.1963 - val_loss: 31404.6835 - val_mae: 53.9117 - val_mse: 31404.6816\n",
      "Epoch 480/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15958.6883 - mae: 50.4350 - mse: 15958.6865 - val_loss: 31404.8098 - val_mae: 53.5485 - val_mse: 31404.8105\n",
      "Epoch 481/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15923.8736 - mae: 50.6941 - mse: 15923.8721 - val_loss: 31399.6640 - val_mae: 53.4898 - val_mse: 31399.6641\n",
      "Epoch 482/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15923.8141 - mae: 50.6487 - mse: 15923.8135 - val_loss: 31399.1611 - val_mae: 53.1907 - val_mse: 31399.1602\n",
      "Epoch 483/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15818.5684 - mae: 49.9936 - mse: 15818.5664 - val_loss: 31387.3244 - val_mae: 53.7948 - val_mse: 31387.3223\n",
      "Epoch 484/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15921.8962 - mae: 50.4009 - mse: 15921.8936 - val_loss: 31382.1878 - val_mae: 53.8067 - val_mse: 31382.1875\n",
      "Epoch 485/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 16056.0308 - mae: 51.1967 - mse: 16056.0283 - val_loss: 31382.6214 - val_mae: 53.3033 - val_mse: 31382.6230\n",
      "Epoch 486/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15918.4564 - mae: 50.3774 - mse: 15918.4551 - val_loss: 31377.9760 - val_mae: 53.2046 - val_mse: 31377.9746\n",
      "Epoch 487/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15944.5418 - mae: 50.3634 - mse: 15944.5430 - val_loss: 31375.1511 - val_mae: 53.1393 - val_mse: 31375.1504\n",
      "Epoch 488/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15831.8037 - mae: 50.5538 - mse: 15831.8027 - val_loss: 31366.7732 - val_mae: 53.3030 - val_mse: 31366.7754\n",
      "Epoch 489/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15956.9651 - mae: 50.5383 - mse: 15956.9658 - val_loss: 31369.9757 - val_mae: 52.8626 - val_mse: 31369.9746\n",
      "Epoch 490/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15964.5095 - mae: 50.4079 - mse: 15964.5117 - val_loss: 31364.8714 - val_mae: 52.8689 - val_mse: 31364.8691\n",
      "Epoch 491/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15800.8015 - mae: 50.0361 - mse: 15800.7998 - val_loss: 31351.4468 - val_mae: 53.3750 - val_mse: 31351.4492\n",
      "Epoch 492/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15909.4155 - mae: 50.4623 - mse: 15909.4160 - val_loss: 31344.0307 - val_mae: 53.6136 - val_mse: 31344.0273\n",
      "Epoch 493/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15845.9672 - mae: 50.5531 - mse: 15845.9658 - val_loss: 31339.2546 - val_mae: 53.5533 - val_mse: 31339.2520\n",
      "Epoch 494/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15974.7917 - mae: 50.6601 - mse: 15974.7910 - val_loss: 31343.6021 - val_mae: 52.9698 - val_mse: 31343.6016\n",
      "Epoch 495/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15817.6055 - mae: 50.5272 - mse: 15817.6035 - val_loss: 31337.5819 - val_mae: 53.0138 - val_mse: 31337.5820\n",
      "Epoch 496/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15809.1390 - mae: 50.1649 - mse: 15809.1396 - val_loss: 31329.1894 - val_mae: 53.3178 - val_mse: 31329.1895\n",
      "Epoch 497/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15904.5597 - mae: 50.1871 - mse: 15904.5615 - val_loss: 31331.1793 - val_mae: 52.8910 - val_mse: 31331.1777\n",
      "Epoch 498/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15803.2682 - mae: 49.7605 - mse: 15803.2686 - val_loss: 31314.0372 - val_mae: 54.1787 - val_mse: 31314.0371\n",
      "Epoch 499/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15882.5997 - mae: 50.9374 - mse: 15882.5977 - val_loss: 31313.4681 - val_mae: 53.4165 - val_mse: 31313.4668\n",
      "Epoch 500/1000\n",
      "3200/3200 [==============================] - 0s 50us/sample - loss: 15844.8352 - mae: 50.4903 - mse: 15844.8379 - val_loss: 31319.2809 - val_mae: 52.7765 - val_mse: 31319.2832\n",
      "Epoch 501/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 15797.7233 - mae: 49.7642 - mse: 15797.7246 - val_loss: 31304.7425 - val_mae: 53.3705 - val_mse: 31304.7422\n",
      "Epoch 502/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 15892.3018 - mae: 50.5557 - mse: 15892.3047 - val_loss: 31300.8746 - val_mae: 53.2852 - val_mse: 31300.8750\n",
      "Epoch 503/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15816.2013 - mae: 50.3073 - mse: 15816.2012 - val_loss: 31290.8295 - val_mae: 53.7259 - val_mse: 31290.8301\n",
      "Epoch 504/1000\n",
      "3200/3200 [==============================] - 0s 45us/sample - loss: 15848.7995 - mae: 50.5275 - mse: 15848.7998 - val_loss: 31292.2819 - val_mae: 53.1794 - val_mse: 31292.2852\n",
      "Epoch 505/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15743.5655 - mae: 50.1310 - mse: 15743.5625 - val_loss: 31281.4489 - val_mae: 53.7717 - val_mse: 31281.4473\n",
      "Epoch 506/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15752.2956 - mae: 50.0511 - mse: 15752.2979 - val_loss: 31278.5163 - val_mae: 53.6784 - val_mse: 31278.5156\n",
      "Epoch 507/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15831.7370 - mae: 50.9352 - mse: 15831.7363 - val_loss: 31273.3276 - val_mae: 53.7626 - val_mse: 31273.3281\n",
      "Epoch 508/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15781.9287 - mae: 50.0575 - mse: 15781.9287 - val_loss: 31268.0435 - val_mae: 53.6764 - val_mse: 31268.0449\n",
      "Epoch 509/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15922.1034 - mae: 51.5009 - mse: 15922.1035 - val_loss: 31273.8095 - val_mae: 52.9253 - val_mse: 31273.8105\n",
      "Epoch 510/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15853.9173 - mae: 49.7796 - mse: 15853.9160 - val_loss: 31269.0270 - val_mae: 52.8402 - val_mse: 31269.0293\n",
      "Epoch 511/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15806.4403 - mae: 50.0138 - mse: 15806.4434 - val_loss: 31262.9896 - val_mae: 52.9363 - val_mse: 31262.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15867.2459 - mae: 50.7027 - mse: 15867.2451 - val_loss: 31266.1862 - val_mae: 52.5619 - val_mse: 31266.1855\n",
      "Epoch 513/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15829.2779 - mae: 50.2913 - mse: 15829.2764 - val_loss: 31252.0302 - val_mae: 53.0407 - val_mse: 31252.0293\n",
      "Epoch 514/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 15742.0756 - mae: 49.8427 - mse: 15742.0791 - val_loss: 31240.9954 - val_mae: 53.6243 - val_mse: 31240.9922\n",
      "Epoch 515/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15767.7615 - mae: 50.3151 - mse: 15767.7617 - val_loss: 31235.1352 - val_mae: 53.6228 - val_mse: 31235.1328\n",
      "Epoch 516/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15776.6765 - mae: 50.6863 - mse: 15776.6738 - val_loss: 31235.5536 - val_mae: 53.2255 - val_mse: 31235.5547\n",
      "Epoch 517/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15765.7372 - mae: 49.8975 - mse: 15765.7363 - val_loss: 31225.8490 - val_mae: 53.7013 - val_mse: 31225.8477\n",
      "Epoch 518/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15918.8738 - mae: 50.4025 - mse: 15918.8740 - val_loss: 31236.2919 - val_mae: 52.7095 - val_mse: 31236.2930\n",
      "Epoch 519/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15706.5685 - mae: 50.1732 - mse: 15706.5703 - val_loss: 31221.5817 - val_mae: 53.2575 - val_mse: 31221.5801\n",
      "Epoch 520/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15716.8895 - mae: 49.7559 - mse: 15716.8877 - val_loss: 31224.1861 - val_mae: 52.9635 - val_mse: 31224.1855\n",
      "Epoch 521/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15740.6771 - mae: 51.3089 - mse: 15740.6777 - val_loss: 31210.6024 - val_mae: 53.4712 - val_mse: 31210.6016\n",
      "Epoch 522/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15756.4791 - mae: 50.2040 - mse: 15756.4785 - val_loss: 31204.0614 - val_mae: 53.7321 - val_mse: 31204.0625\n",
      "Epoch 523/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15739.2198 - mae: 51.0139 - mse: 15739.2148 - val_loss: 31212.1683 - val_mae: 52.8051 - val_mse: 31212.1680\n",
      "Epoch 524/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 15893.2897 - mae: 49.5658 - mse: 15893.2900 - val_loss: 31208.4121 - val_mae: 52.7549 - val_mse: 31208.4102\n",
      "Epoch 525/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15749.7973 - mae: 49.9840 - mse: 15749.7988 - val_loss: 31191.2908 - val_mae: 53.7497 - val_mse: 31191.2930\n",
      "Epoch 526/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15748.3817 - mae: 50.0944 - mse: 15748.3809 - val_loss: 31206.0522 - val_mae: 52.6191 - val_mse: 31206.0508\n",
      "Epoch 527/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15768.2041 - mae: 50.1897 - mse: 15768.2002 - val_loss: 31181.8308 - val_mae: 53.9747 - val_mse: 31181.8301\n",
      "Epoch 528/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15622.4202 - mae: 51.1164 - mse: 15622.4209 - val_loss: 31182.9179 - val_mae: 53.2893 - val_mse: 31182.9180\n",
      "Epoch 529/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15710.5283 - mae: 50.3361 - mse: 15710.5264 - val_loss: 31178.5588 - val_mae: 53.4160 - val_mse: 31178.5605\n",
      "Epoch 530/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15712.6663 - mae: 49.9002 - mse: 15712.6660 - val_loss: 31175.3333 - val_mae: 53.2092 - val_mse: 31175.3320\n",
      "Epoch 531/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15835.3687 - mae: 50.3723 - mse: 15835.3701 - val_loss: 31175.1425 - val_mae: 53.0086 - val_mse: 31175.1445\n",
      "Epoch 532/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15687.7142 - mae: 49.6294 - mse: 15687.7178 - val_loss: 31168.0344 - val_mae: 53.1089 - val_mse: 31168.0352\n",
      "Epoch 533/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15738.4791 - mae: 50.6193 - mse: 15738.4824 - val_loss: 31157.3281 - val_mae: 53.6636 - val_mse: 31157.3242\n",
      "Epoch 534/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 15658.5127 - mae: 50.4152 - mse: 15658.5127 - val_loss: 31160.6533 - val_mae: 52.9345 - val_mse: 31160.6523\n",
      "Epoch 535/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15735.8745 - mae: 49.8726 - mse: 15735.8789 - val_loss: 31149.7412 - val_mae: 53.3674 - val_mse: 31149.7422\n",
      "Epoch 536/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15758.3148 - mae: 50.3074 - mse: 15758.3154 - val_loss: 31152.8141 - val_mae: 52.7857 - val_mse: 31152.8125\n",
      "Epoch 537/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15795.5237 - mae: 50.1230 - mse: 15795.5254 - val_loss: 31144.8997 - val_mae: 52.9065 - val_mse: 31144.9004\n",
      "Epoch 538/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15612.5138 - mae: 50.0893 - mse: 15612.5146 - val_loss: 31135.0055 - val_mae: 53.3145 - val_mse: 31135.0059\n",
      "Epoch 539/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15751.1632 - mae: 50.2769 - mse: 15751.1611 - val_loss: 31133.7879 - val_mae: 53.2080 - val_mse: 31133.7871\n",
      "Epoch 540/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15650.5345 - mae: 50.1033 - mse: 15650.5371 - val_loss: 31139.2471 - val_mae: 52.5591 - val_mse: 31139.2441\n",
      "Epoch 541/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15680.4929 - mae: 49.7463 - mse: 15680.4941 - val_loss: 31124.7507 - val_mae: 53.2297 - val_mse: 31124.7500\n",
      "Epoch 542/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15719.9003 - mae: 50.0671 - mse: 15719.9023 - val_loss: 31113.2893 - val_mae: 53.8247 - val_mse: 31113.2930\n",
      "Epoch 543/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15691.9993 - mae: 50.1393 - mse: 15691.9971 - val_loss: 31115.5482 - val_mae: 53.2632 - val_mse: 31115.5449\n",
      "Epoch 544/1000\n",
      "3200/3200 [==============================] - 0s 43us/sample - loss: 15688.2903 - mae: 49.8583 - mse: 15688.2891 - val_loss: 31109.7759 - val_mae: 53.4283 - val_mse: 31109.7754\n",
      "Epoch 545/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15638.2413 - mae: 49.6936 - mse: 15638.2422 - val_loss: 31104.9522 - val_mae: 53.7829 - val_mse: 31104.9531\n",
      "Epoch 546/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15733.5791 - mae: 50.7704 - mse: 15733.5752 - val_loss: 31111.1676 - val_mae: 52.7789 - val_mse: 31111.1699\n",
      "Epoch 547/1000\n",
      "3200/3200 [==============================] - 0s 44us/sample - loss: 15685.0268 - mae: 49.9713 - mse: 15685.0303 - val_loss: 31101.7730 - val_mae: 53.1277 - val_mse: 31101.7734\n",
      "Epoch 548/1000\n",
      "3200/3200 [==============================] - 0s 50us/sample - loss: 15625.5662 - mae: 50.1984 - mse: 15625.5635 - val_loss: 31117.0063 - val_mae: 52.2038 - val_mse: 31117.0059\n",
      "Epoch 549/1000\n",
      "3200/3200 [==============================] - 0s 46us/sample - loss: 15663.1457 - mae: 49.1867 - mse: 15663.1426 - val_loss: 31089.2838 - val_mae: 53.4695 - val_mse: 31089.2832\n",
      "Epoch 550/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 15651.5194 - mae: 50.3616 - mse: 15651.5195 - val_loss: 31087.1784 - val_mae: 53.4155 - val_mse: 31087.1797\n",
      "Epoch 551/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15676.8593 - mae: 49.9506 - mse: 15676.8623 - val_loss: 31082.7362 - val_mae: 53.4720 - val_mse: 31082.7344\n",
      "Epoch 552/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 15705.0911 - mae: 50.0039 - mse: 15705.0898 - val_loss: 31081.9869 - val_mae: 53.0517 - val_mse: 31081.9883\n",
      "Epoch 553/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15706.3550 - mae: 49.8775 - mse: 15706.3516 - val_loss: 31079.0934 - val_mae: 53.0387 - val_mse: 31079.0957\n",
      "Epoch 554/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15627.8350 - mae: 50.1101 - mse: 15627.8350 - val_loss: 31072.5749 - val_mae: 53.3013 - val_mse: 31072.5742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15663.2599 - mae: 49.8208 - mse: 15663.2627 - val_loss: 31071.1114 - val_mae: 53.2120 - val_mse: 31071.1133\n",
      "Epoch 556/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15726.7237 - mae: 50.2526 - mse: 15726.7227 - val_loss: 31064.3923 - val_mae: 53.3381 - val_mse: 31064.3926\n",
      "Epoch 557/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15696.1689 - mae: 50.0142 - mse: 15696.1709 - val_loss: 31058.6787 - val_mae: 53.4742 - val_mse: 31058.6777\n",
      "Epoch 558/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15649.0351 - mae: 49.8144 - mse: 15649.0342 - val_loss: 31055.7173 - val_mae: 53.2802 - val_mse: 31055.7148\n",
      "Epoch 559/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15603.3584 - mae: 50.4061 - mse: 15603.3604 - val_loss: 31045.2507 - val_mae: 53.7376 - val_mse: 31045.2500\n",
      "Epoch 560/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15651.0525 - mae: 50.1637 - mse: 15651.0508 - val_loss: 31060.8425 - val_mae: 52.4771 - val_mse: 31060.8418\n",
      "Epoch 561/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15605.1096 - mae: 50.3593 - mse: 15605.1064 - val_loss: 31065.7423 - val_mae: 52.1602 - val_mse: 31065.7422\n",
      "Epoch 562/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 15649.6071 - mae: 49.4389 - mse: 15649.6064 - val_loss: 31037.5445 - val_mae: 53.3590 - val_mse: 31037.5449\n",
      "Epoch 563/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15594.9511 - mae: 50.1476 - mse: 15594.9551 - val_loss: 31038.2348 - val_mae: 53.2158 - val_mse: 31038.2324\n",
      "Epoch 564/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15580.4526 - mae: 49.7956 - mse: 15580.4512 - val_loss: 31037.5138 - val_mae: 52.9480 - val_mse: 31037.5156\n",
      "Epoch 565/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15826.0627 - mae: 50.4451 - mse: 15826.0625 - val_loss: 31038.3642 - val_mae: 52.5718 - val_mse: 31038.3652\n",
      "Epoch 566/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15680.7041 - mae: 49.9924 - mse: 15680.7041 - val_loss: 31033.5646 - val_mae: 52.7307 - val_mse: 31033.5645\n",
      "Epoch 567/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15569.7255 - mae: 49.2521 - mse: 15569.7227 - val_loss: 31017.6654 - val_mae: 53.2869 - val_mse: 31017.6641\n",
      "Epoch 568/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15661.8193 - mae: 49.7956 - mse: 15661.8164 - val_loss: 31020.2930 - val_mae: 52.8082 - val_mse: 31020.2930\n",
      "Epoch 569/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15474.6125 - mae: 49.4189 - mse: 15474.6104 - val_loss: 31007.7870 - val_mae: 53.8635 - val_mse: 31007.7871\n",
      "Epoch 570/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15520.9082 - mae: 50.6840 - mse: 15520.9072 - val_loss: 31012.5771 - val_mae: 52.8424 - val_mse: 31012.5801\n",
      "Epoch 571/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15552.8200 - mae: 49.8928 - mse: 15552.8213 - val_loss: 31003.4171 - val_mae: 53.2005 - val_mse: 31003.4180\n",
      "Epoch 572/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 15569.4002 - mae: 49.9076 - mse: 15569.3975 - val_loss: 30996.5050 - val_mae: 53.5339 - val_mse: 30996.5078\n",
      "Epoch 573/1000\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 10961.7021 - mae: 47.8941 - mse: 10961.70 - 0s 34us/sample - loss: 15592.8513 - mae: 49.6262 - mse: 15592.8516 - val_loss: 31000.4937 - val_mae: 52.9165 - val_mse: 31000.4922\n",
      "Epoch 574/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15619.6170 - mae: 50.1669 - mse: 15619.6152 - val_loss: 31001.7903 - val_mae: 52.6850 - val_mse: 31001.7871\n",
      "Epoch 575/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15530.9631 - mae: 49.2953 - mse: 15530.9629 - val_loss: 30989.5602 - val_mae: 53.3523 - val_mse: 30989.5605\n",
      "Epoch 576/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15560.2037 - mae: 50.2025 - mse: 15560.2021 - val_loss: 30983.1497 - val_mae: 53.3254 - val_mse: 30983.1504\n",
      "Epoch 577/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15563.8695 - mae: 50.0686 - mse: 15563.8701 - val_loss: 30978.7800 - val_mae: 53.1067 - val_mse: 30978.7832\n",
      "Epoch 578/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15555.0336 - mae: 50.3482 - mse: 15555.0303 - val_loss: 30987.0902 - val_mae: 52.3671 - val_mse: 30987.0898\n",
      "Epoch 579/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15552.2404 - mae: 49.2811 - mse: 15552.2402 - val_loss: 30979.2923 - val_mae: 52.5056 - val_mse: 30979.2891\n",
      "Epoch 580/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15545.0577 - mae: 49.9646 - mse: 15545.0615 - val_loss: 30973.4164 - val_mae: 52.7920 - val_mse: 30973.4180\n",
      "Epoch 581/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15562.2031 - mae: 49.5530 - mse: 15562.2012 - val_loss: 30970.6958 - val_mae: 52.8667 - val_mse: 30970.6953\n",
      "Epoch 582/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 15638.3687 - mae: 49.1575 - mse: 15638.3691 - val_loss: 30967.7841 - val_mae: 52.8370 - val_mse: 30967.7832\n",
      "Epoch 583/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15524.5033 - mae: 49.8923 - mse: 15524.5010 - val_loss: 30959.4115 - val_mae: 52.9128 - val_mse: 30959.4121\n",
      "Epoch 584/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15464.4370 - mae: 49.5645 - mse: 15464.4375 - val_loss: 30953.6261 - val_mae: 53.2303 - val_mse: 30953.6250\n",
      "Epoch 585/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15472.9890 - mae: 49.8893 - mse: 15472.9863 - val_loss: 30951.6261 - val_mae: 53.0995 - val_mse: 30951.6270\n",
      "Epoch 586/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15568.0770 - mae: 50.1554 - mse: 15568.0752 - val_loss: 30948.5811 - val_mae: 53.3000 - val_mse: 30948.5801\n",
      "Epoch 587/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15609.5169 - mae: 49.7074 - mse: 15609.5186 - val_loss: 30945.7098 - val_mae: 53.0880 - val_mse: 30945.7109\n",
      "Epoch 588/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15429.7124 - mae: 49.8266 - mse: 15429.7139 - val_loss: 30941.5811 - val_mae: 53.1892 - val_mse: 30941.5820\n",
      "Epoch 589/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15548.5764 - mae: 49.8554 - mse: 15548.5762 - val_loss: 30936.4400 - val_mae: 53.0980 - val_mse: 30936.4395\n",
      "Epoch 590/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15494.3418 - mae: 48.9681 - mse: 15494.3398 - val_loss: 30933.5657 - val_mae: 53.0572 - val_mse: 30933.5645\n",
      "Epoch 591/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15617.9785 - mae: 50.1677 - mse: 15617.9775 - val_loss: 30951.4278 - val_mae: 51.9848 - val_mse: 30951.4277\n",
      "Epoch 592/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15541.0723 - mae: 49.7943 - mse: 15541.0684 - val_loss: 30943.2214 - val_mae: 52.1711 - val_mse: 30943.2207\n",
      "Epoch 593/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15517.3309 - mae: 49.3819 - mse: 15517.3311 - val_loss: 30932.2943 - val_mae: 52.5022 - val_mse: 30932.2949\n",
      "Epoch 594/1000\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 7778.6309 - mae: 45.2433 - mse: 7778.63 - 0s 38us/sample - loss: 15707.0789 - mae: 49.1684 - mse: 15707.0801 - val_loss: 30926.3552 - val_mae: 52.5843 - val_mse: 30926.3574\n",
      "Epoch 595/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 15432.1885 - mae: 49.7477 - mse: 15432.1904 - val_loss: 30914.4984 - val_mae: 53.2389 - val_mse: 30914.5000\n",
      "Epoch 596/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 15626.7838 - mae: 49.9397 - mse: 15626.7842 - val_loss: 30922.5148 - val_mae: 52.4300 - val_mse: 30922.5156\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15479.7535 - mae: 49.1593 - mse: 15479.7529 - val_loss: 30909.0750 - val_mae: 53.0071 - val_mse: 30909.0781\n",
      "Epoch 598/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15593.2733 - mae: 50.2770 - mse: 15593.2725 - val_loss: 30913.3330 - val_mae: 52.4272 - val_mse: 30913.3320\n",
      "Epoch 599/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15485.1630 - mae: 49.2741 - mse: 15485.1621 - val_loss: 30900.8128 - val_mae: 53.0420 - val_mse: 30900.8145\n",
      "Epoch 600/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 15517.5361 - mae: 49.2077 - mse: 15517.5342 - val_loss: 30898.8072 - val_mae: 52.9045 - val_mse: 30898.8066\n",
      "Epoch 601/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15549.5012 - mae: 49.5882 - mse: 15549.5039 - val_loss: 30896.8411 - val_mae: 52.7718 - val_mse: 30896.8398\n",
      "Epoch 602/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15561.9463 - mae: 49.5864 - mse: 15561.9453 - val_loss: 30888.9643 - val_mae: 53.0604 - val_mse: 30888.9648\n",
      "Epoch 603/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15445.5151 - mae: 49.9169 - mse: 15445.5137 - val_loss: 30893.2852 - val_mae: 52.4526 - val_mse: 30893.2852\n",
      "Epoch 604/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15529.9946 - mae: 49.3122 - mse: 15529.9951 - val_loss: 30883.0513 - val_mae: 52.9711 - val_mse: 30883.0527\n",
      "Epoch 605/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15529.2094 - mae: 49.7036 - mse: 15529.2070 - val_loss: 30896.8125 - val_mae: 52.0392 - val_mse: 30896.8105\n",
      "Epoch 606/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15470.0117 - mae: 49.0857 - mse: 15470.0117 - val_loss: 30872.6324 - val_mae: 53.3308 - val_mse: 30872.6328\n",
      "Epoch 607/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15547.7372 - mae: 50.0233 - mse: 15547.7354 - val_loss: 30890.9730 - val_mae: 51.9689 - val_mse: 30890.9727\n",
      "Epoch 608/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15460.2475 - mae: 49.0740 - mse: 15460.2451 - val_loss: 30873.7751 - val_mae: 52.6204 - val_mse: 30873.7734\n",
      "Epoch 609/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15433.0023 - mae: 49.1766 - mse: 15433.0000 - val_loss: 30871.3411 - val_mae: 52.6233 - val_mse: 30871.3398\n",
      "Epoch 610/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15545.7933 - mae: 49.3934 - mse: 15545.7930 - val_loss: 30869.6337 - val_mae: 52.5952 - val_mse: 30869.6328\n",
      "Epoch 611/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15466.3157 - mae: 49.1901 - mse: 15466.3154 - val_loss: 30872.6615 - val_mae: 52.2083 - val_mse: 30872.6602\n",
      "Epoch 612/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15490.5547 - mae: 49.7387 - mse: 15490.5537 - val_loss: 30859.3824 - val_mae: 52.7065 - val_mse: 30859.3809\n",
      "Epoch 613/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15437.9984 - mae: 49.7007 - mse: 15438.0000 - val_loss: 30878.7000 - val_mae: 51.6628 - val_mse: 30878.6992\n",
      "Epoch 614/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15455.4232 - mae: 48.4871 - mse: 15455.4199 - val_loss: 30843.2273 - val_mae: 53.5329 - val_mse: 30843.2266\n",
      "Epoch 615/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15483.7575 - mae: 49.5789 - mse: 15483.7588 - val_loss: 30851.3577 - val_mae: 52.4619 - val_mse: 30851.3574\n",
      "Epoch 616/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15390.4921 - mae: 49.5347 - mse: 15390.4951 - val_loss: 30840.4665 - val_mae: 52.8561 - val_mse: 30840.4668\n",
      "Epoch 617/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15438.1337 - mae: 49.8882 - mse: 15438.1348 - val_loss: 30834.7324 - val_mae: 53.2736 - val_mse: 30834.7305\n",
      "Epoch 618/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15430.0209 - mae: 49.6587 - mse: 15430.0225 - val_loss: 30830.8700 - val_mae: 53.0753 - val_mse: 30830.8691\n",
      "Epoch 619/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15441.6682 - mae: 49.7310 - mse: 15441.6689 - val_loss: 30840.3251 - val_mae: 52.3024 - val_mse: 30840.3242\n",
      "Epoch 620/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15519.3156 - mae: 48.7755 - mse: 15519.3154 - val_loss: 30841.9839 - val_mae: 52.1614 - val_mse: 30841.9844\n",
      "Epoch 621/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15384.9724 - mae: 50.2524 - mse: 15384.9727 - val_loss: 30825.0433 - val_mae: 52.6520 - val_mse: 30825.0449\n",
      "Epoch 622/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15438.8725 - mae: 49.1029 - mse: 15438.8740 - val_loss: 30825.3604 - val_mae: 52.4801 - val_mse: 30825.3594\n",
      "Epoch 623/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15468.2909 - mae: 49.3696 - mse: 15468.2900 - val_loss: 30817.6474 - val_mae: 52.7693 - val_mse: 30817.6484\n",
      "Epoch 624/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15422.1885 - mae: 48.7692 - mse: 15422.1875 - val_loss: 30820.3998 - val_mae: 52.4792 - val_mse: 30820.4004\n",
      "Epoch 625/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15501.7796 - mae: 49.5030 - mse: 15501.7803 - val_loss: 30810.9107 - val_mae: 52.6252 - val_mse: 30810.9121\n",
      "Epoch 626/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15459.6543 - mae: 49.2169 - mse: 15459.6572 - val_loss: 30826.0090 - val_mae: 51.8555 - val_mse: 30826.0117\n",
      "Epoch 627/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15425.9895 - mae: 48.8000 - mse: 15425.9883 - val_loss: 30808.1236 - val_mae: 52.5466 - val_mse: 30808.1230\n",
      "Epoch 628/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15522.6449 - mae: 49.4604 - mse: 15522.6416 - val_loss: 30805.1669 - val_mae: 52.4574 - val_mse: 30805.1680\n",
      "Epoch 629/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15392.2462 - mae: 49.5925 - mse: 15392.2490 - val_loss: 30805.9519 - val_mae: 52.3381 - val_mse: 30805.9531\n",
      "Epoch 630/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15493.2634 - mae: 49.6632 - mse: 15493.2637 - val_loss: 30821.6239 - val_mae: 51.5508 - val_mse: 30821.6250\n",
      "Epoch 631/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15373.6983 - mae: 48.8170 - mse: 15373.6992 - val_loss: 30792.0955 - val_mae: 52.8466 - val_mse: 30792.0918\n",
      "Epoch 632/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15353.1533 - mae: 49.1292 - mse: 15353.1533 - val_loss: 30787.5658 - val_mae: 52.9427 - val_mse: 30787.5645\n",
      "Epoch 633/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15410.1657 - mae: 49.1657 - mse: 15410.1621 - val_loss: 30792.5227 - val_mae: 52.7296 - val_mse: 30792.5234\n",
      "Epoch 634/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15379.6389 - mae: 49.4814 - mse: 15379.6377 - val_loss: 30786.5278 - val_mae: 52.7035 - val_mse: 30786.5273\n",
      "Epoch 635/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15368.1384 - mae: 49.2144 - mse: 15368.1367 - val_loss: 30784.0047 - val_mae: 52.5602 - val_mse: 30784.0020\n",
      "Epoch 636/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15459.9635 - mae: 49.0524 - mse: 15459.9629 - val_loss: 30786.7414 - val_mae: 52.1439 - val_mse: 30786.7422\n",
      "Epoch 637/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15343.2533 - mae: 49.0401 - mse: 15343.2510 - val_loss: 30776.1398 - val_mae: 52.5206 - val_mse: 30776.1406\n",
      "Epoch 638/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15513.3352 - mae: 48.9320 - mse: 15513.3379 - val_loss: 30769.5289 - val_mae: 52.7742 - val_mse: 30769.5332\n",
      "Epoch 639/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15401.6377 - mae: 49.7559 - mse: 15401.6377 - val_loss: 30776.5848 - val_mae: 52.1230 - val_mse: 30776.5859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 640/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15278.9790 - mae: 48.3978 - mse: 15278.9785 - val_loss: 30757.8607 - val_mae: 53.2334 - val_mse: 30757.8594\n",
      "Epoch 641/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15319.3035 - mae: 50.1333 - mse: 15319.3037 - val_loss: 30761.3258 - val_mae: 52.9415 - val_mse: 30761.3242\n",
      "Epoch 642/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 15457.2358 - mae: 48.6252 - mse: 15457.2363 - val_loss: 30772.5919 - val_mae: 51.9298 - val_mse: 30772.5898\n",
      "Epoch 643/1000\n",
      "3200/3200 [==============================] - 0s 49us/sample - loss: 15411.2659 - mae: 49.2371 - mse: 15411.2646 - val_loss: 30755.0450 - val_mae: 53.1334 - val_mse: 30755.0449\n",
      "Epoch 644/1000\n",
      "3200/3200 [==============================] - 0s 47us/sample - loss: 15370.6700 - mae: 49.8206 - mse: 15370.6709 - val_loss: 30758.8498 - val_mae: 52.3914 - val_mse: 30758.8496\n",
      "Epoch 645/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15343.4847 - mae: 49.2543 - mse: 15343.4873 - val_loss: 30772.1965 - val_mae: 51.5617 - val_mse: 30772.1953\n",
      "Epoch 646/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 15356.5260 - mae: 48.5547 - mse: 15356.5264 - val_loss: 30754.1244 - val_mae: 52.2871 - val_mse: 30754.1250\n",
      "Epoch 647/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15265.3441 - mae: 49.3395 - mse: 15265.3438 - val_loss: 30743.0533 - val_mae: 53.3380 - val_mse: 30743.0508\n",
      "Epoch 648/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15460.4618 - mae: 50.1011 - mse: 15460.4629 - val_loss: 30756.4512 - val_mae: 51.8067 - val_mse: 30756.4492\n",
      "Epoch 649/1000\n",
      "3200/3200 [==============================] - 0s 42us/sample - loss: 15322.7768 - mae: 48.0465 - mse: 15322.7764 - val_loss: 30748.5877 - val_mae: 51.9949 - val_mse: 30748.5879\n",
      "Epoch 650/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15360.5900 - mae: 49.8664 - mse: 15360.5898 - val_loss: 30752.6533 - val_mae: 51.6494 - val_mse: 30752.6523\n",
      "Epoch 651/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15281.8846 - mae: 49.0655 - mse: 15281.8838 - val_loss: 30738.1663 - val_mae: 52.0402 - val_mse: 30738.1641\n",
      "Epoch 652/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15385.9036 - mae: 49.5899 - mse: 15385.9023 - val_loss: 30735.3910 - val_mae: 51.9712 - val_mse: 30735.3906\n",
      "Epoch 653/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15418.2975 - mae: 48.6646 - mse: 15418.2959 - val_loss: 30733.6931 - val_mae: 51.9680 - val_mse: 30733.6895\n",
      "Epoch 654/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15302.7845 - mae: 49.1347 - mse: 15302.7852 - val_loss: 30728.1875 - val_mae: 52.0282 - val_mse: 30728.1895\n",
      "Epoch 655/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15361.6373 - mae: 49.0121 - mse: 15361.6387 - val_loss: 30729.2028 - val_mae: 51.7933 - val_mse: 30729.2031\n",
      "Epoch 656/1000\n",
      "3200/3200 [==============================] - 0s 47us/sample - loss: 15380.5592 - mae: 49.2018 - mse: 15380.5596 - val_loss: 30727.5279 - val_mae: 52.0537 - val_mse: 30727.5254\n",
      "Epoch 657/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15390.2602 - mae: 48.8801 - mse: 15390.2617 - val_loss: 30716.9755 - val_mae: 52.4410 - val_mse: 30716.9727\n",
      "Epoch 658/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 15292.1235 - mae: 48.7483 - mse: 15292.1240 - val_loss: 30710.3103 - val_mae: 52.5553 - val_mse: 30710.3125\n",
      "Epoch 659/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15365.3226 - mae: 49.2631 - mse: 15365.3203 - val_loss: 30706.6823 - val_mae: 52.4922 - val_mse: 30706.6816\n",
      "Epoch 660/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15313.8366 - mae: 49.5207 - mse: 15313.8350 - val_loss: 30704.5753 - val_mae: 52.2496 - val_mse: 30704.5723\n",
      "Epoch 661/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15311.2036 - mae: 48.5892 - mse: 15311.2061 - val_loss: 30702.3934 - val_mae: 52.1443 - val_mse: 30702.3945\n",
      "Epoch 662/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15323.7794 - mae: 49.7250 - mse: 15323.7822 - val_loss: 30722.8165 - val_mae: 51.2597 - val_mse: 30722.8145\n",
      "Epoch 663/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15175.1910 - mae: 48.7725 - mse: 15175.1904 - val_loss: 30687.7929 - val_mae: 52.7050 - val_mse: 30687.7949\n",
      "Epoch 664/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15354.0449 - mae: 49.4696 - mse: 15354.0459 - val_loss: 30695.4988 - val_mae: 52.0395 - val_mse: 30695.5000\n",
      "Epoch 665/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15362.1442 - mae: 48.5245 - mse: 15362.1416 - val_loss: 30686.5000 - val_mae: 52.5569 - val_mse: 30686.5000\n",
      "Epoch 666/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15332.2025 - mae: 49.3380 - mse: 15332.2021 - val_loss: 30697.9644 - val_mae: 51.7270 - val_mse: 30697.9648\n",
      "Epoch 667/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15344.9277 - mae: 48.8719 - mse: 15344.9277 - val_loss: 30684.2780 - val_mae: 52.3433 - val_mse: 30684.2773\n",
      "Epoch 668/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15231.1011 - mae: 49.1576 - mse: 15231.1035 - val_loss: 30676.7791 - val_mae: 52.4032 - val_mse: 30676.7793\n",
      "Epoch 669/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15294.4052 - mae: 49.1817 - mse: 15294.4053 - val_loss: 30685.0803 - val_mae: 51.7006 - val_mse: 30685.0801\n",
      "Epoch 670/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15307.4433 - mae: 48.7456 - mse: 15307.4424 - val_loss: 30674.3502 - val_mae: 51.9904 - val_mse: 30674.3477\n",
      "Epoch 671/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15288.8482 - mae: 48.5235 - mse: 15288.8467 - val_loss: 30679.0993 - val_mae: 51.8294 - val_mse: 30679.0996\n",
      "Epoch 672/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15388.9494 - mae: 48.6162 - mse: 15388.9492 - val_loss: 30665.2095 - val_mae: 52.9808 - val_mse: 30665.2109\n",
      "Epoch 673/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15318.7496 - mae: 49.3821 - mse: 15318.7510 - val_loss: 30672.7306 - val_mae: 51.8704 - val_mse: 30672.7324\n",
      "Epoch 674/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15480.1786 - mae: 48.0825 - mse: 15480.1758 - val_loss: 30662.3567 - val_mae: 52.6509 - val_mse: 30662.3574\n",
      "Epoch 675/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15266.4980 - mae: 49.3675 - mse: 15266.5000 - val_loss: 30661.3787 - val_mae: 52.2966 - val_mse: 30661.3809\n",
      "Epoch 676/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15243.3500 - mae: 49.0249 - mse: 15243.3516 - val_loss: 30658.1266 - val_mae: 52.2743 - val_mse: 30658.1270\n",
      "Epoch 677/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15217.4669 - mae: 48.9562 - mse: 15217.4678 - val_loss: 30657.4025 - val_mae: 52.0664 - val_mse: 30657.4023\n",
      "Epoch 678/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15176.3186 - mae: 48.7596 - mse: 15176.3174 - val_loss: 30649.8078 - val_mae: 52.3172 - val_mse: 30649.8066\n",
      "Epoch 679/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15325.8898 - mae: 48.7694 - mse: 15325.8896 - val_loss: 30648.7043 - val_mae: 52.2137 - val_mse: 30648.7070\n",
      "Epoch 680/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15372.8009 - mae: 49.1011 - mse: 15372.7979 - val_loss: 30680.9917 - val_mae: 51.0307 - val_mse: 30680.9941\n",
      "Epoch 681/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15255.4655 - mae: 48.8090 - mse: 15255.4658 - val_loss: 30650.9547 - val_mae: 51.7643 - val_mse: 30650.9551\n",
      "Epoch 682/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15119.4233 - mae: 47.9861 - mse: 15119.4209 - val_loss: 30632.3404 - val_mae: 53.0636 - val_mse: 30632.3398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 15026.6875 - mae: 49.9169 - mse: 15026.68 - 0s 32us/sample - loss: 15218.9545 - mae: 49.6286 - mse: 15218.9521 - val_loss: 30645.5858 - val_mae: 51.9056 - val_mse: 30645.5879\n",
      "Epoch 684/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15306.9484 - mae: 48.0455 - mse: 15306.9502 - val_loss: 30648.2604 - val_mae: 51.7184 - val_mse: 30648.2598\n",
      "Epoch 685/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15293.2301 - mae: 49.9012 - mse: 15293.2275 - val_loss: 30631.2097 - val_mae: 52.3399 - val_mse: 30631.2129\n",
      "Epoch 686/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15304.5398 - mae: 48.9858 - mse: 15304.5391 - val_loss: 30641.3604 - val_mae: 51.6118 - val_mse: 30641.3594\n",
      "Epoch 687/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15213.8893 - mae: 48.4932 - mse: 15213.8916 - val_loss: 30625.8394 - val_mae: 52.1660 - val_mse: 30625.8379\n",
      "Epoch 688/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15153.0074 - mae: 47.8755 - mse: 15153.0059 - val_loss: 30619.2048 - val_mae: 53.5502 - val_mse: 30619.2051\n",
      "Epoch 689/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 15308.7868 - mae: 49.9456 - mse: 15308.7852 - val_loss: 30618.0237 - val_mae: 52.4642 - val_mse: 30618.0254\n",
      "Epoch 690/1000\n",
      "3200/3200 [==============================] - 0s 50us/sample - loss: 15184.2623 - mae: 49.1982 - mse: 15184.2627 - val_loss: 30616.0401 - val_mae: 52.2442 - val_mse: 30616.0391\n",
      "Epoch 691/1000\n",
      "3200/3200 [==============================] - 0s 50us/sample - loss: 15307.0130 - mae: 48.9072 - mse: 15307.0117 - val_loss: 30646.9789 - val_mae: 51.0456 - val_mse: 30646.9805\n",
      "Epoch 692/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15184.7402 - mae: 48.1180 - mse: 15184.7422 - val_loss: 30611.8403 - val_mae: 52.3237 - val_mse: 30611.8398\n",
      "Epoch 693/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 15274.1166 - mae: 49.0183 - mse: 15274.1152 - val_loss: 30607.6006 - val_mae: 52.3940 - val_mse: 30607.5996\n",
      "Epoch 694/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15222.2690 - mae: 49.0295 - mse: 15222.2686 - val_loss: 30607.5743 - val_mae: 52.1358 - val_mse: 30607.5742\n",
      "Epoch 695/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15372.1171 - mae: 48.5698 - mse: 15372.1133 - val_loss: 30608.7431 - val_mae: 51.8697 - val_mse: 30608.7441\n",
      "Epoch 696/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15119.5437 - mae: 49.1433 - mse: 15119.5449 - val_loss: 30607.7527 - val_mae: 51.8126 - val_mse: 30607.7559\n",
      "Epoch 697/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 15142.6817 - mae: 48.4166 - mse: 15142.6836 - val_loss: 30597.3240 - val_mae: 52.4808 - val_mse: 30597.3242\n",
      "Epoch 698/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15185.7473 - mae: 49.0939 - mse: 15185.7461 - val_loss: 30599.8101 - val_mae: 52.0389 - val_mse: 30599.8105\n",
      "Epoch 699/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15244.7829 - mae: 49.1763 - mse: 15244.7891 - val_loss: 30601.8805 - val_mae: 51.6570 - val_mse: 30601.8770\n",
      "Epoch 700/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15192.1345 - mae: 48.3392 - mse: 15192.1309 - val_loss: 30597.2765 - val_mae: 51.7436 - val_mse: 30597.2773\n",
      "Epoch 701/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15189.6267 - mae: 49.0954 - mse: 15189.6289 - val_loss: 30581.7158 - val_mae: 52.3998 - val_mse: 30581.7168\n",
      "Epoch 702/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15188.3673 - mae: 49.1607 - mse: 15188.3701 - val_loss: 30577.6421 - val_mae: 52.3541 - val_mse: 30577.6426\n",
      "Epoch 703/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15203.7992 - mae: 48.9355 - mse: 15203.7988 - val_loss: 30581.5237 - val_mae: 51.6923 - val_mse: 30581.5234\n",
      "Epoch 704/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15127.1103 - mae: 48.2095 - mse: 15127.1113 - val_loss: 30568.6410 - val_mae: 52.8647 - val_mse: 30568.6426\n",
      "Epoch 705/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15263.4211 - mae: 49.0584 - mse: 15263.4209 - val_loss: 30574.6544 - val_mae: 52.0152 - val_mse: 30574.6543\n",
      "Epoch 706/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15296.1467 - mae: 48.5875 - mse: 15296.1475 - val_loss: 30621.9697 - val_mae: 50.5699 - val_mse: 30621.9707\n",
      "Epoch 707/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15320.3965 - mae: 47.8409 - mse: 15320.3975 - val_loss: 30576.3467 - val_mae: 51.6589 - val_mse: 30576.3457\n",
      "Epoch 708/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15207.2554 - mae: 49.2606 - mse: 15207.2539 - val_loss: 30586.5949 - val_mae: 51.1538 - val_mse: 30586.5957\n",
      "Epoch 709/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15297.4948 - mae: 48.2225 - mse: 15297.4941 - val_loss: 30567.1490 - val_mae: 51.7576 - val_mse: 30567.1484\n",
      "Epoch 710/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15377.5917 - mae: 48.7666 - mse: 15377.5898 - val_loss: 30560.5100 - val_mae: 52.1929 - val_mse: 30560.5098\n",
      "Epoch 711/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15237.8348 - mae: 47.9601 - mse: 15237.8340 - val_loss: 30556.9919 - val_mae: 52.3150 - val_mse: 30556.9922\n",
      "Epoch 712/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15195.6094 - mae: 49.4077 - mse: 15195.6064 - val_loss: 30572.3209 - val_mae: 51.3134 - val_mse: 30572.3203\n",
      "Epoch 713/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15196.6771 - mae: 48.3271 - mse: 15196.6729 - val_loss: 30554.4158 - val_mae: 52.0045 - val_mse: 30554.4141\n",
      "Epoch 714/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15329.4490 - mae: 47.9399 - mse: 15329.4502 - val_loss: 30551.3323 - val_mae: 51.8569 - val_mse: 30551.3320\n",
      "Epoch 715/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15316.5842 - mae: 48.5458 - mse: 15316.5850 - val_loss: 30542.3793 - val_mae: 52.6327 - val_mse: 30542.3809\n",
      "Epoch 716/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15206.1281 - mae: 49.3393 - mse: 15206.1240 - val_loss: 30571.6877 - val_mae: 51.0857 - val_mse: 30571.6875\n",
      "Epoch 717/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14988.8145 - mae: 48.7011 - mse: 14988.8125 - val_loss: 30551.0500 - val_mae: 51.7244 - val_mse: 30551.0508\n",
      "Epoch 718/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15187.6578 - mae: 48.1472 - mse: 15187.6572 - val_loss: 30535.9332 - val_mae: 52.6528 - val_mse: 30535.9316\n",
      "Epoch 719/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15362.7972 - mae: 48.9098 - mse: 15362.7988 - val_loss: 30533.1415 - val_mae: 52.5071 - val_mse: 30533.1406\n",
      "Epoch 720/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15183.0774 - mae: 48.5145 - mse: 15183.0771 - val_loss: 30528.9920 - val_mae: 52.6776 - val_mse: 30528.9922\n",
      "Epoch 721/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15143.5890 - mae: 48.8807 - mse: 15143.5908 - val_loss: 30528.9002 - val_mae: 52.1142 - val_mse: 30528.9004\n",
      "Epoch 722/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15196.2314 - mae: 48.4536 - mse: 15196.2324 - val_loss: 30524.3047 - val_mae: 52.6194 - val_mse: 30524.3047\n",
      "Epoch 723/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15240.8248 - mae: 48.9462 - mse: 15240.8262 - val_loss: 30554.7982 - val_mae: 50.9729 - val_mse: 30554.7969\n",
      "Epoch 724/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15196.8153 - mae: 48.3887 - mse: 15196.8164 - val_loss: 30516.0832 - val_mae: 52.6277 - val_mse: 30516.0859\n",
      "Epoch 725/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15261.7162 - mae: 49.1587 - mse: 15261.7148 - val_loss: 30521.0737 - val_mae: 52.0835 - val_mse: 30521.0723\n",
      "Epoch 726/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15264.0797 - mae: 48.5315 - mse: 15264.0801 - val_loss: 30525.0290 - val_mae: 51.5201 - val_mse: 30525.0293\n",
      "Epoch 727/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15215.4049 - mae: 48.8837 - mse: 15215.4014 - val_loss: 30530.1409 - val_mae: 51.4052 - val_mse: 30530.1406\n",
      "Epoch 728/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15270.8214 - mae: 49.3061 - mse: 15270.8213 - val_loss: 30561.2183 - val_mae: 50.6431 - val_mse: 30561.2227\n",
      "Epoch 729/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15153.1906 - mae: 47.7251 - mse: 15153.1885 - val_loss: 30509.0383 - val_mae: 53.2017 - val_mse: 30509.0371\n",
      "Epoch 730/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15189.4678 - mae: 49.1216 - mse: 15189.4717 - val_loss: 30536.5289 - val_mae: 51.3235 - val_mse: 30536.5293\n",
      "Epoch 731/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15215.6520 - mae: 48.4737 - mse: 15215.6514 - val_loss: 30506.9763 - val_mae: 52.8014 - val_mse: 30506.9766\n",
      "Epoch 732/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15126.0601 - mae: 48.2621 - mse: 15126.0615 - val_loss: 30503.6909 - val_mae: 53.2870 - val_mse: 30503.6895\n",
      "Epoch 733/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15308.9115 - mae: 48.6898 - mse: 15308.9092 - val_loss: 30527.7654 - val_mae: 51.0428 - val_mse: 30527.7676\n",
      "Epoch 734/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15018.6151 - mae: 48.3086 - mse: 15018.6133 - val_loss: 30501.5402 - val_mae: 51.9207 - val_mse: 30501.5391\n",
      "Epoch 735/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15027.9287 - mae: 48.8431 - mse: 15027.9287 - val_loss: 30514.4709 - val_mae: 51.2276 - val_mse: 30514.4727\n",
      "Epoch 736/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15135.3613 - mae: 48.4311 - mse: 15135.3613 - val_loss: 30516.5129 - val_mae: 51.1146 - val_mse: 30516.5117\n",
      "Epoch 737/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 15254.8668 - mae: 47.8006 - mse: 15254.8672 - val_loss: 30485.5726 - val_mae: 52.6962 - val_mse: 30485.5723\n",
      "Epoch 738/1000\n",
      "3200/3200 [==============================] - 0s 52us/sample - loss: 15154.8833 - mae: 48.6331 - mse: 15154.8809 - val_loss: 30485.8774 - val_mae: 53.0715 - val_mse: 30485.8770\n",
      "Epoch 739/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 15204.0027 - mae: 48.4436 - mse: 15204.0029 - val_loss: 30487.1937 - val_mae: 52.2227 - val_mse: 30487.1934\n",
      "Epoch 740/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15257.0357 - mae: 48.6167 - mse: 15257.0391 - val_loss: 30484.0321 - val_mae: 51.9708 - val_mse: 30484.0332\n",
      "Epoch 741/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15145.7302 - mae: 48.5662 - mse: 15145.7305 - val_loss: 30480.6193 - val_mae: 52.0447 - val_mse: 30480.6191\n",
      "Epoch 742/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15123.9863 - mae: 49.0373 - mse: 15123.9883 - val_loss: 30495.1111 - val_mae: 51.3376 - val_mse: 30495.1094\n",
      "Epoch 743/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14992.9170 - mae: 48.1320 - mse: 14992.9150 - val_loss: 30475.3173 - val_mae: 52.5664 - val_mse: 30475.3184\n",
      "Epoch 744/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15012.9991 - mae: 48.7051 - mse: 15012.9961 - val_loss: 30471.2442 - val_mae: 52.6652 - val_mse: 30471.2441\n",
      "Epoch 745/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15183.3019 - mae: 48.6975 - mse: 15183.3027 - val_loss: 30496.7016 - val_mae: 51.0846 - val_mse: 30496.7031\n",
      "Epoch 746/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15163.2435 - mae: 48.7938 - mse: 15163.2412 - val_loss: 30519.1384 - val_mae: 50.5978 - val_mse: 30519.1367\n",
      "Epoch 747/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15241.8400 - mae: 48.2664 - mse: 15241.8389 - val_loss: 30504.5772 - val_mae: 51.0055 - val_mse: 30504.5801\n",
      "Epoch 748/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15168.3870 - mae: 48.6968 - mse: 15168.3848 - val_loss: 30475.5734 - val_mae: 51.7944 - val_mse: 30475.5723\n",
      "Epoch 749/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15106.0117 - mae: 48.0565 - mse: 15106.0117 - val_loss: 30464.8438 - val_mae: 52.1320 - val_mse: 30464.8418\n",
      "Epoch 750/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15004.3544 - mae: 48.5427 - mse: 15004.3535 - val_loss: 30456.0318 - val_mae: 53.5209 - val_mse: 30456.0332\n",
      "Epoch 751/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15116.2446 - mae: 49.0954 - mse: 15116.2461 - val_loss: 30476.2787 - val_mae: 51.2768 - val_mse: 30476.2773\n",
      "Epoch 752/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15062.4365 - mae: 48.2850 - mse: 15062.4346 - val_loss: 30456.1023 - val_mae: 52.2760 - val_mse: 30456.1055\n",
      "Epoch 753/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15039.6338 - mae: 48.1446 - mse: 15039.6299 - val_loss: 30450.8764 - val_mae: 53.1658 - val_mse: 30450.8770\n",
      "Epoch 754/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15208.1105 - mae: 49.2191 - mse: 15208.1123 - val_loss: 30464.0845 - val_mae: 51.3709 - val_mse: 30464.0859\n",
      "Epoch 755/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 15131.0704 - mae: 48.3626 - mse: 15131.0654 - val_loss: 30440.4356 - val_mae: 52.5447 - val_mse: 30440.4355\n",
      "Epoch 756/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15193.9844 - mae: 48.3540 - mse: 15193.9863 - val_loss: 30450.0743 - val_mae: 51.9445 - val_mse: 30450.0742\n",
      "Epoch 757/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15170.6015 - mae: 48.2913 - mse: 15170.6035 - val_loss: 30459.0330 - val_mae: 51.4167 - val_mse: 30459.0352\n",
      "Epoch 758/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15142.5662 - mae: 47.9518 - mse: 15142.5654 - val_loss: 30457.8332 - val_mae: 51.2842 - val_mse: 30457.8359\n",
      "Epoch 759/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15106.4138 - mae: 48.2610 - mse: 15106.4160 - val_loss: 30441.2062 - val_mae: 51.8539 - val_mse: 30441.2051\n",
      "Epoch 760/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15186.3308 - mae: 48.4585 - mse: 15186.3291 - val_loss: 30439.3954 - val_mae: 51.9178 - val_mse: 30439.3945\n",
      "Epoch 761/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14982.2683 - mae: 48.2224 - mse: 14982.2676 - val_loss: 30432.3213 - val_mae: 52.5041 - val_mse: 30432.3223\n",
      "Epoch 762/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15045.8506 - mae: 48.6996 - mse: 15045.8516 - val_loss: 30435.9851 - val_mae: 51.8982 - val_mse: 30435.9844\n",
      "Epoch 763/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15184.6986 - mae: 48.6106 - mse: 15184.6992 - val_loss: 30443.6151 - val_mae: 51.3736 - val_mse: 30443.6152\n",
      "Epoch 764/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15196.7384 - mae: 47.6931 - mse: 15196.7383 - val_loss: 30420.9674 - val_mae: 53.2108 - val_mse: 30420.9648\n",
      "Epoch 765/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 15145.7608 - mae: 49.5386 - mse: 15145.7617 - val_loss: 30459.3858 - val_mae: 50.7127 - val_mse: 30459.3848\n",
      "Epoch 766/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15259.9855 - mae: 48.3675 - mse: 15259.9863 - val_loss: 30448.3730 - val_mae: 51.1028 - val_mse: 30448.3691\n",
      "Epoch 767/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15062.6261 - mae: 48.4293 - mse: 15062.6250 - val_loss: 30441.0629 - val_mae: 51.3651 - val_mse: 30441.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15098.0880 - mae: 48.4137 - mse: 15098.0928 - val_loss: 30447.8958 - val_mae: 50.9619 - val_mse: 30447.8926\n",
      "Epoch 769/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15210.5754 - mae: 47.6537 - mse: 15210.5752 - val_loss: 30419.0549 - val_mae: 52.1358 - val_mse: 30419.0547\n",
      "Epoch 770/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15117.7842 - mae: 48.6855 - mse: 15117.7852 - val_loss: 30415.0543 - val_mae: 52.3022 - val_mse: 30415.0508\n",
      "Epoch 771/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14977.7475 - mae: 48.3414 - mse: 14977.7500 - val_loss: 30410.3519 - val_mae: 52.4395 - val_mse: 30410.3516\n",
      "Epoch 772/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15023.4178 - mae: 48.4052 - mse: 15023.4189 - val_loss: 30409.2024 - val_mae: 52.1507 - val_mse: 30409.2031\n",
      "Epoch 773/1000\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 16425.2948 - mae: 48.3649 - mse: 16425.29 - 0s 32us/sample - loss: 15072.2476 - mae: 48.5098 - mse: 15072.2441 - val_loss: 30427.2123 - val_mae: 51.1229 - val_mse: 30427.2148\n",
      "Epoch 774/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14969.6234 - mae: 47.6447 - mse: 14969.6221 - val_loss: 30398.6786 - val_mae: 52.6722 - val_mse: 30398.6777\n",
      "Epoch 775/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14990.9569 - mae: 49.0234 - mse: 14990.9600 - val_loss: 30405.8753 - val_mae: 51.8884 - val_mse: 30405.8750\n",
      "Epoch 776/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14942.2995 - mae: 47.8079 - mse: 14942.2979 - val_loss: 30403.4892 - val_mae: 51.7639 - val_mse: 30403.4883\n",
      "Epoch 777/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15089.1228 - mae: 48.1733 - mse: 15089.1260 - val_loss: 30395.6501 - val_mae: 52.0611 - val_mse: 30395.6523\n",
      "Epoch 778/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15013.5037 - mae: 48.5825 - mse: 15013.5039 - val_loss: 30405.0933 - val_mae: 51.5507 - val_mse: 30405.0918\n",
      "Epoch 779/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15090.8763 - mae: 48.6824 - mse: 15090.8740 - val_loss: 30388.5733 - val_mae: 52.2628 - val_mse: 30388.5742\n",
      "Epoch 780/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15056.7678 - mae: 48.2492 - mse: 15056.7686 - val_loss: 30427.1042 - val_mae: 50.7566 - val_mse: 30427.1055\n",
      "Epoch 781/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15070.1656 - mae: 48.5143 - mse: 15070.1650 - val_loss: 30403.8318 - val_mae: 51.2616 - val_mse: 30403.8320\n",
      "Epoch 782/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15108.9450 - mae: 48.0037 - mse: 15108.9473 - val_loss: 30410.7587 - val_mae: 51.0667 - val_mse: 30410.7598\n",
      "Epoch 783/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15048.0347 - mae: 48.0835 - mse: 15048.0342 - val_loss: 30383.1972 - val_mae: 51.9573 - val_mse: 30383.1973\n",
      "Epoch 784/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 15421.3870 - mae: 48.0763 - mse: 15421.3867 - val_loss: 30399.8823 - val_mae: 51.0866 - val_mse: 30399.8828\n",
      "Epoch 785/1000\n",
      "3200/3200 [==============================] - 0s 57us/sample - loss: 15133.1722 - mae: 48.3905 - mse: 15133.1729 - val_loss: 30394.6615 - val_mae: 51.1124 - val_mse: 30394.6621\n",
      "Epoch 786/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 14958.2661 - mae: 47.9659 - mse: 14958.2646 - val_loss: 30385.9007 - val_mae: 51.4230 - val_mse: 30385.9023\n",
      "Epoch 787/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14977.0707 - mae: 48.3418 - mse: 14977.0713 - val_loss: 30368.4894 - val_mae: 52.0987 - val_mse: 30368.4883\n",
      "Epoch 788/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15070.7445 - mae: 48.1297 - mse: 15070.7441 - val_loss: 30387.5478 - val_mae: 51.1405 - val_mse: 30387.5469\n",
      "Epoch 789/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15102.2397 - mae: 48.2191 - mse: 15102.2383 - val_loss: 30379.2354 - val_mae: 51.5649 - val_mse: 30379.2344\n",
      "Epoch 790/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15031.9950 - mae: 47.8984 - mse: 15031.9941 - val_loss: 30372.4459 - val_mae: 51.7784 - val_mse: 30372.4453\n",
      "Epoch 791/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15076.9564 - mae: 48.5821 - mse: 15076.9609 - val_loss: 30374.1514 - val_mae: 51.5022 - val_mse: 30374.1504\n",
      "Epoch 792/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 15037.7862 - mae: 48.1115 - mse: 15037.7871 - val_loss: 30374.6400 - val_mae: 51.2562 - val_mse: 30374.6406\n",
      "Epoch 793/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15177.4470 - mae: 48.1955 - mse: 15177.4502 - val_loss: 30374.8509 - val_mae: 51.2207 - val_mse: 30374.8496\n",
      "Epoch 794/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15125.5679 - mae: 48.4305 - mse: 15125.5674 - val_loss: 30382.8389 - val_mae: 51.0074 - val_mse: 30382.8398\n",
      "Epoch 795/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15113.7029 - mae: 48.2058 - mse: 15113.7021 - val_loss: 30372.5697 - val_mae: 51.4327 - val_mse: 30372.5684\n",
      "Epoch 796/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15040.8784 - mae: 48.4646 - mse: 15040.8750 - val_loss: 30377.3582 - val_mae: 51.0691 - val_mse: 30377.3594\n",
      "Epoch 797/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15005.5429 - mae: 47.6707 - mse: 15005.5430 - val_loss: 30347.7911 - val_mae: 52.7984 - val_mse: 30347.7930\n",
      "Epoch 798/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 15084.8277 - mae: 48.3471 - mse: 15084.8291 - val_loss: 30364.2028 - val_mae: 51.3280 - val_mse: 30364.2031\n",
      "Epoch 799/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15008.6540 - mae: 48.0201 - mse: 15008.6572 - val_loss: 30342.3122 - val_mae: 52.0225 - val_mse: 30342.3125\n",
      "Epoch 800/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14935.6986 - mae: 47.9575 - mse: 14935.7002 - val_loss: 30340.0352 - val_mae: 52.5970 - val_mse: 30340.0352\n",
      "Epoch 801/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15024.9296 - mae: 48.2580 - mse: 15024.9316 - val_loss: 30347.0002 - val_mae: 51.5631 - val_mse: 30347.0000\n",
      "Epoch 802/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14974.8503 - mae: 47.9765 - mse: 14974.8496 - val_loss: 30334.2776 - val_mae: 52.3718 - val_mse: 30334.2773\n",
      "Epoch 803/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14948.1232 - mae: 48.1603 - mse: 14948.1240 - val_loss: 30343.0582 - val_mae: 51.6609 - val_mse: 30343.0566\n",
      "Epoch 804/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15052.0806 - mae: 48.7605 - mse: 15052.0811 - val_loss: 30358.9668 - val_mae: 51.0092 - val_mse: 30358.9668\n",
      "Epoch 805/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14905.8747 - mae: 47.8951 - mse: 14905.8750 - val_loss: 30337.9515 - val_mae: 52.0633 - val_mse: 30337.9531\n",
      "Epoch 806/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14985.9371 - mae: 48.4484 - mse: 14985.9385 - val_loss: 30335.3263 - val_mae: 52.0851 - val_mse: 30335.3281\n",
      "Epoch 807/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14952.9550 - mae: 48.2573 - mse: 14952.9561 - val_loss: 30340.6135 - val_mae: 51.5700 - val_mse: 30340.6133\n",
      "Epoch 808/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14986.8855 - mae: 47.8221 - mse: 14986.8838 - val_loss: 30324.8754 - val_mae: 52.3301 - val_mse: 30324.8750\n",
      "Epoch 809/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14998.3756 - mae: 47.8991 - mse: 14998.3750 - val_loss: 30320.5725 - val_mae: 52.4007 - val_mse: 30320.5723\n",
      "Epoch 810/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15243.8083 - mae: 48.6758 - mse: 15243.8096 - val_loss: 30345.8333 - val_mae: 50.9762 - val_mse: 30345.8320\n",
      "Epoch 811/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14942.9803 - mae: 47.7087 - mse: 14942.9805 - val_loss: 30312.5992 - val_mae: 52.5199 - val_mse: 30312.5996\n",
      "Epoch 812/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15091.0021 - mae: 48.5205 - mse: 15091.0029 - val_loss: 30333.7861 - val_mae: 51.1926 - val_mse: 30333.7871\n",
      "Epoch 813/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 15098.6465 - mae: 47.6733 - mse: 15098.6445 - val_loss: 30328.5966 - val_mae: 51.3176 - val_mse: 30328.5977\n",
      "Epoch 814/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14984.5386 - mae: 48.7160 - mse: 14984.5352 - val_loss: 30336.8017 - val_mae: 51.1195 - val_mse: 30336.8008\n",
      "Epoch 815/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15019.1134 - mae: 47.6864 - mse: 15019.1113 - val_loss: 30314.6620 - val_mae: 52.3557 - val_mse: 30314.6602\n",
      "Epoch 816/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15003.0171 - mae: 48.3428 - mse: 15003.0146 - val_loss: 30334.7893 - val_mae: 51.2187 - val_mse: 30334.7930\n",
      "Epoch 817/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15017.5048 - mae: 47.7353 - mse: 15017.5059 - val_loss: 30327.9984 - val_mae: 51.4353 - val_mse: 30327.9980\n",
      "Epoch 818/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14849.5943 - mae: 48.0418 - mse: 14849.5928 - val_loss: 30306.1228 - val_mae: 52.9945 - val_mse: 30306.1250\n",
      "Epoch 819/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15094.6738 - mae: 48.3580 - mse: 15094.6738 - val_loss: 30326.3521 - val_mae: 51.1907 - val_mse: 30326.3516\n",
      "Epoch 820/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15055.2344 - mae: 48.4295 - mse: 15055.2324 - val_loss: 30327.1551 - val_mae: 51.0985 - val_mse: 30327.1543\n",
      "Epoch 821/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15063.8735 - mae: 47.5882 - mse: 15063.8740 - val_loss: 30327.0424 - val_mae: 51.2813 - val_mse: 30327.0449\n",
      "Epoch 822/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15122.0078 - mae: 48.3985 - mse: 15122.0078 - val_loss: 30327.9566 - val_mae: 51.1741 - val_mse: 30327.9551\n",
      "Epoch 823/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14888.2234 - mae: 48.2839 - mse: 14888.2236 - val_loss: 30316.0110 - val_mae: 51.4185 - val_mse: 30316.0098\n",
      "Epoch 824/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14949.0159 - mae: 47.9628 - mse: 14949.0137 - val_loss: 30316.2211 - val_mae: 51.2355 - val_mse: 30316.2207\n",
      "Epoch 825/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14982.6523 - mae: 48.4033 - mse: 14982.6514 - val_loss: 30309.4623 - val_mae: 51.5732 - val_mse: 30309.4629\n",
      "Epoch 826/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14983.2757 - mae: 47.5168 - mse: 14983.2803 - val_loss: 30301.3664 - val_mae: 51.8695 - val_mse: 30301.3672\n",
      "Epoch 827/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15060.7883 - mae: 48.6739 - mse: 15060.7871 - val_loss: 30298.9900 - val_mae: 51.8448 - val_mse: 30298.9902\n",
      "Epoch 828/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15095.1815 - mae: 48.5809 - mse: 15095.1816 - val_loss: 30342.6669 - val_mae: 50.4125 - val_mse: 30342.6680\n",
      "Epoch 829/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14919.4593 - mae: 47.4226 - mse: 14919.4590 - val_loss: 30300.4708 - val_mae: 51.4605 - val_mse: 30300.4707\n",
      "Epoch 830/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14776.6888 - mae: 47.9044 - mse: 14776.6865 - val_loss: 30283.2755 - val_mae: 52.7759 - val_mse: 30283.2773\n",
      "Epoch 831/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14865.0652 - mae: 48.7534 - mse: 14865.0635 - val_loss: 30298.6360 - val_mae: 51.3495 - val_mse: 30298.6348\n",
      "Epoch 832/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14971.9601 - mae: 48.0714 - mse: 14971.9600 - val_loss: 30297.3107 - val_mae: 51.3799 - val_mse: 30297.3105\n",
      "Epoch 833/1000\n",
      "3200/3200 [==============================] - 0s 57us/sample - loss: 15106.5907 - mae: 47.8818 - mse: 15106.5928 - val_loss: 30306.7465 - val_mae: 51.0840 - val_mse: 30306.7480\n",
      "Epoch 834/1000\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 14799.5742 - mae: 48.0535 - mse: 14799.5742 - val_loss: 30285.3392 - val_mae: 52.0800 - val_mse: 30285.3379\n",
      "Epoch 835/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15037.6153 - mae: 47.6080 - mse: 15037.6152 - val_loss: 30279.7523 - val_mae: 52.0341 - val_mse: 30279.7500\n",
      "Epoch 836/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15058.2695 - mae: 47.9608 - mse: 15058.2715 - val_loss: 30294.1696 - val_mae: 51.3156 - val_mse: 30294.1719\n",
      "Epoch 837/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15022.1158 - mae: 48.3213 - mse: 15022.1162 - val_loss: 30275.9030 - val_mae: 52.4076 - val_mse: 30275.9023\n",
      "Epoch 838/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15039.0163 - mae: 48.1909 - mse: 15039.0166 - val_loss: 30283.2479 - val_mae: 51.8302 - val_mse: 30283.2480\n",
      "Epoch 839/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14947.3953 - mae: 48.1994 - mse: 14947.3965 - val_loss: 30288.6038 - val_mae: 51.4025 - val_mse: 30288.6055\n",
      "Epoch 840/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14937.2833 - mae: 47.8778 - mse: 14937.2861 - val_loss: 30299.7395 - val_mae: 51.0106 - val_mse: 30299.7383\n",
      "Epoch 841/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14816.9437 - mae: 47.4487 - mse: 14816.9434 - val_loss: 30271.4146 - val_mae: 52.4020 - val_mse: 30271.4180\n",
      "Epoch 842/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 15125.1652 - mae: 48.0813 - mse: 15125.1650 - val_loss: 30266.4650 - val_mae: 52.3688 - val_mse: 30266.4648\n",
      "Epoch 843/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14966.5788 - mae: 47.7594 - mse: 14966.5771 - val_loss: 30267.7194 - val_mae: 53.6721 - val_mse: 30267.7207\n",
      "Epoch 844/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14953.2080 - mae: 48.8215 - mse: 14953.2100 - val_loss: 30259.8347 - val_mae: 52.4609 - val_mse: 30259.8320\n",
      "Epoch 845/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14885.6756 - mae: 48.0826 - mse: 14885.6758 - val_loss: 30262.7910 - val_mae: 52.1355 - val_mse: 30262.7891\n",
      "Epoch 846/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15062.2202 - mae: 47.6941 - mse: 15062.2188 - val_loss: 30256.1032 - val_mae: 52.6259 - val_mse: 30256.1055\n",
      "Epoch 847/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14908.4671 - mae: 49.1443 - mse: 14908.4736 - val_loss: 30269.2845 - val_mae: 51.4680 - val_mse: 30269.2832\n",
      "Epoch 848/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14908.2574 - mae: 47.8196 - mse: 14908.2637 - val_loss: 30281.2203 - val_mae: 51.0659 - val_mse: 30281.2168\n",
      "Epoch 849/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14874.0267 - mae: 47.5280 - mse: 14874.0273 - val_loss: 30254.0690 - val_mae: 53.1347 - val_mse: 30254.0684\n",
      "Epoch 850/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14887.5924 - mae: 48.7613 - mse: 14887.5908 - val_loss: 30251.6947 - val_mae: 52.3862 - val_mse: 30251.6953\n",
      "Epoch 851/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14782.6951 - mae: 47.8674 - mse: 14782.6934 - val_loss: 30256.9615 - val_mae: 53.5316 - val_mse: 30256.9629\n",
      "Epoch 852/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14893.6031 - mae: 48.0754 - mse: 14893.6016 - val_loss: 30253.9890 - val_mae: 51.8083 - val_mse: 30253.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14981.3334 - mae: 47.9417 - mse: 14981.3320 - val_loss: 30242.2406 - val_mae: 52.1297 - val_mse: 30242.2422\n",
      "Epoch 854/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14814.8536 - mae: 47.3402 - mse: 14814.8535 - val_loss: 30237.1081 - val_mae: 52.8687 - val_mse: 30237.1094\n",
      "Epoch 855/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14966.2213 - mae: 47.8160 - mse: 14966.2217 - val_loss: 30233.9551 - val_mae: 52.5937 - val_mse: 30233.9531\n",
      "Epoch 856/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14853.3927 - mae: 48.8042 - mse: 14853.3926 - val_loss: 30271.3960 - val_mae: 50.7163 - val_mse: 30271.3984\n",
      "Epoch 857/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14943.6107 - mae: 47.5691 - mse: 14943.6104 - val_loss: 30256.2192 - val_mae: 51.0352 - val_mse: 30256.2207\n",
      "Epoch 858/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15043.8083 - mae: 47.7054 - mse: 15043.8076 - val_loss: 30249.1561 - val_mae: 51.3279 - val_mse: 30249.1582\n",
      "Epoch 859/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15008.1666 - mae: 48.7572 - mse: 15008.1680 - val_loss: 30247.2968 - val_mae: 51.5941 - val_mse: 30247.2969\n",
      "Epoch 860/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14770.7641 - mae: 48.0128 - mse: 14770.7666 - val_loss: 30238.4658 - val_mae: 52.0847 - val_mse: 30238.4668\n",
      "Epoch 861/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14852.3295 - mae: 48.7125 - mse: 14852.3311 - val_loss: 30258.5355 - val_mae: 51.1939 - val_mse: 30258.5352\n",
      "Epoch 862/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14849.5339 - mae: 47.9953 - mse: 14849.5322 - val_loss: 30262.2709 - val_mae: 51.0141 - val_mse: 30262.2695\n",
      "Epoch 863/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14968.9066 - mae: 48.4290 - mse: 14968.9023 - val_loss: 30270.1484 - val_mae: 50.7062 - val_mse: 30270.1504\n",
      "Epoch 864/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14832.8905 - mae: 47.7206 - mse: 14832.8887 - val_loss: 30255.5338 - val_mae: 50.8812 - val_mse: 30255.5371\n",
      "Epoch 865/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 15016.9766 - mae: 47.4915 - mse: 15016.9814 - val_loss: 30246.1860 - val_mae: 51.1469 - val_mse: 30246.1875\n",
      "Epoch 866/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14971.8229 - mae: 47.7562 - mse: 14971.8242 - val_loss: 30226.3954 - val_mae: 52.5451 - val_mse: 30226.3945\n",
      "Epoch 867/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14974.7133 - mae: 48.4902 - mse: 14974.7148 - val_loss: 30228.9778 - val_mae: 52.0713 - val_mse: 30228.9766\n",
      "Epoch 868/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15066.0718 - mae: 47.4916 - mse: 15066.0752 - val_loss: 30233.1920 - val_mae: 51.7826 - val_mse: 30233.1895\n",
      "Epoch 869/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14846.6149 - mae: 48.4965 - mse: 14846.6152 - val_loss: 30223.6549 - val_mae: 52.0483 - val_mse: 30223.6543\n",
      "Epoch 870/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14941.5075 - mae: 48.4264 - mse: 14941.5059 - val_loss: 30243.3648 - val_mae: 51.0088 - val_mse: 30243.3652\n",
      "Epoch 871/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14890.0172 - mae: 47.7088 - mse: 14890.0176 - val_loss: 30214.7911 - val_mae: 52.9012 - val_mse: 30214.7930\n",
      "Epoch 872/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14904.0948 - mae: 47.4670 - mse: 14904.0947 - val_loss: 30209.4166 - val_mae: 52.4770 - val_mse: 30209.4141\n",
      "Epoch 873/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15081.1279 - mae: 48.8444 - mse: 15081.1250 - val_loss: 30212.3878 - val_mae: 52.1523 - val_mse: 30212.3867\n",
      "Epoch 874/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14937.1912 - mae: 48.0609 - mse: 14937.1875 - val_loss: 30219.7872 - val_mae: 51.5805 - val_mse: 30219.7871\n",
      "Epoch 875/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14853.4547 - mae: 48.2322 - mse: 14853.4541 - val_loss: 30237.9104 - val_mae: 50.9791 - val_mse: 30237.9121\n",
      "Epoch 876/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14856.0244 - mae: 47.4892 - mse: 14856.0254 - val_loss: 30208.6086 - val_mae: 52.1243 - val_mse: 30208.6074\n",
      "Epoch 877/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14817.7760 - mae: 47.5929 - mse: 14817.7773 - val_loss: 30213.1199 - val_mae: 51.7338 - val_mse: 30213.1191\n",
      "Epoch 878/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14905.7373 - mae: 48.2475 - mse: 14905.7354 - val_loss: 30212.1090 - val_mae: 51.6366 - val_mse: 30212.1094\n",
      "Epoch 879/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14877.5751 - mae: 47.5386 - mse: 14877.5742 - val_loss: 30221.1459 - val_mae: 51.1124 - val_mse: 30221.1445\n",
      "Epoch 880/1000\n",
      "3200/3200 [==============================] - 0s 41us/sample - loss: 14882.4129 - mae: 48.1339 - mse: 14882.4121 - val_loss: 30209.2757 - val_mae: 51.4254 - val_mse: 30209.2754\n",
      "Epoch 881/1000\n",
      "3200/3200 [==============================] - 0s 63us/sample - loss: 14904.7827 - mae: 47.9403 - mse: 14904.7842 - val_loss: 30208.3197 - val_mae: 51.7533 - val_mse: 30208.3203\n",
      "Epoch 882/1000\n",
      "3200/3200 [==============================] - 0s 48us/sample - loss: 14808.9340 - mae: 47.5804 - mse: 14808.9336 - val_loss: 30198.0589 - val_mae: 53.3400 - val_mse: 30198.0605\n",
      "Epoch 883/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14858.1404 - mae: 48.6030 - mse: 14858.1426 - val_loss: 30219.8526 - val_mae: 51.1428 - val_mse: 30219.8516\n",
      "Epoch 884/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 14970.4366 - mae: 47.4540 - mse: 14970.4346 - val_loss: 30203.2067 - val_mae: 51.5348 - val_mse: 30203.2070\n",
      "Epoch 885/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14910.9611 - mae: 47.9725 - mse: 14910.9609 - val_loss: 30200.6844 - val_mae: 51.5322 - val_mse: 30200.6816\n",
      "Epoch 886/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 15027.2429 - mae: 47.4494 - mse: 15027.2422 - val_loss: 30191.2747 - val_mae: 52.2600 - val_mse: 30191.2734\n",
      "Epoch 887/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14943.2283 - mae: 49.0731 - mse: 14943.2275 - val_loss: 30199.2233 - val_mae: 51.5315 - val_mse: 30199.2246\n",
      "Epoch 888/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15009.6300 - mae: 47.7723 - mse: 15009.6299 - val_loss: 30246.1025 - val_mae: 50.3487 - val_mse: 30246.1016\n",
      "Epoch 889/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14894.1192 - mae: 47.7712 - mse: 14894.1191 - val_loss: 30223.4301 - val_mae: 50.8270 - val_mse: 30223.4297\n",
      "Epoch 890/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14953.8320 - mae: 47.1646 - mse: 14953.8320 - val_loss: 30191.7173 - val_mae: 52.5451 - val_mse: 30191.7168\n",
      "Epoch 891/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14890.2027 - mae: 49.0368 - mse: 14890.2012 - val_loss: 30211.4842 - val_mae: 51.1826 - val_mse: 30211.4824\n",
      "Epoch 892/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14920.7053 - mae: 47.9720 - mse: 14920.7021 - val_loss: 30189.9914 - val_mae: 51.7786 - val_mse: 30189.9922\n",
      "Epoch 893/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14917.6290 - mae: 47.8374 - mse: 14917.6328 - val_loss: 30199.7963 - val_mae: 51.4539 - val_mse: 30199.7949\n",
      "Epoch 894/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14899.2875 - mae: 47.8078 - mse: 14899.2871 - val_loss: 30188.0463 - val_mae: 51.8058 - val_mse: 30188.0449\n",
      "Epoch 895/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14914.0901 - mae: 47.3011 - mse: 14914.0928 - val_loss: 30179.8738 - val_mae: 53.1722 - val_mse: 30179.8691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14904.1069 - mae: 48.5054 - mse: 14904.1055 - val_loss: 30177.2864 - val_mae: 52.5002 - val_mse: 30177.2871\n",
      "Epoch 897/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14958.7181 - mae: 48.5646 - mse: 14958.7178 - val_loss: 30188.2506 - val_mae: 51.4296 - val_mse: 30188.2520\n",
      "Epoch 898/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14996.5872 - mae: 47.2834 - mse: 14996.5859 - val_loss: 30183.5841 - val_mae: 51.7152 - val_mse: 30183.5859\n",
      "Epoch 899/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14854.8783 - mae: 47.8636 - mse: 14854.8779 - val_loss: 30176.6941 - val_mae: 51.9596 - val_mse: 30176.6953\n",
      "Epoch 900/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14846.7522 - mae: 47.8995 - mse: 14846.7539 - val_loss: 30181.9986 - val_mae: 51.5619 - val_mse: 30181.9980\n",
      "Epoch 901/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14974.9582 - mae: 48.4018 - mse: 14974.9609 - val_loss: 30208.6265 - val_mae: 50.8117 - val_mse: 30208.6270\n",
      "Epoch 902/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14822.0575 - mae: 47.4038 - mse: 14822.0547 - val_loss: 30172.1871 - val_mae: 53.2415 - val_mse: 30172.1875\n",
      "Epoch 903/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14807.2150 - mae: 48.3753 - mse: 14807.2148 - val_loss: 30170.8224 - val_mae: 53.0284 - val_mse: 30170.8223\n",
      "Epoch 904/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14884.3481 - mae: 48.3859 - mse: 14884.3516 - val_loss: 30173.0575 - val_mae: 51.9712 - val_mse: 30173.0605\n",
      "Epoch 905/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14720.2216 - mae: 47.6461 - mse: 14720.2197 - val_loss: 30165.3306 - val_mae: 52.8064 - val_mse: 30165.3301\n",
      "Epoch 906/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14794.7493 - mae: 48.1318 - mse: 14794.7461 - val_loss: 30183.8426 - val_mae: 51.3391 - val_mse: 30183.8457\n",
      "Epoch 907/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14790.8846 - mae: 48.1642 - mse: 14790.8867 - val_loss: 30171.5705 - val_mae: 51.6648 - val_mse: 30171.5703\n",
      "Epoch 908/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14995.5937 - mae: 47.3958 - mse: 14995.5938 - val_loss: 30170.0986 - val_mae: 52.2027 - val_mse: 30170.0977\n",
      "Epoch 909/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14767.8140 - mae: 48.2988 - mse: 14767.8154 - val_loss: 30196.0020 - val_mae: 51.0839 - val_mse: 30196.0020\n",
      "Epoch 910/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14787.4827 - mae: 47.5835 - mse: 14787.4834 - val_loss: 30173.4825 - val_mae: 51.9673 - val_mse: 30173.4844\n",
      "Epoch 911/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14931.0172 - mae: 47.8060 - mse: 14931.0186 - val_loss: 30179.5182 - val_mae: 51.8885 - val_mse: 30179.5195\n",
      "Epoch 912/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14821.8831 - mae: 47.4963 - mse: 14821.8838 - val_loss: 30175.5201 - val_mae: 53.9042 - val_mse: 30175.5195\n",
      "Epoch 913/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14911.2490 - mae: 48.2140 - mse: 14911.2461 - val_loss: 30157.4967 - val_mae: 52.6249 - val_mse: 30157.4980\n",
      "Epoch 914/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14940.6523 - mae: 48.2863 - mse: 14940.6523 - val_loss: 30161.5371 - val_mae: 52.0017 - val_mse: 30161.5371\n",
      "Epoch 915/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14784.9046 - mae: 47.8384 - mse: 14784.9053 - val_loss: 30165.6427 - val_mae: 51.7639 - val_mse: 30165.6406\n",
      "Epoch 916/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14838.3164 - mae: 48.0973 - mse: 14838.3184 - val_loss: 30179.7300 - val_mae: 51.4481 - val_mse: 30179.7305\n",
      "Epoch 917/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14913.8702 - mae: 47.0119 - mse: 14913.8701 - val_loss: 30160.1248 - val_mae: 52.2770 - val_mse: 30160.1270\n",
      "Epoch 918/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14794.5459 - mae: 48.5007 - mse: 14794.5439 - val_loss: 30155.1661 - val_mae: 52.8831 - val_mse: 30155.1680\n",
      "Epoch 919/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14791.1388 - mae: 47.7495 - mse: 14791.1338 - val_loss: 30176.7215 - val_mae: 51.1878 - val_mse: 30176.7207\n",
      "Epoch 920/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14845.8072 - mae: 48.1266 - mse: 14845.8096 - val_loss: 30172.2585 - val_mae: 51.3473 - val_mse: 30172.2598\n",
      "Epoch 921/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14894.5325 - mae: 47.1042 - mse: 14894.5342 - val_loss: 30154.5447 - val_mae: 53.0409 - val_mse: 30154.5449\n",
      "Epoch 922/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14833.0514 - mae: 48.0460 - mse: 14833.0537 - val_loss: 30169.9008 - val_mae: 51.2278 - val_mse: 30169.9004\n",
      "Epoch 923/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14784.6837 - mae: 47.6219 - mse: 14784.6846 - val_loss: 30155.3269 - val_mae: 52.0469 - val_mse: 30155.3281\n",
      "Epoch 924/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14888.5419 - mae: 47.9943 - mse: 14888.5439 - val_loss: 30148.7902 - val_mae: 52.6596 - val_mse: 30148.7891\n",
      "Epoch 925/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14820.7688 - mae: 47.7271 - mse: 14820.7725 - val_loss: 30148.5748 - val_mae: 52.3164 - val_mse: 30148.5781\n",
      "Epoch 926/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14793.3471 - mae: 48.5608 - mse: 14793.3467 - val_loss: 30181.1542 - val_mae: 50.7601 - val_mse: 30181.1543\n",
      "Epoch 927/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14820.8042 - mae: 48.0933 - mse: 14820.8037 - val_loss: 30139.9188 - val_mae: 52.0772 - val_mse: 30139.9199\n",
      "Epoch 928/1000\n",
      "3200/3200 [==============================] - 0s 39us/sample - loss: 14801.6863 - mae: 47.4746 - mse: 14801.6875 - val_loss: 30159.9758 - val_mae: 51.0698 - val_mse: 30159.9746\n",
      "Epoch 929/1000\n",
      "3200/3200 [==============================] - 0s 63us/sample - loss: 14917.2123 - mae: 47.7532 - mse: 14917.2148 - val_loss: 30173.5214 - val_mae: 50.7693 - val_mse: 30173.5234\n",
      "Epoch 930/1000\n",
      "3200/3200 [==============================] - 0s 48us/sample - loss: 14878.4752 - mae: 47.6231 - mse: 14878.4727 - val_loss: 30136.8485 - val_mae: 52.0114 - val_mse: 30136.8477\n",
      "Epoch 931/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14774.6299 - mae: 47.4666 - mse: 14774.6299 - val_loss: 30132.0633 - val_mae: 52.4560 - val_mse: 30132.0645\n",
      "Epoch 932/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 14776.5390 - mae: 47.8356 - mse: 14776.5391 - val_loss: 30137.2937 - val_mae: 52.4110 - val_mse: 30137.2949\n",
      "Epoch 933/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 14775.3660 - mae: 47.8128 - mse: 14775.3633 - val_loss: 30133.1327 - val_mae: 52.0980 - val_mse: 30133.1348\n",
      "Epoch 934/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14796.7544 - mae: 48.2967 - mse: 14796.7559 - val_loss: 30134.6143 - val_mae: 51.8923 - val_mse: 30134.6133\n",
      "Epoch 935/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14945.8270 - mae: 47.5598 - mse: 14945.8262 - val_loss: 30135.4523 - val_mae: 52.1188 - val_mse: 30135.4492\n",
      "Epoch 936/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14938.1821 - mae: 47.9386 - mse: 14938.1797 - val_loss: 30136.8711 - val_mae: 52.3056 - val_mse: 30136.8750\n",
      "Epoch 937/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14704.0829 - mae: 48.3244 - mse: 14704.0811 - val_loss: 30153.0053 - val_mae: 51.2060 - val_mse: 30153.0020\n",
      "Epoch 938/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14930.3000 - mae: 47.3749 - mse: 14930.3008 - val_loss: 30143.7189 - val_mae: 51.7443 - val_mse: 30143.7168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 939/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14831.6493 - mae: 47.1238 - mse: 14831.6484 - val_loss: 30144.6884 - val_mae: 52.7489 - val_mse: 30144.6895\n",
      "Epoch 940/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 15003.7706 - mae: 47.9543 - mse: 15003.7734 - val_loss: 30153.5549 - val_mae: 51.4805 - val_mse: 30153.5547\n",
      "Epoch 941/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14927.0029 - mae: 48.1928 - mse: 14927.0039 - val_loss: 30149.9400 - val_mae: 51.7678 - val_mse: 30149.9395\n",
      "Epoch 942/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14763.5151 - mae: 47.7632 - mse: 14763.5146 - val_loss: 30149.1665 - val_mae: 51.7478 - val_mse: 30149.1680\n",
      "Epoch 943/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14852.2570 - mae: 48.0023 - mse: 14852.2598 - val_loss: 30137.5307 - val_mae: 52.2457 - val_mse: 30137.5332\n",
      "Epoch 944/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14915.5507 - mae: 47.8639 - mse: 14915.5508 - val_loss: 30136.3800 - val_mae: 52.3028 - val_mse: 30136.3828\n",
      "Epoch 945/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14837.2752 - mae: 47.5492 - mse: 14837.2734 - val_loss: 30136.6756 - val_mae: 52.4799 - val_mse: 30136.6758\n",
      "Epoch 946/1000\n",
      "3200/3200 [==============================] - 0s 31us/sample - loss: 14847.8613 - mae: 48.0846 - mse: 14847.8623 - val_loss: 30133.6015 - val_mae: 52.1503 - val_mse: 30133.5996\n",
      "Epoch 947/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14873.9596 - mae: 47.6965 - mse: 14873.9600 - val_loss: 30135.4456 - val_mae: 51.8736 - val_mse: 30135.4492\n",
      "Epoch 948/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14899.7549 - mae: 47.9395 - mse: 14899.7559 - val_loss: 30147.5925 - val_mae: 51.4542 - val_mse: 30147.5918\n",
      "Epoch 949/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14999.7308 - mae: 47.2970 - mse: 14999.7334 - val_loss: 30138.4639 - val_mae: 51.7141 - val_mse: 30138.4648\n",
      "Epoch 950/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14916.9481 - mae: 48.2900 - mse: 14916.9473 - val_loss: 30125.4564 - val_mae: 52.9936 - val_mse: 30125.4570\n",
      "Epoch 951/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14878.4389 - mae: 47.8990 - mse: 14878.4404 - val_loss: 30123.9667 - val_mae: 52.3226 - val_mse: 30123.9707\n",
      "Epoch 952/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14829.9065 - mae: 47.9935 - mse: 14829.9033 - val_loss: 30135.4760 - val_mae: 51.6116 - val_mse: 30135.4766\n",
      "Epoch 953/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14908.3911 - mae: 47.9025 - mse: 14908.3926 - val_loss: 30179.2960 - val_mae: 50.3820 - val_mse: 30179.2949\n",
      "Epoch 954/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14681.9770 - mae: 47.4672 - mse: 14681.9766 - val_loss: 30127.9434 - val_mae: 53.3742 - val_mse: 30127.9434\n",
      "Epoch 955/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14959.9556 - mae: 48.3557 - mse: 14959.9551 - val_loss: 30153.3389 - val_mae: 50.8825 - val_mse: 30153.3398\n",
      "Epoch 956/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14822.1529 - mae: 47.5856 - mse: 14822.1533 - val_loss: 30124.6883 - val_mae: 51.6246 - val_mse: 30124.6875\n",
      "Epoch 957/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14729.7799 - mae: 47.3939 - mse: 14729.7822 - val_loss: 30135.0541 - val_mae: 51.2872 - val_mse: 30135.0547\n",
      "Epoch 958/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14960.6420 - mae: 47.8264 - mse: 14960.6445 - val_loss: 30114.7318 - val_mae: 52.9069 - val_mse: 30114.7324\n",
      "Epoch 959/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14756.8632 - mae: 48.5520 - mse: 14756.8652 - val_loss: 30116.1077 - val_mae: 52.5759 - val_mse: 30116.1074\n",
      "Epoch 960/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14815.5995 - mae: 48.4087 - mse: 14815.5986 - val_loss: 30142.2299 - val_mae: 50.9246 - val_mse: 30142.2324\n",
      "Epoch 961/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14857.4325 - mae: 47.4840 - mse: 14857.4326 - val_loss: 30127.9246 - val_mae: 51.2943 - val_mse: 30127.9219\n",
      "Epoch 962/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14849.9568 - mae: 47.5029 - mse: 14849.9590 - val_loss: 30133.5417 - val_mae: 51.1766 - val_mse: 30133.5391\n",
      "Epoch 963/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14854.3766 - mae: 48.2526 - mse: 14854.3750 - val_loss: 30112.9022 - val_mae: 52.0635 - val_mse: 30112.9004\n",
      "Epoch 964/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14743.6473 - mae: 48.0407 - mse: 14743.6436 - val_loss: 30111.3702 - val_mae: 51.9599 - val_mse: 30111.3691\n",
      "Epoch 965/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14658.7037 - mae: 47.7638 - mse: 14658.7051 - val_loss: 30182.8467 - val_mae: 50.1386 - val_mse: 30182.8457\n",
      "Epoch 966/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14878.2052 - mae: 46.7492 - mse: 14878.2061 - val_loss: 30100.9475 - val_mae: 52.4970 - val_mse: 30100.9473\n",
      "Epoch 967/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14801.0049 - mae: 48.6613 - mse: 14801.0049 - val_loss: 30128.5645 - val_mae: 51.0098 - val_mse: 30128.5645\n",
      "Epoch 968/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 14845.2624 - mae: 47.7028 - mse: 14845.2598 - val_loss: 30112.0914 - val_mae: 51.4989 - val_mse: 30112.0918\n",
      "Epoch 969/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14893.2092 - mae: 47.0978 - mse: 14893.2070 - val_loss: 30104.0907 - val_mae: 52.3413 - val_mse: 30104.0918\n",
      "Epoch 970/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14855.6054 - mae: 47.7751 - mse: 14855.6035 - val_loss: 30113.3167 - val_mae: 51.8482 - val_mse: 30113.3184\n",
      "Epoch 971/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14763.2712 - mae: 48.4333 - mse: 14763.2734 - val_loss: 30119.2491 - val_mae: 51.2582 - val_mse: 30119.2500\n",
      "Epoch 972/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14704.2364 - mae: 48.3563 - mse: 14704.2314 - val_loss: 30131.5473 - val_mae: 50.8957 - val_mse: 30131.5469\n",
      "Epoch 973/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14929.6085 - mae: 47.5687 - mse: 14929.6074 - val_loss: 30104.2010 - val_mae: 51.6692 - val_mse: 30104.1992\n",
      "Epoch 974/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14844.6064 - mae: 47.1518 - mse: 14844.6064 - val_loss: 30121.1874 - val_mae: 54.4631 - val_mse: 30121.1895\n",
      "Epoch 975/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14898.9442 - mae: 48.8362 - mse: 14898.9453 - val_loss: 30093.3812 - val_mae: 52.3193 - val_mse: 30093.3828\n",
      "Epoch 976/1000\n",
      "3200/3200 [==============================] - 0s 47us/sample - loss: 14882.8560 - mae: 47.6586 - mse: 14882.8555 - val_loss: 30121.3355 - val_mae: 51.0853 - val_mse: 30121.3398\n",
      "Epoch 977/1000\n",
      "3200/3200 [==============================] - 0s 76us/sample - loss: 14997.9732 - mae: 48.2293 - mse: 14997.9736 - val_loss: 30105.5717 - val_mae: 51.5294 - val_mse: 30105.5703\n",
      "Epoch 978/1000\n",
      "3200/3200 [==============================] - 0s 46us/sample - loss: 14778.3906 - mae: 47.4925 - mse: 14778.3916 - val_loss: 30093.2506 - val_mae: 52.3700 - val_mse: 30093.2500\n",
      "Epoch 979/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 14838.1241 - mae: 47.7785 - mse: 14838.1250 - val_loss: 30107.5635 - val_mae: 51.7418 - val_mse: 30107.5645\n",
      "Epoch 980/1000\n",
      "3200/3200 [==============================] - 0s 40us/sample - loss: 14773.5609 - mae: 47.4322 - mse: 14773.5615 - val_loss: 30101.4471 - val_mae: 52.3121 - val_mse: 30101.4473\n",
      "Epoch 981/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14694.8644 - mae: 47.9819 - mse: 14694.8633 - val_loss: 30100.6882 - val_mae: 51.6499 - val_mse: 30100.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "3200/3200 [==============================] - 0s 35us/sample - loss: 14782.1298 - mae: 47.2314 - mse: 14782.1289 - val_loss: 30089.3322 - val_mae: 52.5567 - val_mse: 30089.3320\n",
      "Epoch 983/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14844.9965 - mae: 49.0063 - mse: 14844.9971 - val_loss: 30130.4693 - val_mae: 50.8364 - val_mse: 30130.4707\n",
      "Epoch 984/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14885.7615 - mae: 47.1234 - mse: 14885.7598 - val_loss: 30101.2068 - val_mae: 51.5301 - val_mse: 30101.2051\n",
      "Epoch 985/1000\n",
      "3200/3200 [==============================] - 0s 36us/sample - loss: 14800.4906 - mae: 47.0129 - mse: 14800.4922 - val_loss: 30091.3129 - val_mae: 52.7668 - val_mse: 30091.3125\n",
      "Epoch 986/1000\n",
      "3200/3200 [==============================] - 0s 38us/sample - loss: 14930.0116 - mae: 47.9065 - mse: 14930.0127 - val_loss: 30109.2367 - val_mae: 51.2162 - val_mse: 30109.2344\n",
      "Epoch 987/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14688.2586 - mae: 47.5299 - mse: 14688.2588 - val_loss: 30102.3010 - val_mae: 51.3405 - val_mse: 30102.3008\n",
      "Epoch 988/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14809.9446 - mae: 48.0919 - mse: 14809.9404 - val_loss: 30089.9637 - val_mae: 53.0766 - val_mse: 30089.9629\n",
      "Epoch 989/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14757.9770 - mae: 47.5340 - mse: 14757.9766 - val_loss: 30083.4819 - val_mae: 52.4512 - val_mse: 30083.4824\n",
      "Epoch 990/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14832.9945 - mae: 47.8886 - mse: 14832.9951 - val_loss: 30084.1221 - val_mae: 52.3572 - val_mse: 30084.1191\n",
      "Epoch 991/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14796.0753 - mae: 47.7637 - mse: 14796.0752 - val_loss: 30098.6698 - val_mae: 51.2604 - val_mse: 30098.6699\n",
      "Epoch 992/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14840.9649 - mae: 47.7344 - mse: 14840.9648 - val_loss: 30082.1497 - val_mae: 52.0093 - val_mse: 30082.1523\n",
      "Epoch 993/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14796.6744 - mae: 48.0080 - mse: 14796.6797 - val_loss: 30113.5519 - val_mae: 50.7450 - val_mse: 30113.5527\n",
      "Epoch 994/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14783.3248 - mae: 48.1285 - mse: 14783.3252 - val_loss: 30111.1053 - val_mae: 50.8084 - val_mse: 30111.1016\n",
      "Epoch 995/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14594.9582 - mae: 47.4833 - mse: 14594.9561 - val_loss: 30073.8046 - val_mae: 52.0300 - val_mse: 30073.8066\n",
      "Epoch 996/1000\n",
      "3200/3200 [==============================] - 0s 37us/sample - loss: 14803.4324 - mae: 48.2084 - mse: 14803.4365 - val_loss: 30093.7906 - val_mae: 51.1287 - val_mse: 30093.7891\n",
      "Epoch 997/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14769.1864 - mae: 47.6359 - mse: 14769.1865 - val_loss: 30082.4207 - val_mae: 51.4630 - val_mse: 30082.4219\n",
      "Epoch 998/1000\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 14766.6230 - mae: 47.9073 - mse: 14766.6221 - val_loss: 30086.4266 - val_mae: 51.3158 - val_mse: 30086.4258\n",
      "Epoch 999/1000\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 14581.2678 - mae: 48.5830 - mse: 14581.2676 - val_loss: 30095.0604 - val_mae: 50.9974 - val_mse: 30095.0605\n",
      "Epoch 1000/1000\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 14671.9057 - mae: 47.1991 - mse: 14671.9062 - val_loss: 30075.4980 - val_mae: 53.2935 - val_mse: 30075.4980\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.2) # 42, 56, 66, 87\n",
    "\n",
    "# https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(9, activation='relu', input_shape =(9,)) , #Could use softmax\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "     tf.keras.layers.Dense(9, activation='relu') ,\n",
    "  tf.keras.layers.Dense(1, activation='relu')# Could use softmax\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs= 1000,\n",
    "                    batch_size = 50,\n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "print(hist.tail())\n",
    "\n",
    "#Plotting results, after training model\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('Model Error')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
